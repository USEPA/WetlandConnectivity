---
title: "Make WetPath Tables"
author: "Ryan Hill"
date: "Thursday, June 09, 2016"
output: html_document
---

# Set up
```{r, eval=F}
final_path = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/FinalTables/WetlandTables/'
accum_path = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/Accumulation/'
accum_cat = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/Accumulation/'
precip_path = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/WetlandCat/Accumulation/'
data_path = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/WetlandPath/Data'
wetland_tables = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/FinalTables/WetlandTables/'
lookup_tables = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/LookupTables/'
cat_path = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/FinalTables/NHDPlusCatchmentTables/'
#table_combo = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/CombiningTables/'
files = list.files(accum_path, pattern = 'NLCD'); rpus = c()
for(i in 1:length(files)){
  #print(files[i])
  rpus[i] = substr(files[i], 18, 20)
}
```

#Make rise, run, slope tables
```{r, eval=F}
for(i in 1:length(rpus)){
  print(rpus[i])
  elevmax = read.csv(paste0(accum_path, 'Elev_MAX_', rpus[i], '.csv'))
  elevmin = read.csv(paste0(accum_path, 'Elev_MIN_', rpus[i], '.csv'))  
  rise = merge(elevmax, elevmin)
  rise$rise = (rise$MAX - rise$MIN) / 100 #convert to meters
  rise$rise = rise$rise + 0.1
  rise = rise[ ,c('PathID', 'rise')]
  #names(rise) = c('PATHID', 'rise')
  write.csv(rise, paste0(accum_path, 'rise_m_', rpus[i], '.csv'), row.names=F)
}

# for(i in 1:length(rpus)){
#   print(rpus[i])
#   rise = read.csv(paste0(accum_path, 'rise_m_', rpus[i], '.csv'))
#   print(summary(rise))
#   #names(rise)[1] <- 'PATHID'
#   #write.csv(rise, paste0(accum_path, 'rise_m_', rpus[i], '.csv'), row.names=F)                
# }

#Make run tables

for(i in 1:length(rpus)){
  print(rpus[i])
  flmax = read.csv(paste0(accum_path, 'flowlength_m_MAX_', rpus[i], '.csv'))
  flmin = read.csv(paste0(accum_path, 'flowlength_m_MIN_', rpus[i], '.csv'))  
  run = merge(flmax, flmin)
  run$run = (run$MAX - run$MIN) + 15
  run = run[ ,c('PathID', 'run')]
  names(run) = c('PATHID', 'run')
  write.csv(run, paste0(accum_path, 'run_m_', rpus[i], '.csv'), row.names=F)
}


#Make slope tables

for(i in 1:length(rpus)){
  print(rpus[i])
  rise = read.csv(paste0(accum_path, 'rise_m_', rpus[i], '.csv'))
  run = read.csv(paste0(accum_path, 'run_m_', rpus[i], '.csv'))  
  slope = merge(rise, run)
  slope$slope = (slope$rise / slope$run) 
  slope = slope[ ,c('PATHID', 'slope')]
  write.csv(slope, paste0(accum_path, 'slope_', rpus[i], '.csv'), row.names=F)
}
```

#Make Precip and Mannings tables
```{r, eval=F}
library(stringr)
#path_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/WetlandPath/Accumulation'
path_dir = accum_path

variables=list.files(path_dir)

# Mannings
library(foreign)
rat <- read.dbf('L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/nlcd2011.tif.vat.dbf')
names(rat) <- toupper(names(rat))
r <- sapply(rat$VALUE, function(x) paste(c('VALUE_',x),collapse=''))
library(matrixStats)
nlcdlist = variables[grep("NLCD2011", variables)]
mannings = read.csv('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/LookupTables/NLCD_Mannings_Lookup.csv')
head(mannings)
for (i in 1:length(nlcdlist)){
  nlcd = read.csv(paste0(path_dir,'/',nlcdlist[i]))
  head(nlcd)
  missing <- r[is.na(match(r, names(nlcd)))]
  nlcd[,paste(missing)] <- c(0)
  nlcd$Total <- rowSums(nlcd[,2:length(nlcd)])
  
  #calculate %s for each nlcd category
  for (k in 2:length(nlcd)){
    nlcd[,k] = 100.0 * nlcd[,k]/nlcd[,length(nlcd)]
  } 
  nlcd = nlcd[c(1:(length(nlcd)-1))]
  #calculate final mannings geometric mean
  #First raise each mannings to the % of flow path of NLCD type
  for (m in 2:length(nlcd)){
    nlcd[,m] = (mannings$Mannings[match(names(nlcd)[m], mannings$NLCD)])^(nlcd[,m])
  } 
  #Calculate geomean using product
  nlcd$GeoMean = (rowProds(as.matrix(nlcd[,2:17])))^(1/100)
  names(nlcd)[1] = 'PATHID'
  nlcd = nlcd[, c('PATHID','GeoMean')]
  write.csv(nlcd, paste0(path_dir, '/Mannings', str_sub(strsplit(nlcdlist[i],'\\.')[[1]][1],-3),'.csv'))
}

#New precip code
cat_dir = accum_cat
variables=list.files(cat_dir)
preciplist = variables[grep("US2yr24ha_mm_10x_MEAN_", variables)]
#lookups = list.files(lookup_tables)
#lookup_list = lookups[grep("WetlandsWithPath_StreamLink_Lookup", lookups)]
rpus = c()
for(i in 1:length(preciplist)){
  #print(files[i])
  rpus[i] = substr(preciplist[i], 23, 25)
}
for(i in 1:length(rpus)){
  precip = read.csv(paste0(cat_dir, 'US2yr24ha_mm_10x_MEAN_', rpus[i], '.csv'))
  precip$PRECIP_2YR24HR_MM = (precip$SUM / precip$COUNT) * 0.1
  lookup = read.csv(paste0(lookup_tables, 'WetlandsWithPath_StreamLink_Lookup_', rpus[i], '.csv'))
  names(precip) = toupper(names(precip))
  precip$PATHID = lookup$STRMLNK_ID[match(precip$BASINID, lookup$WET_ID)]
}


#----------------------------------------------------------------------------------------------------------------------------------------------
#Old precip code that did no use accumulated precip
# Precip
library(foreign)
#cat_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/WetlandCat/Zonal'
cat_dir = accum_cat
variables=list.files(cat_dir)
preciplist = variables[grep("US2yr24ha_mm_10x_MEAN_", variables)]
preciplist = preciplist[grep('\\.dbf$',preciplist)]
lookups = list.files('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/LookupTables')
lookup_list = lookups[grep("WetlandsWithPath_StreamLink_Lookup", lookups)]

for (i in 1:59){
  precip = read.dbf(paste0(cat_dir,'/',preciplist[i]))
  head(precip)
  precip$PRECIP_2YR24HR_MM = precip$MEAN * .1
  lookup = read.csv(paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/LookupTables/',lookup_list[i]))
  names(precip) = toupper(names(precip))
  precip$PATHID = lookup$STRMLNK_ID[match(precip$VALUE, lookup$WET_ID)]
  precip = precip[c(1,15,14)]
  names(precip)[1] = 'WETID'
  write.csv(precip, paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/WetlandCat/Accumulation/Precip2Yr24hr', str_sub(strsplit(preciplist[i],'\\.')[[1]][1],-3),'.csv'))
}

```


#Make combine to make start of shallow table
```{r, eval=F}
for(i in 1:length(rpus)){
  print(rpus[i])
  run = read.csv(paste0(accum_path, 'run_m_', rpus[i], '.csv'))
  slope = read.csv(paste0(accum_path, 'slope_', rpus[i], '.csv'))
  porosity = read.csv(paste0(accum_path, 'AvgPorosity_MAX_', rpus[i], '.csv'))
  names(porosity) <- c('PATHID', 'porosity_max')
  perm = read.csv(paste0(accum_path, 'AvgPerm_MIN_', rpus[i], '.csv'))
  perm$MIN = perm$MIN / 1000
  names(perm) <- c('PATHID', 'perm_min')
  
  out_table = run
  out_table = merge(out_table, slope)
  out_table = merge(out_table, porosity)
  out_table = merge(out_table, perm)
  
  write.csv(out_table, paste0(final_path, 'ShallowFlow_', rpus[i], '.csv'), row.names=F)
}
```

#Make shallow travel time
```{r, eval=F}
for(i in 1:length(rpus)){
  print(rpus[i])
  travel = read.csv(paste0(final_path, 'ShallowFlow_', rpus[i], '.csv'))
  
  travel$perm_min = travel$perm_min #+ 0.1

  travel$slope = travel$slope + 0.01
  
  travel$t_shallow = travel$run / ((travel$perm_min / travel$porosity_max) * travel$slope)
  
  write.csv(travel, paste0(final_path, 'ShallowFlow_', rpus[i], '.csv'), row.names=F)
}
```

#Make flow type table
```{r, eval=F}
library(dplyr)
r = c('VALUE_11', 'VALUE_12', 'VALUE_21', 'VALUE_22')

for(i in 1:length(rpus)){
  
  print(rpus[i])
  flow_cls = read.csv(paste0(accum_path, 'BdrckPerm_4_classes_Alb83_PERCENT_', rpus[i], '.csv'))   
  missing <- r[is.na(match(r, names(flow_cls)))]
  flow_cls[,paste(missing)] <- c(0)
  
  flow_cls = flow_cls[, c('PathID', r)] #make in right order
  
  flow_cls[ ,2:5] = prop.table(as.matrix(flow_cls[ ,2:5]), margin = 1) * 100
  flow_cls$Overland = flow_cls$VALUE_11 + flow_cls$VALUE_21
  flow_cls = select(flow_cls, -VALUE_11, -VALUE_21)
    #Make sure in correct order
  flow_cls = flow_cls[, c('PathID','VALUE_12','VALUE_22','Overland')]  
  names(flow_cls)[1:3] <- c('PATHID','Shallow','ShallowDeep')
  type_names = names(flow_cls)[2:4]  
  flow_cls = na.omit(flow_cls)  
  flow_cls$DomFlow = type_names[apply(flow_cls[, 2:4], 1, which.max)]
  write.csv(flow_cls, paste0(final_path, 'FlowClass_', rpus[i], '.csv'), row.names=F)
  
}     
        
        
```


#Make combine to make start of overland table
```{r, eval=F}
for(i in 1:length(rpus)){
  print(rpus[i])
  run = read.csv(paste0(accum_path, 'run_m_', rpus[i], '.csv'))
  slope = read.csv(paste0(accum_path, 'slope_', rpus[i], '.csv'))
  slope$slope = slope$slope + 0.01
  man = read.csv(paste0(accum_path, 'Mannings', rpus[i], '.csv'))
  man = man[ , c('PATHID','GeoMean')]
  names(man) <- c('PATHID','Manning')
  precip = read.csv((paste0(precip_path, 'Precip2Yr24hr', rpus[i], '.csv')))
  precip = precip[!is.na(precip$PATHID),]
  # precip 2yr24hr values already divided by 10 when making accumulation tables, so use as is
  precip = precip[c(2:4)]
  out_table = precip
  out_table = merge(out_table, slope, by='PATHID', all.x=TRUE)
  out_table = merge(out_table, man, by='PATHID', all.x=TRUE)
  out_table = merge(out_table, run, by='PATHID', all.x=TRUE)
  write.csv(out_table, paste0(final_path, 'OverlandFlow_', rpus[i], '.csv'), row.names=F)
}

```

#Make overland travel time
```{r, eval=F}
for(i in 1:length(rpus)){
  print(rpus[i])
  travel = read.csv(paste0(final_path, 'OverlandFlow_', rpus[i], '.csv'))
  
  travel$t_overland = 0.0913*(((travel$Manning * travel$run)^0.8)/((travel$PRECIP_2YR24HR_MM)^0.5 * (travel$slope)^0.4))
  
  write.csv(travel, paste0(final_path, 'OverlandFlow_', rpus[i], '.csv'), row.names=F)
}
```

#Get  flow type for wetlands with no path 
```{r, eval=F}
library(raster)
library(dplyr)
r = c('VALUE_11', 'VALUE_12', 'VALUE_21', 'VALUE_22')

bdrck = raster('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Gleason/BdrckPerm_4_classes_Alb83.tif')
  
for(i in 1:length(rpus)){
  print(rpus[i])
  wet_points = readOGR(data_path, paste0('WetlandPoints', rpus[i])) 
  projection(bdrck)
  proj4string(wet_points)
  results = extract(bdrck, wet_points)
  wet_points$DomFlow =  results
  wet_points$DomFlow[wet_points$DomFlow %in% c(11,21)] = 'Overland'
  wet_points$DomFlow[wet_points$DomFlow == 12] = 'Shallow'
  wet_points$DomFlow[wet_points$DomFlow == 22] = 'ShallowDeep'
  wet_points = wet_points[,c('GRID_CODE','DomFlow')]
  names(wet_points)[1] = 'WETID'
  write.csv(wet_points, paste0(wetland_tables, 'Wetland_NoPath_FlowClass', rpus[i], '.csv'), row.names=F)
}     

for(i in 1:length(rpus)){
  print(rpus[i])
  wet_points = read.csv(paste0(wetland_tables, 'Wetland_NoPath_FlowClass', rpus[i], '.csv')) 
  wet_points = wet_points[,c('GRID_CODE','DomFlow')]
  names(wet_points)[1] = 'WETID'
  write.csv(wet_points, paste0(wetland_tables, 'Wetland_NoPath_FlowClass', rpus[i], '.csv'), row.names=F)
}     
```

#Make levee influence table
```{r, eval=F}


```

#Make cathment tables
```{r, eval=F}
library(dplyr)
master_table = read.csv(paste0(lookup_tables,'eco9_all.csv'))

# overland
for(i in 1:length(rpus)){
  print(rpus[i])
  travel = read.csv(paste0(final_path, 'OverlandFlow_', rpus[i], '.csv'))
  travel = travel[!is.na(travel$t_overland), ]
  cat_lookup = read.csv(paste0(lookup_tables, 'Wetlands_NHDPlusCat_Lookup_', rpus[i], '.csv'))
  travel$COMID = cat_lookup$COMID[match(travel$WETID, cat_lookup$WET_ID)]
  if (i==1){
    final = group_by(travel,COMID)
    final = summarize(final, t_overland_mean = mean(t_overland), t_overland_med = median(t_overland))
    final$WSA_9 = master_table$WSA_9[match(final$COMID, master_table$COMID)]
  }
  if (i> 1){
    temp = group_by(travel,COMID)
    temp = summarize(temp, t_overland_mean = mean(t_overland), t_overland_med = median(t_overland))
    temp$WSA_9 = master_table$WSA_9[match(temp$COMID, master_table$COMID)]
    final = rbind(final, temp)
  }
}
master_table$t_overland_mean = final$t_overland_mean[match(master_table$COMID, final$COMID)]
master_table$t_overland_med = final$t_overland_med[match(master_table$COMID, final$COMID)]
write.csv(master_table, paste0(cat_path, 'OverlandFlow.csv'), row.names=F)
rmNA = na.omit(master_table)
write.csv(rmNA, file = paste0(cat_path, 'OverlandFlow_narm.csv'), row.names=F)

# shallow
master_table = read.csv(paste0(lookup_tables,'eco9_all.csv'))
for(i in 1:length(rpus)){
  print(rpus[i])
  travel = read.csv(paste0(final_path, 'ShallowFlow_', rpus[i], '.csv'))
  travel = travel[!is.na(travel$t_shallow), ]
  cat_lookup = read.csv(paste0(lookup_tables, 'Wetlands_NHDPlusCat_Lookup_', rpus[i], '.csv'))
  travel$COMID = cat_lookup$COMID[match(travel$WETID, cat_lookup$WET_ID)]
  if (i==1){
    final = group_by(travel,COMID)
    final = summarize(final, t_shallow_mean = mean(t_shallow), t_shallow_med = median(t_shallow))
    final$WSA_9 = master_table$WSA_9[match(final$COMID, master_table$COMID)]
  }
  if (i> 1){
    temp = group_by(travel,COMID)
    temp = summarize(temp, t_shallow_mean = mean(t_shallow), t_shallow_med = median(t_shallow))
    temp$WSA_9 = master_table$WSA_9[match(temp$COMID, master_table$COMID)]
    final = rbind(final, temp)
  }
}
master_table$t_shallow_mean = final$t_shallow_mean[match(master_table$COMID, final$COMID)]
master_table$t_shallow_med = final$t_shallow_med[match(master_table$COMID, final$COMID)]
write.csv(master_table, paste0(cat_path, 'ShallowFlow.csv'), row.names=F)
rmNA = na.omit(master_table)
write.csv(rmNA, file = paste0(cat_path, 'ShallowFlow_narm.csv'), row.names=F)

# summary of wetland type by NHDPlus catchment
master_table = read.csv(paste0(lookup_tables,'eco9_all.csv'))
for(i in 1:length(rpus)){
  print(rpus[i])
  wetlands = read.csv(paste0(lookup_tables, 'AllWetlands_StreamLink_Lookup_', rpus[i], '.csv'))
  cat_lookup = read.csv(paste0(lookup_tables, 'Wetlands_NHDPlusCat_Lookup_', rpus[i], '.csv'))
  wetlands$COMID = cat_lookup$COMID[match(wetlands$WET_ID, cat_lookup$WET_ID)]
  wetlands$Group1 = 0
  wetlands$Group1[is.na(wetlands$STRMLNK_ID)] = 1
  wetlands$Group2 = 1
  
  if (i==1){
    final = group_by(wetlands,COMID)
    final = summarize(final, sumG1 = sum(Group1), sumG2 = sum(Group2))
    final$PCTGIW = (final$sumG1/final$sumG2) *100
    final$WSA_9 = master_table$WSA_9[match(final$COMID, master_table$COMID)]
    final = final[,c('COMID','PCTGIW','WSA_9')]
  }
  if (i> 1){
    temp = group_by(wetlands,COMID)
    temp = summarize(temp, sumG1 = sum(Group1), sumG2 = sum(Group2))
    temp$PCTGIW = (temp$sumG1/temp$sumG2) *100
    temp$WSA_9 = master_table$WSA_9[match(temp$COMID, master_table$COMID)]
    temp = temp[,c('COMID','PCTGIW','WSA_9')]
    final = rbind(final, temp)
  }
}  
master_table$PCTGIW = final$PCTGIW[match(master_table$COMID, final$COMID)]
write.csv(master_table, paste0(cat_path, 'GIW_PERCENT.csv'), row.names=F)

# Mannings
master_table = read.csv(paste0(lookup_tables,'eco9_all.csv'))
for(i in 1:length(rpus)){
  print(rpus[i])
  travel = read.csv(paste0(accum_path, 'Mannings', rpus[i], '.csv'))
  travel = travel[!is.na(travel$GeoMean), ]
  wetid = read.csv(paste0(lookup_tables, 'WetlandsWithPath_StreamLink_Lookup_', rpus[i], '.csv'))
  travel$WET_ID = wetid$WET_ID[match(travel$PATHID, wetid$STRMLNK_ID)]
  cat_lookup = read.csv(paste0(lookup_tables, 'Wetlands_NHDPlusCat_Lookup_', rpus[i], '.csv'))
  travel$COMID = cat_lookup$COMID[match(travel$WET_ID, cat_lookup$WET_ID)]
  if (i==1){
    final = group_by(travel,COMID)
    final = summarize(final, GeoMean_mean = mean(GeoMean), GeoMean_med = median(GeoMean))
    final$WSA_9 = master_table$WSA_9[match(final$COMID, master_table$COMID)]
  }
  if (i> 1){
    temp = group_by(travel,COMID)
    temp = summarize(temp, GeoMean_mean = mean(GeoMean), GeoMean_med = median(GeoMean))
    temp$WSA_9 = master_table$WSA_9[match(temp$COMID, master_table$COMID)]
    final = rbind(final, temp)
  }
}
master_table$GeoMean_mean = final$GeoMean_mean[match(master_table$COMID, final$COMID)]
master_table$GeoMean_med = final$GeoMean_med[match(master_table$COMID, final$COMID)]
write.csv(master_table, paste0(cat_path, 'Mannings.csv'), row.names=F)



```    


