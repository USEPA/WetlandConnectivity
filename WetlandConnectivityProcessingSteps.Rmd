---
title: "Wetland Connectivity Processing Steps"
author: "Marc Weber & Ryan Hill"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    theme: yeti
    highlighted: default 
    toc: yes
---

The following steps lay out the approach to generate wetland flow paths and calculate wetland hydrological connectivity at a national level

## Wetland extraction and preparation

### Derive NLCD 2001 or 2011 based wetlands
1. Extract wetland cells from NLCD 2011 raster
2. Use Arc region group tool to define contiguous wetland cells and assign a unique ID
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
# Import arcpy module
# Import arcpy module
import arcpy
import os
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env

# Set variables
nhddir = "L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/HYDROLOGY/NHDPlusV21"
year = '2001'
wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD'+year+'/AllWetlands/'
out_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD'+year+'/AllWetlands_rpu/'
Wetlands = Raster(wetlands_dir + "Wetlands.tif")

# for 2011
# nlcd = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/nlcd2011.tif'
# for 2001
nlcd = 'L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/LAND_COVER/NLCD/nlcd_2001_landcover_2011_edition_2014_10_10/nlcd_2001_landcover_2011_edition_2014_10_10.img'


# Derive NLCD based wetlands
#NLCD = Raster(nlcd)
#wetlands = Con((NLCD == 90) | (NLCD == 95), 1,)
#if not arcpy.Exists(wetlands_dir + "/Wetlands" + ".tif"):
#    wetlands.save(wetlands_dir + "/Wetlands.tif")

# Now create unique wetland groups of contiguous wetland cells
inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
         'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

i = 1
for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]
                #print i
                fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                arcpy.env.snapRaster = fdr
                arcpy.env.cellSize = "30"
                arcpy.env.mask = fdr
                arcpy.env.extent = fdr
                arcpy.env.compression = 'LZW'
                WetlandRegions = RegionGroup(Wetlands, "EIGHT", "WITHIN", "NO_LINK", "")
                if i ==1:                    
                    WetlandRegions.save(out_dir + 'WetlandsRgnGrp_'+rpu+'.tif')
                else:
                    WetlandRegions = WetlandRegions + maxval
                    WetlandRegions.save(out_dir + 'WetlandsRgnGrp_'+rpu+'.tif')
                maxval = arcpy.GetRasterProperties_management(WetlandRegions, "MAXIMUM").getOutput(0)
                maxval = int(maxval)
                i = i + 1   
```

### Create NLCD year specific full stream rasters (i.e. full streams for NLCD 2001 and NLCD 2011)
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
# Import arcpy module
import arcpy
import os
from arcpy.sa import *
# Check out any necessary licenses
arcpy.CheckOutExtension("spatial")
import numpy as np
import numpy.ma as ma
from osgeo import gdal
import osr
import geopandas as gpd
import fiona
import rasterio
from rasterio import features
arcpy.env.overwriteOutput = True

# Local variables:
working_dir = 'H:/WorkingData/wetlandjunk'
NHDDir = "H:/NHDPlusV21"
Year = '2001'
FullStreamsDir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + Year + '/FullStreams'
Mosaics_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask/Mosaics'
def array2raster(newRasterfn,rasterfn,array):
    geotransform = rasterfn.GetGeoTransform()
    originX = geotransform[0]
    originY = geotransform[3]
    pixelWidth = geotransform[1]
    pixelHeight = geotransform[5]
    cols = array.shape[1]
    rows = array.shape[0]

    driver = gdal.GetDriverByName('GTiff')
    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Byte)
    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))
    outband = outRaster.GetRasterBand(1)
    outband.WriteArray(array)
    outRasterSRS = osr.SpatialReference()
    outRasterSRS.ImportFromWkt(rasterfn.GetProjectionRef())
    outRaster.SetProjection(outRasterSRS.ExportToWkt())
    outband.FlushCache()

def records(filename, usecols, **kwargs):
    with fiona.open(filename, **kwargs) as source:
        for feature in source:
            f = {k: feature[k] for k in ['id', 'geometry']}
            f['properties'] = {k: feature['properties'][k] for k in usecols}
            yield f

def getRows(fn, idxList):
    reader = fiona.open(fn)
    return gpd.GeoDataFrame.from_features([reader[x] for x in idxList])
            
# Pull out NALCMS Water to use in creating mask
# Pull out NLCD Water to use in creating mask
if not arcpy.Exists(FullStreamsDir + '/NLCD_Water.tif'):
    if Year=='2001':
        nlcd = Raster('L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/LAND_COVER/NLCD/nlcd_2001_landcover_2011_edition_2014_10_10/nlcd_2001_landcover_2011_edition_2014_10_10.img')
    if Year=='2011':    
        nlcd = Raster('L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/nlcd2011.tif')
    NLCDWat = Con(nlcd ==11 ,1)
    NLCDWat.save(FullStreamsDir + '/NLCD_Water.tif')
    

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
for regions in inputs.keys():
    for hydro in inputs[regions]:
        print 'on region ' + regions + ' and hydro number ' + hydro
        hydrodir = "%s/NHDPlus%s/NHDPlus%s"%(NHDDir,regions, hydro)
        for subdirs in os.listdir(hydrodir):
            if subdirs.count("FdrNull") and not subdirs.count('.txt') and not subdirs.count('.7z'):
                print 'working on ' + subdirs
                
                # Read in the fdr null raster for hydroregion
                fdrnull = "%s/%s/fdrnull"%(hydrodir, subdirs)
                dsc=arcpy.Describe(fdrnull)
                arcpy.env.extent=dsc.Extent
                ext=dsc.Extent
                ll = arcpy.Point(ext.XMin, ext.YMin)
                arcpy.env.outputCoordinateSystem=dsc.SpatialReference
                arcpy.env.cellSize=dsc.meanCellWidth
                fdr = "%s/%s/fdr"%(hydrodir, subdirs.replace('Null','Fac'))
                arcpy.env.mask = fdr 
                
                
#            cat = NHDDir + "/NHDPlus" + regions + "/NHDPlus" + hydro + "/NHDPlusCatchment/cat"
                flowline = NHDDir + "/NHDPlus" + regions + "/NHDPlus" + hydro + "/NHDSnapshot/Hydrography/NHDFlowline.shp"
                flowgrid = Mosaics_dir + '/flowgrid' + hydro
                if not arcpy.Exists(flowgrid):
                    flowline_sp = gpd.read_file(flowline)
                    flowline_sp = flowline_sp.loc[(flowline_sp['FTYPE'].isin([ 'ArtificialPath', 'Connector', 'StreamRiver'])) | (flowline_sp['FLOWDIR'] == 'With Digitized')]
                    
                    flowline_sp['Junk'] = 1
                    rst = rasterio.open(fdr)
                    if flowline_sp.crs != rst.crs:
                        flowline_sp = flowline_sp.to_crs(rst.crs)
                    meta = rst.meta.copy()
                    meta.update(compress='lzw')
                    with rasterio.open(flowgrid, 'w', **meta) as out:
                        out_arr = out.read(1)
                        # this is where we create a generator of geom, value pairs to use in rasterizing
                        shapes = ((geom,value) for geom, value in zip(flowline_sp.geometry, flowline_sp.Junk))
                        
                        burned = features.rasterize(shapes=shapes, fill=0, out=out_arr, transform=out.transform)
                        out.write_band(1, burned)
                    
                StrmRas = Raster(Mosaics_dir + '/flowgrid' + hydro )
                # Process: Region Group - this gives each group of contiguous pixels a unique region ID
                NLCDWat = Raster(FullStreamsDir + '/NLCD_Water.tif')
                RegGrp = working_dir + '/RegionGroup_' + subdirs.split('Null',2)[1] + '.tif'
                if not arcpy.Exists(RegionGroup):
                    outRegGrp = RegionGroup(NLCDWat, "EIGHT", "WITHIN", "NO_LINK", "")
                    # Save the output 
                    outRegGrp.save(RegGrp)
                                                
                # Now multiply the region group raster by the stream raster
                RgnGrp = Raster(RegGrp)
                OutTimes = Times(StrmRas,RgnGrp)
                if not arcpy.Exists(working_dir + '/OutTimes_' + subdirs.split('Null',2)[1] + '.tif'):
                    OutTimes.save(working_dir + '/OutTimes_' + subdirs.split('Null',2)[1] + '.tif')
                if not arcpy.Exists(FullStreamsDir + '/WaterMask_' + subdirs.split('Null',2)[1] + '.tif'):
                    # Convert Rasters to numpy arrays
                    OutTimes = gdal.Open(working_dir + '/OutTimes_' + subdirs.split('Null',2)[1] + '.tif')
                    OutTimes_arr = np.array(OutTimes.GetRasterBand(1).ReadAsArray())
                    RgnGrp = gdal.Open(working_dir + '/RegionGroup_' + subdirs.split('Null',2)[1] + '.tif')
                    RgnGrp_arr = np.array(RgnGrp.GetRasterBand(1).ReadAsArray())
                    #OutTimes_arr = arcpy.RasterToNumPyArray('%s/OutTimes_%s.tif'%(working_dir,subdirs.split('Null',2)[1]))
                    #RgnGrp_arr = arcpy.RasterToNumPyArray('%s/RegionGroup_%s.tif'%(working_dir,subdirs.split('Null',2)[1]))
                        
                    unq = np.unique(OutTimes_arr) #Get unique values for query
                    unq = unq[1:] #The first member of the vector will be -32768. Let's us set new grid == 1 (see line 62)
                    #This is what the vector looked like before removing the first element:
                    #unq
                    #Out[46]: array([-32768,      3,      7, ...,   2462,   2464,   2466], dtype=int16)
                    
                    RgnGrp_arr = RgnGrp_arr.flatten() #Flatten 2d array to 1d
                    z = np.where(np.in1d(RgnGrp_arr, unq), 1, np.NaN)
                    #z = np.where(np.in1d(RgnGrp_arr, unq), RgnGrp_arr, np.NaN) #Make NaN where no match
                    #z[z==-32768] = np.NaN #Brings in big neg number when read into Python. Turn to NaN
                    z.shape = OutTimes_arr.shape #Reshape back to 2d
                    
                    #newRaster = arcpy.NumPyArrayToRaster(z, ll, dsc.meanCellWidth, dsc.meanCellHeight) #Make ESRI raster
                    newraster= array2raster(working_dir + '/OutTimesV2_' + subdirs.split('Null',2)[1] + '.tif', OutTimes, z)
                    newRaster = Raster(working_dir + '/OutTimesV2_' + subdirs.split('Null',2)[1] + '.tif')
                    WaterMask = Con(newRaster == 1, 1) #run it through a process to get it to be integer and in native ESRI format (exclude odd NUMPY stuff)                
                    WaterMask.save(FullStreamsDir + '/WaterMask_' + subdirs.split('Null',2)[1] + '.tif')
                if not arcpy.Exists(FullStreamsDir + '/FullStreams_' + subdirs.split('Null',2)[1] + '.tif'):
                    WaterMask = Raster(FullStreamsDir + '/WaterMask_' + subdirs.split('Null',2)[1] + '.tif')
                    StrmRas = Con(IsNull(StrmRas),0,1)
                    WaterMask = Con(IsNull(WaterMask),0,1)
                    FullStreams = StrmRas + WaterMask
                    FullStreams = Con(FullStreams >= 1, 1,)
                    FullStreams.save(FullStreamsDir + '/FullStreams_' + subdirs.split('Null',2)[1] + '.tif')
                if not arcpy.Exists(FullStreamsDir + '/FullStreamsFDRNull' + subdirs.split('Null',2)[1] + '.tif'):
                    FullStreams = Raster(FullStreamsDir + '/FullStreams_' + subdirs.split('Null',2)[1] + '.tif')
                    FDR_Ras = Raster("%s/%s/fdr"%(hydrodir, subdirs.replace('Null','Fac')))
                    FullStreams = Con(IsNull(FullStreams),0)
                    FDRNull = FullStreams + FDR_Ras
                    FDRNull.save(FullStreamsDir + '/FullStreamsFDRNull' + subdirs.split('Null',2)[1] + '.tif')
```

### WE'RE NOT USING THIS NEXT CHUNK IN CURRENT PROCESS!!! ###
### Use Full Streams to test if wetlands are isolated from stream network 
1. Build VAT for wetland raster
2. Set non-null values in fdrnull raster = 1
3. Multiply rasters and build VAT of output of (2)
4. Compare counts of regions in VATS 
5. Save isolated wetlands
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}

import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")
from collections import deque, defaultdict
import pysal as ps
import pandas as pd
import numpy as np
import numpy.ma as ma
from osgeo import gdal
import osr

arcpy.env.overwriteOutput = True

def array2raster(newRasterfn,rasterfn,array):
    geotransform = rasterfn.GetGeoTransform()
    originX = geotransform[0]
    originY = geotransform[3]
    pixelWidth = geotransform[1]
    pixelHeight = geotransform[5]
    cols = array.shape[1]
    rows = array.shape[0]

    driver = gdal.GetDriverByName('GTiff')
    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Byte)
    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))
    outband = outRaster.GetRasterBand(1)
    outband.WriteArray(array)
    outRasterSRS = osr.SpatialReference()
    outRasterSRS.ImportFromWkt(rasterfn.GetProjectionRef())
    outRaster.SetProjection(outRasterSRS.ExportToWkt())
    outband.FlushCache()

def dbf2DF(dbfile, upper=True):
    db = ps.open(dbfile)
    cols = {col: db.by_col(col) for col in db.header}
    db.close()  #Close dbf 
    pandasDF = pd.DataFrame(cols)
    if upper == True:
        pandasDF.columns = pandasDF.columns.str.upper()              
    return pandasDF


# nhddir = 'L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/HYDROLOGY/NHDPlusV
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
# working_dir = 'D:/WorkFolder/WetConnect_Aug2016'
# NLCD 2011
# wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands'
# wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands_rpu'
# watermask_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'
# isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/IsolatedWetlands'
# NLCD 2001
wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands'
wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands_rpu'
watermask_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/IsolatedWetlands'
arcpy.env.workspace = working_dir + '/garbage3'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
         'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
# inputs = {'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}           

for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]

                if not os.path.exists(isolated_dir + '/isoWetlands_' + rpu + '.tif'):                     
                    print rpu
                        #-- thanks ESRI --
                    garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
                    if not os.path.exists(garbage):
                        os.makedirs(garbage)
                    arcpy.env.workspace = garbage
                        #-- thanks ESRI --
                    startTime = time.time()  
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                        # Set env                
                    arcpy.env.snapRaster = fdr
                    arcpy.env.cellSize = "30"
                    arcpy.env.mask = fdr
                    arcpy.env.extent = fdr
                    # Get full streams              
                    fullstreams = Raster(watermask_dir +"/FullStreams"  + rpu + ".tif")
                    stream_expand = Expand(fullstreams, 1, 1) #Expand by 1 pixel to find wetlands that are disconnect by at least 1 pixel                
                    streamcon = Con(IsNull(stream_expand), 1, 0) #Set null pixels to zero, else stay the same                             
                    wetland_all = Raster(wetlands_dir + '/WetlandsRgnGrp.tif')
                    outWet_rpu = wetrpu_dir + '/Wetlands_' + rpu + '.tif'
                    # Make wetland for each RPU 
                    if not arcpy.Exists(outWet_rpu):
                        wetland_rpu = ExtractByMask(wetland_all, fdr)
                        wetland_rpu.save(outWet_rpu) 
                    #arcpy.gp.ExtractByMask_sa(wetland_all, fdr, outWet_rpu)
                    arcpy.BuildRasterAttributeTable_management(outWet_rpu, "Overwrite")
                    wetland = Raster(outWet_rpu)
                    wetcon = Con(IsNull(wetland),0, wetland)
                    # Multiply to create temporary query wetland
                    tmpWet = streamcon * wetcon
                    if not arcpy.Exists(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif'):
                        tmpWet.save(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif')
                    arcpy.BuildRasterAttributeTable_management(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif', "Overwrite")
                        # Read in and merge VATs to compare 
                    lesswet = dbf2DF(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif.vat.dbf')
                    allwet = dbf2DF(outWet_rpu + '.vat.dbf')
                    new = pd.merge(allwet, lesswet, on = 'VALUE', how = 'left')                
                    isolated = new.loc[new['COUNT_x'] == new['COUNT_y']]
                    isolated = np.array(isolated.VALUE).astype(int)
                        # Read in wetland raster, convert to numpy array, flatten, and query against list of isolated wetlands
                    wetland_ras = gdal.Open(outWet_rpu)
                    wetland_arr = np.array(wetland_ras.GetRasterBand(1).ReadAsArray())                
                    wetshape = wetland_arr.shape                               
                    wetland_flat = wetland_arr.flatten() #Flatten 2d array to 1d
                    z = np.where(np.in1d(wetland_flat, isolated), 1, np.NaN)
                    z.shape = wetshape             
                        # Stuff to get it out to TIF ESRI can see
                    newraster = array2raster(working_dir + '/ScratchDir/isoWetTmp_' + rpu + '.tif', wetland_ras, z)
                    newRaster = Raster(working_dir + '/ScratchDir/isoWetTmp_' + rpu + '.tif')
                    newRaster2 = Times(wetland_rpu, newRaster) #run it through a process to get it to be integer and in native ESRI format (exclude odd NUMPY stuff)    
                    newRaster3 = Con(newRaster2 != 0, newRaster2)
                    newRaster3.save(isolated_dir + '/isoWetlands_' + rpu + '.tif')              
                    print "Minutes for this region: " + str((time.time()-startTime) / 60.0)                          

```


### Generate wetland points for each wetland group
1. Generate points for each raster cell in wetland groups
2. Use geopandas to select just the point in each group with largest flow accumulation (the wetland outlet)
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import arcpy
import os
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env
import georasters as gr
import geopandas as gp
import pandas as pd
wetcatfunc = 'J:/GitProjects/Wetland Connectivity/WetlandScripts'
sys.path.append(wetcatfunc)  
from WetCat_functions import GetRasterValueAtPoints
from datetime import datetime

nhddir = "L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/HYDROLOGY/NHDPlusV21"
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
#working_dir = 'D:/WorkFolder/WetConnect_Aug2016'
year = '2001'
wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/AllWetlands_rpu'
watermask_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/FullStreams'
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/IsolatedWetlands'
wetpoints_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandPoints'


inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

for region in inputs.keys():
    for hydro in inputs[region]:
        print 'on region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                if not arcpy.Exists(wetpoints_dir + "/WetlandPoints" + dirs[-3:]+ ".shp"):
                    print dirs
                    # Execute ExtractValuesToPoints to get flow accumulation for each wetland region grid point
                    fac = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + dirs[-3:] + "/fac")
                    arcpy.env.snapRaster = fac
                    arcpy.env.mask = fac
                    arcpy.env.extent = fac.extent
                    # Raster to points
                    outPoint = working_dir + "/ScratchDir/RasterPoints" + dirs[-3:] + ".shp"
                    # Execute RasterToPoint - do for both iso and all wetlands!
                    # Wetlands = isolated_dir + "/isoWetlands_" + dirs[-3:] + ".tif"
                    Wetlands = wetrpu_dir + "/WetlandsRgnGrp_" + dirs[-3:] + ".tif"
                    if not arcpy.Exists(outPoint):
                        arcpy.RasterToPoint_conversion(Wetlands, outPoint, "VALUE")
                    
                    outPointFac = working_dir + "/ScratchDir/PointFac" + dirs[-3:] +  ".shp"
                    if not arcpy.Exists(outPointFac):
                        ExtractValuesToPoints(outPoint, fac, outPointFac,"", "ALL")
                    
                    # Process: Make Feature Layer
                    arcpy.MakeFeatureLayer_management(outPointFac, "FacPoints")
                    
                    # Process: Make Feature Layer
                    BoundaryUnits = nhddir + "/NHDPlusGlobalData/BoundaryUnit.shp"
                    arcpy.MakeFeatureLayer_management(BoundaryUnits, "BoundaryUnit", "\"UnitID\" = '%s'"%(dirs[-3:]))
                    
#                    # Process: Select Layer By Location
#                    arcpy.SelectLayerByLocation_management("FacPoints", "INTERSECT", "BoundaryUnit", "", "NEW_SELECTION")
                    
                    # Process: Feature Class To Shapefile (multiple)
                    arcpy.FeatureClassToShapefile_conversion("FacPoints", working_dir + "/ScratchDir")
                    
                    # Use Pandas to get the minimum flow distance point for each wetland region group ID
                    WetPoints = gp.GeoDataFrame.from_file(working_dir + "/ScratchDir/FacPoints.shp")
                    # First we'll drop all the -999 sites - these are wetland grid cells in the stream
                    WetPoints = WetPoints.loc[WetPoints.RASTERVALU!=-9999]
                    # Now we'll group points by wetland region group maximum flow accumulation
                    WetPoints = WetPoints.loc[WetPoints.groupby("GRID_CODE")["RASTERVALU"].idxmax()]
                    # And then we'll export to a text file after grabbing coordinates as fields we add
                    df = WetPoints.drop('geometry', axis=1)  # df is a DataFrame, not GeoDataFrame after the drop
                    def getXY(pt):
                        return (pt.x, pt.y)
                    centroidseries = WetPoints['geometry'].centroid
                    x,y = [list(t) for t in zip(*map(getXY, centroidseries))]
                    WetPoints['XCOORD'] = x
                    WetPoints['YCOORD'] = y
                    if not arcpy.Exists(wetpoints_dir + "/WetlandPoints" + dirs[-3:] +".shp"):
                        WetPoints.to_file(wetpoints_dir + "/WetlandPoints" + dirs[-3:]+ ".shp", driver = 'ESRI Shapefile')
                    df['XCOORD'] = x
                    df['YCOORD'] = y
                    df.head()
                    #df[x] = WetPoints.geometry.apply(lambda p: p.x)
                    #df[y] = WetPoints.geometry.apply(lambda p: p.y)
                    
                    df.to_csv(wetpoints_dir +"/WetlandPoints" + dirs[-3:] + ".csv")
                    
                    WetPoints = wetpoints_dir + "/WetlandPoints" + dirs[-3:] + ".shp"  
                    
                    arcpy.Delete_management(outPoint)
                    arcpy.Delete_management(outPointFac)
                    arcpy.Delete_management("FacPoints")
                    arcpy.Delete_management(working_dir + "/ScratchDir/FacPoints.shp") 

  
```  

## Wetland path processes

### Generate Cost Paths from each wetland outlet point to NHDPlus stream lines for each NLCD year
1. Create a full streams null grid to use in cost path analysis
2. Run cost path tool using wetland outlet points, NHDPlus hydro DEM, and full streams null grid
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import arcpy
import os
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env
from datetime import datetime
import geopandas as gpd

nhddir = 'L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/HYDROLOGY/NHDPlusV21'
working_dir = 'F:/WetlandConnectivity/SpatialData'
#working_dir = 'D:/WorkFolder/WetConnect_Aug2016'
year = 2001
watermask_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'
fullstreams_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/FullStreams'
# NLCD2011
wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/AllWetlands'
wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/AllWetlands_rpu'
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/IsolatedWetlands'
paths_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandPath/CostPaths'
wetpoints_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandPoints'


inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
         'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}


for region in inputs.keys():
    for hydro in inputs[region]:
        print 'on region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                print dirs
                rpu = dirs[-3:]
                fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                arcpy.env.snapRaster = fdr
                arcpy.env.cellSize = "30"
                arcpy.env.mask = fdr
                arcpy.env.extent = fdr
                WetPoints = wetpoints_dir + "/WetlandPoints" + rpu + ".shp" 
                # Create Full cost path raster - first, we'll geneerate a fullstreamsnull grid to pass to cost path tool
                FullStreams = Raster(fullstreams_dir + '/FullStreams' + rpu + '.tif')
                Fullstreamsnull = fullstreams_dir + "/FullStreamsFDRNull" + rpu + ".tif"
                if not arcpy.Exists(paths_dir + '/CostPath' + rpu + '.tif'):
                    outCostPath = CostPath(WetPoints, nhddir + "/NHDPlus" + region + "/NHDPlus" + hydro + "/NHDPlusHydrodem" + rpu + "/hydrodem",Fullstreamsnull, "EACH_CELL", "GRID_CODE")
                    outCostPath.save(paths_dir + '/CostPath' + rpu + '.tif')
                
                if not arcpy.Exists(working_dir + "/ScratchDir/RasterPoints" + rpu + ".tif"):
                    wetpoints = gpd.GeoDataFrame.from_file(WetPoints)
                    wetpoints["junk"] = 1
                    wetpoints.to_file(working_dir + "/ScratchDir/WetPoints" + rpu + ".shp", driver = 'ESRI Shapefile') 
                    # Now convert polylines back to a raster
                    arcpy.FeatureToRaster_conversion(in_features=working_dir + "/ScratchDir/WetPoints" + rpu + ".shp", field="junk", out_raster= working_dir + "/ScratchDir/RasterPoints" + rpu + ".tif", cell_size="30")
                 
                if not arcpy.Exists(working_dir + "/ScratchDir/RasterPointsExpand" + rpu + ".tif"):
                    # Expand the rasterized wetlands points
                    Points = Raster(working_dir + "/ScratchDir/RasterPoints" + rpu + ".tif")
                    Points = Con(Points >= 1, 1,)
                    outExpand = Expand(Points, 1, 1)
                    outExpand.save(working_dir + "/ScratchDir/RasterPointsExpand" + rpu + ".tif")
                if not arcpy.Exists(working_dir + "/ScratchDir/ExpandCost" + rpu + ".tif"):
                    # Mosaic expanded points raster and cost path raster set to 1
                    input1 = Raster(working_dir + "/ScratchDir/RasterPointsExpand" + rpu + ".tif")
                    input1 = Con(IsNull(input1),0,input1)
                    input2 = Raster(paths_dir + "/CostPath" + rpu + ".tif")
                    input2 = Con(IsNull(input2), 0, 1)
                    cost = Raster(paths_dir + '/CostPath' + rpu + '.tif')
#                    arcpy.env.mask = cost
#                    arcpy.env.snapRaster = cost
                    output = input1 + input2
                    output2 = Con(output>=1,1)
                    output2.save(working_dir + "/ScratchDir/ExpandCost" + rpu + ".tif")
                if not arcpy.Exists(paths_dir + "/StreamLinkExp" + rpu + ".tif"):
                    # Run stream link on the cost path to 'uniqueify' the sections
                    # Execute StreamLink
                    arcpy.gp.StreamLink_sa(working_dir + "/ScratchDir/ExpandCost" + rpu + ".tif", fdr, paths_dir + "/StreamLinkExp" + rpu + ".tif")                
```

### Find duplicated PathIDs in StreamLink rasters from previous step
```{r, eval=F}
library(raster)
library(rgdal)
library(stringr)
library(foreign)
require(dplyr)

year = '2001'
path_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/CostPaths')
points_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPoints')
accum_path = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/Accumulation/')
  
path_list = list.files(path_dir, pattern = "StreamLinkExp")
path_list = path_list[grep('\\.tif$',path_list)]

for (i in 1:length(path_list)){
  print(path_list[i])
  outfile = paste0(path_dir, '/duplicated_', substr(path_list[i], 14, 16),'.csv')
  if(!file.exists(outfile)){
    if(file.exists(paste0(path_dir,'/',path_list[i]))){
      streamlink_ras = raster(paste0(path_dir,'/',path_list[i]))
      wetpoint = readOGR(points_dir, paste0('WetlandPoints', substr(path_list[i], 14, 16)))
      results = extract(streamlink_ras, wetpoint)
      wetpoint$duplicated =  results  
      tmp = wetpoint@data
      head(tmp)
      tmp = subset(tmp, select = c(duplicated))
      tmp = tmp[duplicated(tmp$duplicated),]
      tmp = unique(tmp)
      tmp = tmp[!is.na(tmp)]
      tmp = data.frame(duplicated = tmp)
      print(nrow(tmp))
      write.csv(tmp, file = outfile, row.names=F)
    }
  }
}
```

### Fix duplicated PathIDs in StreamLink rasters
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import os
import arcpy
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env
import pandas as pd
import numpy as np
import gdal
import osr
import time

def array2raster(newRasterfn,rasterfn,array):
    geotransform = rasterfn.GetGeoTransform()
    originX = geotransform[0]
    originY = geotransform[3]
    pixelWidth = geotransform[1]
    pixelHeight = geotransform[5]
    cols = array.shape[1]
    rows = array.shape[0]

    driver = gdal.GetDriverByName('GTiff')
    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Int32, ['COMPRESS=LZW'])
    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))
    outband = outRaster.GetRasterBand(1)
    outband.SetNoDataValue(-2147483647.0)
    outband.WriteArray(array)
    outRasterSRS = osr.SpatialReference()
    outRasterSRS.ImportFromWkt(rasterfn.GetProjectionRef())
    outRaster.SetProjection(outRasterSRS.ExportToWkt())
    outband.FlushCache()
    
arcpy.env.compression = 'LZW'

year = '2011'
# Set local working directory
#working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData/ScratchDir/'
working_dir = 'D:/WorkFolder/WetConnect_Nov2016/ScratchDir/'

wetpt_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD'+year+'/WetlandPoints/'
cost_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandPath/CostPaths/'
files = filter(lambda x: x.endswith(('.tif')) and x.count(('StreamLinkExp')), os.listdir(cost_dir))

#Set inputs - will want to make loopable
for in_strlink in files: 
    t1 = time.time()
    #Set names and paths for files    
    inRaster = cost_dir + in_strlink
    outRas = cost_dir + 'StreamLink_' + in_strlink[13:]  
    in_dup = cost_dir + 'duplicated_' + in_strlink[13:16] + '.csv'
    column = 'duplicated'
    #Read in files 
    dup = pd.read_csv(in_dup)
    dup = np.array(dup[column])
    #dup = dup[~np.isnan(dup)]
    #dup = np.unique(dup)
    if not arcpy.Exists(outRas):
        #Check to see if values need to be replaced in the raster
        if len(dup) > 0:  
            print '---Processing: '+in_strlink+'---'
            inRas = gdal.Open(inRaster)
            rst = np.array(inRas.GetRasterBand(1).ReadAsArray())
            shp = rst.shape #Get initial shape of rst
            rst = rst.flatten() #flatten rst
            query1 = np.in1d(rst, dup) #Find duped cells in rst (boolean vector)
            #Define start and end of sequence that will replace these values
            start = np.max(rst) + 1
            end = start + np.sum(query1)
            sequence = np.arange(start,end, 1)
         
            #Replace rst values with sequence values where boolean == True
            #Much faster than the loop if it will run
    #        np.place(rst, query1, sequence) #This code kept crashing python
            
            #Break array into 10 parts   - don't need if np.place works 
            splits = np.array_split(rst, 10)  
            x = 0
            for i, split in enumerate(splits):
                query_i = np.in1d(splits[i], dup)#Find boolean of need replace 
                if np.sum(query_i) > 0:
                    splitseq = sequence[x:x + np.sum(query_i)]#Split seq vector
                    np.place(splits[i], query_i, splitseq)#Replace values with seq   
                if i == 0:
                    rst = splits[i]
                else:
                    rst = np.append(rst, splits[i])
                x = x + np.sum(query_i)
            #Reshape and write out raster
            rst.shape = shp
        else:
            #Still need to read raster in to mask even if no values replaced
            inRas = gdal.Open(inRaster)
            rst = np.array(inRas.GetRasterBand(1).ReadAsArray())
        
        
        tempraster = working_dir + 'streamlinkfixed' + in_strlink[13:16] + '.tif'            
        newraster = array2raster(tempraster, inRas, rst)
        
        cost = Raster(cost_dir + '/CostPath' + in_strlink[13:16] + '.tif')
        arcpy.env.mask = cost
        arcpy.env.snapRaster = cost
                
        tmp_link = Raster(tempraster)
        tmp_link = Con(tmp_link > -9999, tmp_link)
        tmp_link.save(outRas)
        #arcpy.CopyRaster_management(tempraster, outRas, "", "", "", "", "", "32_BIT_SIGNED")
        print '---Minutes to process: '+str((time.time() - t1)/60)+'---' 
```

### Create flow path connections (from-to tables)
1. Shift the catchment in each of the 8 neighboring directions
2. Check each neighboring cell following conditions:
    * Does the cell have a different catchment ID as neighbor?
    * Does it flow into the neighboring cell?
3. If 'yes' to both questions, then connect in topology table
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}

# Import arcpy module
import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")
from datetime import datetime
import struct, decimal, itertools

arcpy.env.overwriteOutput = True
nhddir = 'H:/NHDPlusV21'
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
year = '2001'
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/IsolatedWetlands'
paths_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandPath/CostPaths'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandPath/FlowTables'


inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
# inputs = {'GL':['04']}          
for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]
                # Check to see if wetland paths from to exist already
                outDbf = frmto_dir + "/WetlandFrmTo" + rpu + ".dbf"
                outtif = frmto_dir + "/WetlandFrmTo" + rpu + ".tif"
                if not os.path.exists(outDbf):
                        #-- Create garbage cans --
                    garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
                    if not os.path.exists(garbage):
                        os.makedirs(garbage)
                    arcpy.env.workspace = garbage
                        #-- Delete garbage after run --
                    startTime = time.time()
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                    arcpy.env.snapRaster = fdr
                    description = arcpy.Describe(fdr)  
                    cellsize = description.children[0].meanCellHeight 
                    arcpy.env.cellSize = cellsize
                    arcpy.env.mask = fdr
                    arcpy.env.extent = fdr
                    print "Shifting region: " + rpu
                    Paths = Raster(paths_dir + '/StreamLink_' + rpu + '.tif')     
                    shift1 = arcpy.Shift_management(Paths, "shift1.tif", "-%s"%(cellsize), "0", Paths)
                    shift2 = arcpy.Shift_management(Paths, "shift2.tif", "-%s"%(cellsize), "%s"%(cellsize), Paths)
                    shift4 = arcpy.Shift_management(Paths, "shift4.tif", "0", "%s"%(cellsize), Paths)
                    shift8 = arcpy.Shift_management(Paths, "shift8.tif", "%s"%(cellsize), "%s"%(cellsize), Paths)
                    shift16 = arcpy.Shift_management(Paths, "shift16.tif", "%s"%(cellsize), "0", Paths)
                    shift32 = arcpy.Shift_management(Paths, "shift32.tif", "%s"%(cellsize), "-%s"%(cellsize), Paths)
                    shift64 = arcpy.Shift_management(Paths, "shift64.tif", "0", "-%s"%(cellsize), Paths)
                    shift128 = arcpy.Shift_management(Paths, "shift128.tif", "-%s"%(cellsize), "-%s"%(cellsize), Paths)  
                    print "Minutes to shift this region: " + str((time.time()-startTime) / 60.0) 
                    
                    # Process: Raster Calculator                    
                    print 'Creating from-to connections'
                    startTime = time.time() 
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                    flowto1 = ((shift1 != Paths) * (fdr == 1)) * shift1
                    flowto1.save("FlowTo1.tif")
                    flowto1 = Raster("FlowTo1.tif")
                    flowto1 = Con(IsNull(flowto1),0,flowto1)
                    
                    flowto2 = ((shift2 != Paths) * (fdr == 2)) * shift2
                    flowto2.save("FlowTo2.tif")
                    flowto2 = Raster("FlowTo2.tif")
                    flowto2 = Con(IsNull(flowto2),0,flowto2)
                    
                    flowto4 = ((shift4 != Paths) * (fdr == 4)) * shift4
                    flowto4.save("FlowTo4.tif")
                    flowto4 = Raster("FlowTo4.tif")
                    flowto4 = Con(IsNull(flowto4),0,flowto4)
                    
                    flowto8 = ((shift8 != Paths) * (fdr == 8)) * shift8
                    flowto8.save("FlowTo8.tif")
                    flowto8 = Raster("FlowTo8.tif")
                    flowto8 = Con(IsNull(flowto8),0,flowto8)
                    
                    flowto16 = ((shift16 != Paths) * (fdr == 16)) * shift16
                    flowto16.save("FlowTo16.tif")
                    flowto16 = Raster("FlowTo16.tif")
                    flowto16 = Con(IsNull(flowto16),0,flowto16)
                    
                    flowto32 = ((shift32 != Paths) * (fdr == 32)) * shift32
                    flowto32.save("FlowTo32.tif")
                    flowto32 = Raster("FlowTo32.tif")
                    flowto32 = Con(IsNull(flowto32),0,flowto32)
                    
                    flowto64 = ((shift64 != Paths) * (fdr == 64)) * shift64
                    flowto64.save("FlowTo64.tif")
                    flowto64 = Raster("FlowTo64.tif")
                    flowto64 = Con(IsNull(flowto64),0,flowto64)
                    
                    flowto128 = ((shift128 != Paths) * (fdr == 128)) * shift128
                    flowto128.save("FlowTo128.tif")
                    flowto128 = Raster("FlowTo128.tif")
                    flowto128 = Con(IsNull(flowto128),0,flowto128)
                    
                    FlowToSum = flowto1 + flowto2 + flowto4 + flowto8 + flowto16 + flowto32 + flowto64 + flowto128
                    FlowToSum.save("FlowToSum.tif")
                    FlowToSum = Raster("FlowToSum.tif")
                    FlowToFinal = Con(FlowToSum != 0, FlowToSum)
                    FlowToFinal.save("FlowToFinal.tif")
                    
                    outCombine = Combine([FlowToFinal, Paths])
                    outCombine.save(outtif)

                    if not arcpy.Exists(outDbf):
                        arcpy.CopyRows_management(outCombine, outDbf, "")
                    print "Minutes to connect flowpaths in this region: " + str((time.time()-startTime) / 60.0) 
                    
                    try:
                        arcpy.Delete_management("FlowTo1.tif")
                        arcpy.Delete_management("FlowTo2.tif")
                        arcpy.Delete_management("FlowTo4.tif")
                        arcpy.Delete_management("FlowTo8.tif")
                        arcpy.Delete_management("FlowTo16.tif")
                        arcpy.Delete_management("FlowTo32.tif")
                        arcpy.Delete_management("FlowTo64.tif")
                        arcpy.Delete_management("FlowTo128.tif")
                        arcpy.Delete_management("shift1.tif")
                        arcpy.Delete_management("shift2.tif")
                        arcpy.Delete_management("shift4.tif")
                        arcpy.Delete_management("shift8.tif")
                        arcpy.Delete_management("shift16.tif")
                        arcpy.Delete_management("shift32.tif")
                        arcpy.Delete_management("shift64.tif")
                        arcpy.Delete_management("shift128.tif")
                        arcpy.Delete_management("FlowToSum.tif")
                        arcpy.Delete_management("FlowToFinal.tif")
                    except:
                        pass
```

### Create numpy files for accumulating wetland path results
1. Loops through from-to tables
2. Makes dictionary of next downstream path for each non-terminal wetland path
3. Runs bastards function to make full list of downstream flowpaths
4. Generates information such as length of each connection and saves results as 3 numpy vectors
    * comids<regionID>.npy - Vector of unique IDs for each wetland in region
    * lengths<regionID>.npy - Vector of the number of upstream catchments above each wetland. Children includes focal catchment, bastards excludes focal catchment
    * downPaths<regionID>.npy - Vector of the unique IDs of each downstream path for each focal path listed in order. 

```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import arcpy
import os, sys
import pysal as ps
import numpy as np
from collections import deque, defaultdict, OrderedDict
#Need to set to where WetCat_function.py is stored
wetcatfunc = 'J:/GitProjects/Wetland Connectivity/WetlandScripts'
sys.path.append(wetcatfunc)  
from WetCat_functions import dbf2DF, children, bastards

year = '2001'
numpy_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandPath/WetPaths_npy/'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandPath/FlowTables/'
Paths_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandPath/CostPaths/'


files = filter(lambda x: x.endswith(('.dbf')) and not x.count('.tif'), os.listdir(frmto_dir))

for file in files:
    rpu = file[-7:-4]
    print rpu

    #Read in wetland paths to get list of path IDs    
    wetpath = Paths_dir + 'StreamLink_' + rpu + '.tif'
    if not os.path.exists(wetpath + '.vat.dbf'):
        arcpy.BuildRasterAttributeTable_management(wetpath, "Overwrite")
    tbl = dbf2DF(wetpath + '.vat.dbf')
    PathIDs = tbl.VALUE.values      
    
    #Read in from-to table
    flow = dbf2DF(frmto_dir + file)[['FLOWTOFINA','STREAMLINK']] 
    #print flow.head()
    print "Processing region: " + rpu + " with total records = " + str(len(flow))
    flow.columns = ['TOCOMID','FROMCOMID'] #Rename columns
    fromID = np.array(flow.FROMCOMID) #Make numpy arrays of from and to columns
    toID = np.array(flow.TOCOMID)
    
    #Make dictionary of next up catchment ID
    DownIDs = defaultdict(list)
    for i in range(0, len(flow), 1):
        FROMID = fromID[i]
        TOID = toID[i]
        DownIDs[FROMID].append(TOID)                              
        
    #Make and save bastards
    a = map(lambda x: bastards(x, DownIDs), PathIDs) #Make bastards vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'bastards'):
        os.makedirs(numpy_dir + 'bastards')
    np.save(numpy_dir + 'bastards/downPaths' + rpu + '.npy', a)
    np.save(numpy_dir + 'bastards/PathIDs' + rpu + '.npy', PathIDs)
    np.save(numpy_dir + 'bastards/lengths' + rpu + '.npy', lengths)
    
    #Make and save children
    a = map(lambda x: children(x, DownIDs), PathIDs) #Make children vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'children'):
        os.makedirs(numpy_dir + 'children')
    np.save(numpy_dir + 'children/downPaths' + rpu + '.npy', a)
    np.save(numpy_dir + 'children/PathIDs' + rpu + '.npy', PathIDs)
    np.save(numpy_dir + 'children/lengths' + rpu + '.npy', lengths)    
```

### Create the flow length rasters for calculating flow distances

* Flow distances are based on DEMs and one set can be used for both 2001 and 2011

```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import arcpy
from arcpy import env
from arcpy.sa import *
arcpy.CheckOutExtension("spatial")

import os
import time

year = '2001'
path_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year +'/FullStreams'
out_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year +'/FlowLengthsDown/'

files = filter(lambda x: x.endswith(('.tif')) and x.count(('FDRNull')), os.listdir(path_dir))

for fdrnull in files:
    start_time = time.time() 
    print 'Processing: ' + fdrnull 
    outRas = out_dir+'fldown_'+fdrnull[18:]
    
    outFlowLength = FlowLength(path_dir+fdrnull, 'DOWNSTREAM','')
    outFlowLength.save(outRas)
    print("Duration: --- %s seconds ---" % (time.time() - start_time))
```

### Process rasters with wetland paths to produce continuous or categorical summaries
1. Open control table and access information to process each raster
2. Loop through RPUs
3. Based on raster type, use ArcGIS functions to create catchment summaries
    * Categorical - TabulateArea
    * Continuous - ZonalStatisticsAsTable
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import os
import arcpy
from arcpy.sa import TabulateArea, ZonalStatisticsAsTable
arcpy.CheckOutExtension("spatial")
import pandas as pd

#ctl_path = 'J:/GitProjects/Wetland Connectivity/WetlandScripts/'
ctl_path = 'D:/WorkFolder/WetConnect_Nov2016/Scripts/'
ctl = pd.read_csv(ctl_path + 'ControlTable_Wetlands_NLCD2011.csv')

#-----------------------------------------------------------------------------
# Populate variables from control table
NHD_dir = ctl.DirectoryLocations.values[0]
path_dir = ctl.DirectoryLocations.values[1]
out_dir_paths = ctl.DirectoryLocations.values[3]
numpy_dir = ctl.DirectoryLocations.values[8]
lookup_dir = ctl.DirectoryLocations.values[6]
#-----------------------------------------------------------------------------

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

for line in range(len(ctl.values)):
    if ctl.run[line] == 1:   
        #print '---- Running: ' + str(ctl.LandscapeLayer[line]) + ' ----'
        accum_type = ctl.accum_type[line] 
        ingrid_dir = ctl.ingrid_dir[line]
            # Loop through RPUs
        for region in inputs.keys():
            for hydro in inputs[region]:
                #print 'Region ' + region + ' and hydro number ' + hydro
                for dirs in os.listdir(NHD_dir + '/NHDPlus' + region + '/NHDPlus' + hydro):
                    if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                        rpu =  dirs[-3:] 
                        print rpu + " " + hydro + " " + region
                            # Define inputs from control table
                        inZoneData = path_dir + '/StreamLink_' + rpu + '.tif'
                        if ctl.LandscapeLayer[line] == 'elev_cm':
                            ingrid_dir = NHD_dir
                            LandscapeLayer = ingrid_dir + '/' + '/NHDPlus' + region + '/NHDPlus' + hydro + '/NEDSnapshot/Ned' + rpu + '/elev_cm'
                        if ctl.LandscapeLayer[line] == 'fac':
                            ingrid_dir = NHD_dir
                            LandscapeLayer = ingrid_dir + '/' + '/NHDPlus' + region + '/NHDPlus' + hydro + '/NHDPlusFdrFac' + rpu + '/fac'                        
                        if ctl.LandscapeLayer[line] == 'fldown':
                            LandscapeLayer = ingrid_dir + '/' + ctl.LandscapeLayer[line] + '_' + rpu + '.tif' 
                        if ctl.LandscapeLayer[line] != 'elev_cm' and ctl.LandscapeLayer[line] != 'fldown' and ctl.LandscapeLayer[line] != 'fac':
                            LandscapeLayer = ingrid_dir + '/' +   ctl.LandscapeLayer[line]                         
                        outTable = out_dir_paths + '/' + ctl.Final_Table_Name[line] + '_' + rpu + '.dbf'
                        arcpy.env.cellSize = "30"
                        arcpy.env.snapRaster = inZoneData
                        if accum_type == 'Categorical':
                            if not arcpy.Exists(outTable):
                                TabulateArea(inZoneData, 'VALUE', LandscapeLayer, "Value", outTable, "30")
                        if accum_type == 'Continuous':
                            if not arcpy.Exists(outTable):
                                ZonalStatisticsAsTable(inZoneData, 'VALUE', LandscapeLayer, outTable, "DATA", "ALL") 
```


### Associate wetlands with flow paths
Also make adjustment to get wetland points associated with paths correctly
```{r, eval=F}
library(raster)
library(rgdal)
library(stringr)
library(foreign)
require(dplyr)

year = '2001'
path_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/CostPaths')
points_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPoints')
wetlands_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/AllWetlands_rpu')
fromto_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/FlowTables')
cat_path = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandCat/Accumulation/')
cat_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD', year, '/WetlandCat/Accumulation/')
zonal_path = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/Zonal/')
nhddir = 'L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/HYDROLOGY/NHDPlusV21/'

nhd_units = read.csv('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/nhd_process_units.csv')

files = list.files(fromto_dir, pattern = '.dbf'); rpus = c()
files = files[!grepl('\\.xml$',files) & ! grepl('\\.vat.dbf$',files)]
for(i in 1:length(files)){
  #print(files[i])
  rpus[i] = substr(files[i], 13,15)
}

path_list = list.files(path_dir, pattern = "StreamLink_")
path_list = path_list[grep('\\.tif$',path_list)]

point_list = list.files(points_dir, pattern = "WetlandPoints")
point_list = point_list[grep('\\.shp$',point_list)]

wetland_list = list.files(wetlands_dir, pattern = "Wetlands")
wetland_list = wetland_list[grep('\\.dbf$',wetland_list)]

fromto_list = list.files(fromto_dir, pattern = "FrmTo")
fromto_list  = fromto_list[grep('\\.tif$',fromto_list)]

fromtotable_list = list.files(fromto_dir, pattern = 'FrmTo')
fromtotable_list  = fromtotable_list[grep('\\.dbf$',fromtotable_list)]
drop_list  = fromtotable_list[grep('.vat.dbf',fromtotable_list)]
fromtotable_list = setdiff(fromtotable_list, drop_list)

for (i in 1:59){ 
  print((rpus[i]))
  #print(nhd_units[i,])
  region = nhd_units[i,3]; hydro = nhd_units[i,2]; rpu = nhd_units[i,1] 
  fac_ras = raster(paste0(nhddir,'NHDPlus',region,'/NHDPlus',hydro,'/NHDPlusFdrFac',rpu,'/fac'))
  streamlink_ras = raster(paste0(path_dir,'/',path_list[i]))
  wetpoint = readOGR(points_dir, strsplit(point_list[i],'\\.')[[1]][1])
  wetland = read.dbf(paste0(wetlands_dir,'/',wetland_list[i]))
  wetland = wetland[c(1)]
  fromto = read.dbf(paste0(fromto_dir, '/', fromtotable_list[i]))[c('STREAMLINK','FLOWTOFINA')]
  names(fromto) = c('from','to')
  names(wetland)[1] = 'WET_ID'
  wetpoint$STRMLNK_ID =  extract(streamlink_ras, wetpoint)
  wetpoint$fac = extract(fac_ras, wetpoint)
  wetpoint = wetpoint[c(1,6,7)]
  faczonal = read.dbf(paste0(zonal_path, 'Fac_', rpus[i], '.dbf'))[c('Value','COUNT','MIN','MAX')]
  wetpoint = wetpoint@data
  wetpoint = merge(wetpoint, faczonal, by.x = 'STRMLNK_ID', by.y = 'Value', all.x=T)
  wetpoint = merge(wetpoint, fromto, by.x = 'STRMLNK_ID', by.y = 'from', all.x=T)
  
  wetpoint$Riparian = 0
  wetpoint$Riparian[(wetpoint$fac == wetpoint$MAX & is.na(wetpoint$to))] = 1
  wetpoint$Riparian[(is.na(wetpoint$STRMLNK_ID))] = 1
  wetpoint = wetpoint[c('STRMLNK_ID','GRID_CODE','Riparian')]
  names(wetpoint) = c('PATHID','WET_ID','Riparian')
  wetpoint = wetpoint[c('WET_ID', 'PATHID','Riparian')]
  wetpoint$PATHID[(wetpoint$Riparian==1)] = NA
  
  #------------------------------------------------------------------------------------------------
#   #Development to find riparian versus GIW
#   #Case 1  Riparian
#   head(wetpoint[(wetpoint$fac == wetpoint$MAX & is.na(wetpoint$to)), ], n=50)
#   #Case 2 GIW
#   head(wetpoint[(wetpoint$fac == wetpoint$MAX & !is.na(wetpoint$to)), ], n=50)
#   #Case 3 GIW
#   head(wetpoint[(wetpoint$fac < wetpoint$MAX & is.na(wetpoint$to)), ], n=50)    
#   #Case 4 GIW
#   head(wetpoint[(wetpoint$fac < wetpoint$MAX & !is.na(wetpoint$to)), ], n=50) 
#   #Case 5 Doesn't exist
#   head(wetpoint[(wetpoint$fac > wetpoint$MAX & is.na(wetpoint$to)), ], n=50) 
#   #Case 6 Doesn't exist
#   head(wetpoint[(wetpoint$fac > wetpoint$MAX & !is.na(wetpoint$to)), ], n=50)
#   #Case 7 Riparian
#   head(wetpoint[(is.na(wetpoint$STRMLNK_ID)), ], n=50)
  #------------------------------------------------------------------------------------------------
  
  WetlandsNoPath = wetpoint[wetpoint$Riparian==1,]
  WetlandsWithPath = wetpoint[wetpoint$Riparian==0,]
  
  write.csv(wetpoint, paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/LookupTables/AllWetlands_StreamLink_Lookup_',str_sub(strsplit(wetland_list[i],'\\.')[[1]][1],-3),'.csv'), row.names=FALSE)
  write.csv(WetlandsWithPath, paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/LookupTables/WetlandsWithPath_StreamLink_Lookup_',str_sub(strsplit(wetland_list[i],'\\.')[[1]][1],-3),'.csv'), row.names=FALSE)
  write.csv(WetlandsNoPath, paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/LookupTables/WetlandsNoPath_StreamLink_Lookup_',str_sub(strsplit(wetland_list[i],'\\.')[[1]][1],-3),'.csv'), row.names=FALSE)
}
```

## Wetland catchment processes

### Delineate wetland catchments
1. Check to see if catchments already exist
2. If no, run ArcGIS 'watershed' tool on all wetlands
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
# Import arcpy module
import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")

from datetime import datetime
import struct, decimal, itertools

arcpy.env.overwriteOutput = True

nhddir = 'L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/HYDROLOGY/NHDPlusV21'
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'

year = '2001'
wetland_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/AllWetlands_rpu'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandCat/WetCats'
fullstreams_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year +'/FullStreams'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
          
for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]
                Fullstreamsnull = fullstreams_dir + "/FullStreamsFDRNull" + rpu + ".tif"
                #Check to see if wetland catchments exist already
                if not os.path.exists(watershed_dir + '/WetlandCat_' + rpu + '.tif'):                     
                    print rpu  
                    startTime = time.time() 
                        #-- Create garbage cans --
                    garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
                    if not os.path.exists(garbage):
                        os.makedirs(garbage)
                    arcpy.env.workspace = garbage
                    arcpy.env.mask = Fullstreamsnull
                        #-- Delete garbage after run --
                    startTime = time.time()                      
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                        # Generate wetland watersheds                      
                    outWtshd = Watershed(fdr, wetland_dir + '/WetlandsRgnGrp_' + rpu + '.tif', "VALUE")
                        # Save watershed
                    outWtshd.save(watershed_dir + '/WetlandCat_' + rpu + '.tif')                    
                    print "Minutes for this region: " + str((time.time()-startTime) / 60.0) 
```

### Create catchment connections (from-to tables)
1. Shift the catchment in each of the 8 neighboring directions
2. Check each neighboring cell following conditions:
    * Does the cell have a different catchment ID as neighbor?
    * Does it flow into the neighboring cell?
3. If 'yes' to both questions, then connect in topology table
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}

# Import arcpy module
import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")
from datetime import datetime
import struct, decimal, itertools

arcpy.env.overwriteOutput = True

nhddir = 'H:/NHDPlusV21'
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
# NLCD 2011
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/IsolatedWetlands'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/WetCats'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/FlowTables'

# NLCD 2001
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/IsolatedWetlands'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandCat/WetCats'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandCat/FlowTables'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
          
for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]
                    # Check to see if wetland catchments exist already
                outDbf = frmto_dir + "/WetlandFrmTo" + rpu + ".dbf"
                if not os.path.exists(outDbf):
                        #-- Create garbage cans --
                    garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
                    if not os.path.exists(garbage):
                        os.makedirs(garbage)
                    arcpy.env.workspace = garbage
                        #-- Delete garbage after run --
                    startTime = time.time()   
                    print "Shifting region: " + rpu
                    Wtshds = Raster(watershed_dir + '/WetlandCat_' + rpu + '.tif')     
                    shift1 = arcpy.Shift_management(Wtshds, "shift1.tif", "-30", "0", Wtshds)
                    shift2 = arcpy.Shift_management(Wtshds, "shift2.tif", "-30", "30", Wtshds)
                    shift4 = arcpy.Shift_management(Wtshds, "shift4.tif", "0", "30", Wtshds)
                    shift8 = arcpy.Shift_management(Wtshds, "shift8.tif", "30", "30", Wtshds)
                    shift16 = arcpy.Shift_management(Wtshds, "shift16.tif", "30", "0", Wtshds)
                    shift32 = arcpy.Shift_management(Wtshds, "shift32.tif", "30", "-30", Wtshds)
                    shift64 = arcpy.Shift_management(Wtshds, "shift64.tif", "0", "-30", Wtshds)
                    shift128 = arcpy.Shift_management(Wtshds, "shift128.tif", "-30", "-30", Wtshds)                   
                    print "Minutes to shift this region: " + str((time.time()-startTime) / 60.0) 
                    
                        # Process: Raster Calculator                    
                    print 'Creating from-to connections'
                    startTime = time.time() 
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                    flowto1 = ((shift1 != Wtshds) * (fdr == 1)) * shift1
                    flowto1.save("FlowTo1.tif")
                    flowto1 = Raster("FlowTo1.tif")
                    flowto1 = Con(IsNull(flowto1),0,flowto1)
                    
                    flowto2 = ((shift2 != Wtshds) * (fdr == 2)) * shift2
                    flowto2.save("FlowTo2.tif")
                    flowto2 = Raster("FlowTo2.tif")
                    flowto2 = Con(IsNull(flowto2),0,flowto2)
                    
                    flowto4 = ((shift4 != Wtshds) * (fdr == 4)) * shift4
                    flowto4.save("FlowTo4.tif")
                    flowto4 = Raster("FlowTo4.tif")
                    flowto4 = Con(IsNull(flowto4),0,flowto4)
                    
                    flowto8 = ((shift8 != Wtshds) * (fdr == 8)) * shift8
                    flowto8.save("FlowTo8.tif")
                    flowto8 = Raster("FlowTo8.tif")
                    flowto8 = Con(IsNull(flowto8),0,flowto8)
                    
                    flowto16 = ((shift16 != Wtshds) * (fdr == 16)) * shift16
                    flowto16.save("FlowTo16.tif")
                    flowto16 = Raster("FlowTo16.tif")
                    flowto16 = Con(IsNull(flowto16),0,flowto16)
                    
                    flowto32 = ((shift32 != Wtshds) * (fdr == 32)) * shift32
                    flowto32.save("FlowTo32.tif")
                    flowto32 = Raster("FlowTo32.tif")
                    flowto32 = Con(IsNull(flowto32),0,flowto32)
                    
                    flowto64 = ((shift64 != Wtshds) * (fdr == 64)) * shift64
                    flowto64.save("FlowTo64.tif")
                    flowto64 = Raster("FlowTo64.tif")
                    flowto64 = Con(IsNull(flowto64),0,flowto64)
                    
                    flowto128 = ((shift128 != Wtshds) * (fdr == 128)) * shift128
                    flowto128.save("FlowTo128.tif")
                    flowto128 = Raster("FlowTo128.tif")
                    flowto128 = Con(IsNull(flowto128),0,flowto128)
                    
                    FlowToSum = flowto1 + flowto2 + flowto4 + flowto8 + flowto16 + flowto32 + flowto64 + flowto128
                    FlowToSum.save("FlowToSum.tif")
                    FlowToSum = Raster("FlowToSum.tif")
                    FlowToFinal = Con(FlowToSum != 0, FlowToSum)
                    FlowToFinal.save("FlowToFinal.tif")
                    
                    outCombine = Combine([FlowToFinal, Wtshds])
                    outCombine.save(working_dir + "/ScratchDir/WetlandFrmTo" + rpu + ".tif")

                    if not arcpy.Exists(outDbf):
                        arcpy.CopyRows_management(outCombine, outDbf, "")
                    print "Minutes to connect catchments in this region: " + str((time.time()-startTime) / 60.0) 
                    
                    try:
                        arcpy.Delete_management("FlowTo1.tif")
                        arcpy.Delete_management("FlowTo2.tif")
                        arcpy.Delete_management("FlowTo4.tif")
                        arcpy.Delete_management("FlowTo8.tif")
                        arcpy.Delete_management("FlowTo16.tif")
                        arcpy.Delete_management("FlowTo32.tif")
                        arcpy.Delete_management("FlowTo64.tif")
                        arcpy.Delete_management("FlowTo128.tif")
                        arcpy.Delete_management("shift1.tif")
                        arcpy.Delete_management("shift2.tif")
                        arcpy.Delete_management("shift4.tif")
                        arcpy.Delete_management("shift8.tif")
                        arcpy.Delete_management("shift16.tif")
                        arcpy.Delete_management("shift32.tif")
                        arcpy.Delete_management("shift64.tif")
                        arcpy.Delete_management("shift128.tif")
                        arcpy.Delete_management("FlowToSum.tif")
                        arcpy.Delete_management("FlowToFinal.tif")
                    except:
                        pass
```

### Create numpy files for accumulating wetland catchment results
1. Loops through from-to tables
2. Makes dictionary of next upstream catchment for each non-headwater catchment
3. Runs children and bastards functions to make full list of upstream catchments
4. Generates information such as length of each connection and saves results as 3 numpy vectors
    * comids<regionID>.npy - Vector of unique IDs for each wetland in region
    * lengths<regionID>.npy - Vector of the number of upstream catchments above each wetland. Children includes focal catchment, bastards excludes focal catchment
    * upCats<regionID>.npy - Vector of the unique IDs of each upstream catchment for each focal catchment listed in order. Focal catchment included for children, excluded for bastards
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import arcpy
import os, sys
import pysal as ps
import numpy as np
from collections import deque, defaultdict, OrderedDict

# NLCD 2011
numpy_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/WetCats_npy/'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/FlowTables/'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/WetCats/'

# NLCD 2001
numpy_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandCat/WetCats_npy/'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandCat/FlowTables/'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandCat/WetCats/' 

#Need to set to where WetCat_function.py is stored

sys.path.append(wetcatfunc)  
from WetCat_functions import dbf2DF, children, bastards

files = filter(lambda x: x.endswith(('.dbf')) and not x.count('.tif'), os.listdir(frmto_dir))

for file in files:
    rpu = file[-7:-4]
    print rpu

        #Read in wetland catchments to get list of COMIDs    
    wetcat = watershed_dir + 'WetlandCat_' + rpu + '.tif'
    if not os.path.exists(wetcat + '.vat.dbf'):
        arcpy.BuildRasterAttributeTable_management(wetcat, "Overwrite")
    tbl = dbf2DF(wetcat + '.vat.dbf')
    COMIDs = tbl.VALUE.values      
    
        #Read in from-to table
    flow = dbf2DF(frmto_dir + file)[[1,3]] #Only need columns 1 and 3
    #print flow.head()
    print "Processing region: " + rpu + " with total records = " + str(len(flow))
    flow.columns = ['TOCOMID','FROMCOMID'] #Rename columns
    flow  = flow[flow.FROMCOMID != 0] #Remove paths with FROMCOMID == 0
    fromID = np.array(flow.FROMCOMID) #Make numpy arrays of from and to columns
    toID = np.array(flow.TOCOMID)
    
        #Make dictionary of next up catchment ID
    UpCOMs = defaultdict(list)
    for i in range(0, len(flow), 1):
        FROMID = fromID[i]
        TOID = toID[i]
        UpCOMs[TOID].append(FROMID)                              
        
        #Make and save bastards
    a = map(lambda x: bastards(x, UpCOMs), COMIDs) #Make bastards vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'bastards'):
        os.makedirs(numpy_dir + 'bastards')
    np.save(numpy_dir + 'bastards/upCats' + rpu + '.npy', a)
    np.save(numpy_dir + 'bastards/comids' + rpu + '.npy', COMIDs)
    np.save(numpy_dir + 'bastards/lengths' + rpu + '.npy', lengths)
    
         #Make and save children
    a = map(lambda x: children(x, UpCOMs), COMIDs) #Make children vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'children'):
        os.makedirs(numpy_dir + 'children')
    np.save(numpy_dir + 'children/upCats' + rpu + '.npy', a)
    np.save(numpy_dir + 'children/comids' + rpu + '.npy', COMIDs)
    np.save(numpy_dir + 'children/lengths' + rpu + '.npy', lengths)   
```


### Process rasters with wetland catchments to produce continuous or categorical summaries
1. Open control table and access information to process each raster
2. Loop through RPUs
3. Based on raster type, use ArcGIS functions to create catchment summaries
    * Categorical - TabulateArea
    * Continuous - ZonalStatisticsAsTable
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import os
import arcpy
from arcpy.sa import TabulateArea, ZonalStatisticsAsTable
arcpy.CheckOutExtension("spatial")
import pandas as pd

ctl_path = 'J:/GitProjects/Wetland Connectivity/WetlandScripts/'
ctl = pd.read_csv(ctl_path + 'ControlTable_Wetlands_NLCD2001.csv')

#-----------------------------------------------------------------------------
# Populate variables from control table
NHD_dir = ctl.DirectoryLocations.values[0]
basin_dir = ctl.DirectoryLocations.values[2]
out_dir_basins = ctl.DirectoryLocations.values[4]
numpy_dir = ctl.DirectoryLocations.values[7]
lookup_dir = ctl.DirectoryLocations.values[6]
#-----------------------------------------------------------------------------

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

for line in range(len(ctl.values)):
    if ctl.run[line] == 1:   
        print '---- Running: ' + str(ctl.LandscapeLayer[line]) + ' ----'
        accum_type = ctl.accum_type[line] 
        ingrid_dir = ctl.ingrid_dir[line]
            # Loop through RPUs
        for region in inputs.keys():
            for hydro in inputs[region]:
                print 'Region ' + region + ' and hydro number ' + hydro
                for dirs in os.listdir(NHD_dir + '/NHDPlus' + region + '/NHDPlus' + hydro):
                    if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                        rpu =  dirs[-3:] 
                            # Define inputs from control table
                        inZoneData = basin_dir + '/WetlandCat_' + rpu + '.tif'
                        LandscapeLayer = ingrid_dir + '/' + ctl.LandscapeLayer[line]
                        outTable = out_dir_basins + '/' + ctl.Final_Table_Name[line] + '_' + rpu + '.dbf'
                        arcpy.env.cellSize = "30"
                        arcpy.env.snapRaster = inZoneData
                        if accum_type == 'Categorical':
                            if not arcpy.Exists(outTable):
                                TabulateArea(inZoneData, 'VALUE', LandscapeLayer, "Value", outTable, "30")
                        if accum_type == 'Continuous':
                            if not arcpy.Exists(outTable):
                                ZonalStatisticsAsTable(inZoneData, 'VALUE', LandscapeLayer, outTable, "DATA", "ALL")  
```

## Accumulate path and catchment data

### Universal code to accumulate path or catchment metrics
* Uses control tables to determine whether path or basin metrics should be calculated
* Places results in appropriate directory (i.e., path or basin)
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import pandas as pd
import numpy as np
import os, sys

wetcatfunc = 'D:/WorkFolder/WetConnect_Nov2016/Scripts/'
sys.path.append(wetcatfunc)  
from WetCat_functions import dbf2DF, Accumulation

ctl_path = 'D:/WorkFolder/WetConnect_Nov2016/Scripts/'
ctl = pd.read_csv(ctl_path + 'ControlTable_Wetlands_NLCD2011.csv')

#Use any of the numpy files to get list of regions
numpy_dir = ctl.DirectoryLocations.values[8] + '/'
files = filter(lambda x: x.endswith(('.npy')) and x.count('lengths'), os.listdir(numpy_dir+'children'))

for line in range(len(ctl.values)):
    
    if ctl.run[line] == 1:   
        zonal_type = str.upper(ctl.MetricType[line]) #Type of zonal and accumulation metric to process
        var = ctl.Final_Table_Name[line] #Name of variable to be processed
        tbl_type = ctl.path_basin[line] #Name of type of table (basin or path)
        ID_column = str.capitalize(tbl_type) + 'ID'
        accum_type = ctl.accum_type[line]
            # Populate variables from control table
        if tbl_type == 'path':
            zonal_dir = ctl.DirectoryLocations.values[3] + '/'
            numpy_dir = ctl.DirectoryLocations.values[8] + '/'
            path_dir = ctl.DirectoryLocations.values[1] + '/'
            out_accum = ctl.DirectoryLocations.values[9] + '/'
            npIDvect = 'PathIDs'
            npNetwork = 'downPaths'
        else:
            zonal_dir = ctl.DirectoryLocations.values[4] + '/'    
            numpy_dir = ctl.DirectoryLocations.values[7] + '/'    
            path_dir = ctl.DirectoryLocations.values[2] + '/'
            out_accum = ctl.DirectoryLocations.values[10] + '/'     
            npIDvect = 'comids'
            npNetwork = 'upCats'
            
        print '---- Running: ' + var + ' ' + zonal_type + ' ----'
        for file in files:
            region = file[7:10]
            print region  
            startTime = time.time() 
            outFile = out_accum + var + '_' + zonal_type + '_' + region + '.csv'
            zonal_file =  zonal_dir + var + '_' + region + '.dbf'
                #Read in zonal table
            arr = dbf2DF(zonal_file)  
                #Which columns to keep or drop for accumulation
            if zonal_type == 'MEAN':    
                arr = arr[['VALUE', 'SUM', 'COUNT']]
            elif zonal_type != 'MEAN' and zonal_type != 'PERCENT':
                arr = arr[['VALUE', zonal_type]]                
                #Read in numpy vectors                        
            IDs = np.load(numpy_dir + 'children/' + npIDvect + region + '.npy')
            lengths = np.load(numpy_dir + 'children/lengths' + region + '.npy')
            network = np.load(numpy_dir + 'children/' + npNetwork + region + '.npy')
                #Make sure all path or ws IDs are accounted for
            if len(arr) != len(IDs):
                if tbl_type == 'path':
                    allIDs = dbf2DF(path_dir + 'StreamLink_' + region + '.tif.vat.dbf')[['VALUE']]
                else:
                    allIDs = dbf2DF(path_dir + 'WetlandCat_' + region + '.tif.vat.dbf')[['VALUE']]
                arr = pd.merge(arr, allIDs, on = 'VALUE', how = 'right')

            df = Accumulation(arr, IDs, lengths, network, tbl_type=tbl_type, ID_column=ID_column, zonal_type=zonal_type)
            df.to_csv(out_accum + var + '_' + zonal_type + '_' + region + '.csv', index=False)
            print "Minutes for this region: " + str((time.time()-startTime) / 60.0)
```













