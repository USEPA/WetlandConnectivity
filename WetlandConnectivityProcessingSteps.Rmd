---
title: "Wetland Connectivity Processing Steps"
author: "Marc Weber & Ryan Hill"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    theme: yeti
    highlighted: default 
    toc: yes
---

The following steps lay out the approach to generate wetland flow paths and calculate wetland hydrological connectivity at a national level

## Wetland extraction and preparation

### Derive NLCD 2001 or 2011 based wetlands
1. Extract wetland cells from NLCD 2011 raster
2. Use Arc region group tool to define contiguous wetland cells and assign a unique ID
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
# Import arcpy module
import arcpy
import os
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env

# Set variables

# for 2011
# wetlands_dir = "L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands"
# nlcd = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/nlcd2011.tif'
# for 2001
wetlands_dir = "L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands"
nlcd = 'L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/LAND_COVER/NLCD/nlcd_2001_landcover_2011_edition_2014_10_10/nlcd_2001_landcover_2011_edition_2014_10_10.img'

# Derive NLCD based wetlands
NLCD = Raster(nlcd)
wetlands = Con((NLCD == 90) | (NLCD == 95), 1,)
if not arcpy.Exists(wetlands_dir + "/Wetlands" + ".tif"):
    wetlands.save(wetlands_dir + "/Wetlands.tif")

# Now create unique wetland groups of contiguous wetland cells
Wetlands = Raster(wetlands_dir + "/Wetlands.tif")
WetlandRegions = RegionGroup(Wetlands, "EIGHT", "WITHIN", "NO_LINK", "")
if not arcpy.Exists(wetlands_dir + "/WetlandsRgnGrp.tif"):
    WetlandRegions.save(wetlands_dir + "/WetlandsRgnGrp.tif")   
```

### Use Full Streams to test if wetlands are isolated from stream network
1. Build VAT for wetland raster
2. Set non-null values in fdrnull raster = 1
3. Multiply rasters and build VAT of output of (2)
4. Compare counts of regions in VATS 
5. Save isolated wetlands
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}

import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")
from collections import deque, defaultdict
import pysal as ps
import pandas as pd
import numpy as np
import numpy.ma as ma
from osgeo import gdal
import osr

arcpy.env.overwriteOutput = True

def array2raster(newRasterfn,rasterfn,array):
    geotransform = rasterfn.GetGeoTransform()
    originX = geotransform[0]
    originY = geotransform[3]
    pixelWidth = geotransform[1]
    pixelHeight = geotransform[5]
    cols = array.shape[1]
    rows = array.shape[0]

    driver = gdal.GetDriverByName('GTiff')
    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Byte)
    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))
    outband = outRaster.GetRasterBand(1)
    outband.WriteArray(array)
    outRasterSRS = osr.SpatialReference()
    outRasterSRS.ImportFromWkt(rasterfn.GetProjectionRef())
    outRaster.SetProjection(outRasterSRS.ExportToWkt())
    outband.FlushCache()

def dbf2DF(dbfile, upper=True):
    db = ps.open(dbfile)
    cols = {col: db.by_col(col) for col in db.header}
    db.close()  #Close dbf 
    pandasDF = pd.DataFrame(cols)
    if upper == True:
        pandasDF.columns = pandasDF.columns.str.upper()              
    return pandasDF


# nhddir = 'L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/HYDROLOGY/NHDPlusV
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
# working_dir = 'D:/WorkFolder/WetConnect_Aug2016'
# NLCD 2011
# wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands'
# wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands_rpu'
# watermask_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'
# isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/IsolatedWetlands'
# NLCD 2001
wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands'
wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands_rpu'
watermask_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/IsolatedWetlands'
arcpy.env.workspace = working_dir + '/garbage3'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
         'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
# inputs = {'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}           

for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]

                if not os.path.exists(isolated_dir + '/isoWetlands_' + rpu + '.tif'):                     
                    print rpu
                        #-- thanks ESRI --
                    garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
                    if not os.path.exists(garbage):
                        os.makedirs(garbage)
                    arcpy.env.workspace = garbage
                        #-- thanks ESRI --
                    startTime = time.time()  
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                        # Set env                
                    arcpy.env.snapRaster = fdr
                    arcpy.env.cellSize = "30"
                    arcpy.env.mask = fdr
                    arcpy.env.extent = fdr
                    # Get full streams              
                    fullstreams = Raster(watermask_dir +"/FullStreams"  + rpu + ".tif")
                    stream_expand = Expand(fullstreams, 1, 1) #Expand by 1 pixel to find wetlands that are disconnect by at least 1 pixel                
                    streamcon = Con(IsNull(stream_expand), 1, 0) #Set null pixels to zero, else stay the same                             
                    wetland_all = Raster(wetlands_dir + '/WetlandsRgnGrp.tif')
                    outWet_rpu = wetrpu_dir + '/Wetlands_' + rpu + '.tif'
                    # Make wetland for each RPU 
                    if not arcpy.Exists(outWet_rpu):
                        wetland_rpu = ExtractByMask(wetland_all, fdr)
                        wetland_rpu.save(outWet_rpu) 
                    #arcpy.gp.ExtractByMask_sa(wetland_all, fdr, outWet_rpu)
                    arcpy.BuildRasterAttributeTable_management(outWet_rpu, "Overwrite")
                    wetland = Raster(outWet_rpu)
                    wetcon = Con(IsNull(wetland),0, wetland)
                    # Multiply to create temporary query wetland
                    tmpWet = streamcon * wetcon
                    if not arcpy.Exists(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif'):
                        tmpWet.save(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif')
                    arcpy.BuildRasterAttributeTable_management(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif', "Overwrite")
                        # Read in and merge VATs to compare 
                    lesswet = dbf2DF(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif.vat.dbf')
                    allwet = dbf2DF(outWet_rpu + '.vat.dbf')
                    new = pd.merge(allwet, lesswet, on = 'VALUE', how = 'left')                
                    isolated = new.loc[new['COUNT_x'] == new['COUNT_y']]
                    isolated = np.array(isolated.VALUE).astype(int)
                        # Read in wetland raster, convert to numpy array, flatten, and query against list of isolated wetlands
                    wetland_ras = gdal.Open(outWet_rpu)
                    wetland_arr = np.array(wetland_ras.GetRasterBand(1).ReadAsArray())                
                    wetshape = wetland_arr.shape                               
                    wetland_flat = wetland_arr.flatten() #Flatten 2d array to 1d
                    z = np.where(np.in1d(wetland_flat, isolated), 1, np.NaN)
                    z.shape = wetshape             
                        # Stuff to get it out to TIF ESRI can see
                    newraster = array2raster(working_dir + '/ScratchDir/isoWetTmp_' + rpu + '.tif', wetland_ras, z)
                    newRaster = Raster(working_dir + '/ScratchDir/isoWetTmp_' + rpu + '.tif')
                    newRaster2 = Times(wetland_rpu, newRaster) #run it through a process to get it to be integer and in native ESRI format (exclude odd NUMPY stuff)    
                    newRaster3 = Con(newRaster2 != 0, newRaster2)
                    newRaster3.save(isolated_dir + '/isoWetlands_' + rpu + '.tif')              
                    print "Minutes for this region: " + str((time.time()-startTime) / 60.0)                          

```


### Generate wetland points for each wetland group
1. Generate points for each raster cell in wetland groups
2. Use geopandas to select just the point in each group with largest flow accumulation (the wetland outlet)
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import arcpy
import os
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env
import georasters as gr
import geopandas as gp
import pandas as pd
wetcatfunc = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/ScriptsArchive/'
sys.path.append(wetcatfunc)  
from WetCat_functions import GetRasterValueAtPoints
from datetime import datetime

nhddir = "L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/HYDROLOGY/NHDPlusV21"
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
#working_dir = 'D:/WorkFolder/WetConnect_Aug2016'
# NLCD 2011
wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands'
wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands_rpu'
watermask_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/IsolatedWetlands'
wetpoints_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPoints'


# NLCD 2001
#wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands'
#wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands_rpu'
#watermask_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'
#isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/IsolatedWetlands'
#wetpoints_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandPoints'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

for region in inputs.keys():
    for hydro in inputs[region]:
        print 'on region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                if not arcpy.Exists(wetpoints_dir + "/WetlandPoints" + dirs[-3:]+ ".shp"):
                    print dirs
                    # Execute ExtractValuesToPoints to get flow accumulation for each wetland region grid point
                    fac = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + dirs[-3:] + "/fac")
                    arcpy.env.snapRaster = fac
                    arcpy.env.mask = fac
                    arcpy.env.extent = fac.extent
                    # Raster to points
                    outPoint = working_dir + "/ScratchDir/RasterPoints" + dirs[-3:] + ".shp"
                    # Execute RasterToPoint - do for both iso and all wetlands!
                    # Wetlands = isolated_dir + "/isoWetlands_" + dirs[-3:] + ".tif"
                    Wetlands = wetrpu_dir + "/Wetlands_" + dirs[-3:] + ".tif"
                    if not arcpy.Exists(outPoint):
                        arcpy.RasterToPoint_conversion(Wetlands, outPoint, "VALUE")
                    
                    outPointFac = working_dir + "/ScratchDir/PointFac" + dirs[-3:] +  ".shp"
                    if not arcpy.Exists(outPointFac):
                        ExtractValuesToPoints(outPoint, fac, outPointFac,"", "ALL")
                    
                    # Process: Make Feature Layer
                    arcpy.MakeFeatureLayer_management(outPointFac, "FacPoints")
                    
                    # Process: Make Feature Layer
                    BoundaryUnits = nhddir + "/NHDPlusGlobalData/BoundaryUnit.shp"
                    arcpy.MakeFeatureLayer_management(BoundaryUnits, "BoundaryUnit", "\"UnitID\" = '%s'"%(dirs[-3:]))
                    
#                    # Process: Select Layer By Location
#                    arcpy.SelectLayerByLocation_management("FacPoints", "INTERSECT", "BoundaryUnit", "", "NEW_SELECTION")
                    
                    # Process: Feature Class To Shapefile (multiple)
                    arcpy.FeatureClassToShapefile_conversion("FacPoints", working_dir + "/ScratchDir")
                    
                    # Use Pandas to get the minimum flow distance point for each wetland region group ID
                    WetPoints = gp.GeoDataFrame.from_file(working_dir + "/ScratchDir/FacPoints.shp")
                    # First we'll drop all the -999 sites - these are wetland grid cells in the stream
                    WetPoints = WetPoints.loc[WetPoints.RASTERVALU!=-9999]
                    # Now we'll group points by wetland region group maximum flow accumulation
                    WetPoints = WetPoints.loc[WetPoints.groupby("GRID_CODE")["RASTERVALU"].idxmax()]
                    # And then we'll export to a text file after grabbing coordinates as fields we add
                    df = WetPoints.drop('geometry', axis=1)  # df is a DataFrame, not GeoDataFrame after the drop
                    def getXY(pt):
                        return (pt.x, pt.y)
                    centroidseries = WetPoints['geometry'].centroid
                    x,y = [list(t) for t in zip(*map(getXY, centroidseries))]
                    WetPoints['XCOORD'] = x
                    WetPoints['YCOORD'] = y
                    if not arcpy.Exists(wetpoints_dir + "/WetlandPoints" + dirs[-3:] +".shp"):
                        WetPoints.to_file(wetpoints_dir + "/WetlandPoints" + dirs[-3:]+ ".shp", driver = 'ESRI Shapefile')
                    df['XCOORD'] = x
                    df['YCOORD'] = y
                    df.head()
                    #df[x] = WetPoints.geometry.apply(lambda p: p.x)
                    #df[y] = WetPoints.geometry.apply(lambda p: p.y)
                    
                    df.to_csv(wetpoints_dir +"/WetlandPoints" + dirs[-3:] + ".csv")
                    
                    WetPoints = wetpoints_dir + "/WetlandPoints" + dirs[-3:] + ".shp"  
                    
                    arcpy.Delete_management(outPoint)
                    arcpy.Delete_management(outPointFac)
                    arcpy.Delete_management("FacPoints")
                    arcpy.Delete_management(working_dir + "/ScratchDir/FacPoints.shp")   
```  

## Wetland path processes

### Generate Cost Paths from each wetland outlet point to NHDPlus stream lines
1. Create a full streams null grid to use in cost path analysis
2. Run cost path tool using wetland outlet points, NHDPlus hydro DEM, and full streams null grid
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import arcpy
import os
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env
from datetime import datetime
import geopandas as gpd

nhddir = 'L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/HYDROLOGY/NHDPlusV21'
working_dir = 'F:/WetlandConnectivity/SpatialData'
#working_dir = 'D:/WorkFolder/WetConnect_Aug2016'
watermask_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'
fullstreams_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'
# NLCD2011
wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands'
wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands_rpu'
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/IsolatedWetlands'
paths_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/CostPaths'
wetpoints_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPoints'
# NLCD2001
#wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands'
#wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands_rpu'
#isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/IsolatedWetlands'
#paths_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandPath/CostPaths'
#wetpoints_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandPoints'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
         'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}


for region in inputs.keys():
    for hydro in inputs[region]:
        print 'on region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                print dirs
                rpu = dirs[-3:]
                fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                arcpy.env.snapRaster = fdr
                arcpy.env.cellSize = "30"
                arcpy.env.mask = fdr
                arcpy.env.extent = fdr
                WetPoints = wetpoints_dir + "/WetlandPoints" + rpu + ".shp" 
                # Create Full cost path raster - first, we'll geneerate a fullstreamsnull grid to pass to cost path tool
                FullStreams = Raster(fullstreams_dir + '/FullStreams' + rpu + '.tif')
                Fullstreamsnull = fullstreams_dir + "/FullStreamsFDRNull" + rpu + ".tif"
                if not arcpy.Exists(paths_dir + '/CostPath' + rpu + '.tif'):
                    outCostPath = CostPath(WetPoints, nhddir + "/NHDPlus" + region + "/NHDPlus" + hydro + "/NHDPlusHydrodem" + rpu + "/hydrodem",Fullstreamsnull, "EACH_CELL", "GRID_CODE")
                    outCostPath.save(paths_dir + '/CostPath' + rpu + '.tif')
                
                if not arcpy.Exists(working_dir + "/ScratchDir/WetPoints" + rpu + ".shp"):
                    wetpoints = gpd.GeoDataFrame.from_file(WetPoints)
                    wetpoints["junk"] = 1
                    wetpoints.to_file(working_dir + "/ScratchDir/WetPoints" + rpu + ".shp", driver = 'ESRI Shapefile') 
                    # Now convert polylines back to a raster
                    arcpy.FeatureToRaster_conversion(in_features=working_dir + "/ScratchDir/WetPoints" + rpu + ".shp", field="junk", out_raster= working_dir + "/ScratchDir/RasterPoints" + rpu + ".tif", cell_size="30")
                 
                if not arcpy.Exists(working_dir + "/ScratchDir/RasterPointsExpand" + rpu + ".tif"):
                    # Expand the rasterized wetlands points
                    Points = Raster(working_dir + "/ScratchDir/RasterPoints" + rpu + ".tif")
                    Points = Con(Points >= 1, 1,)
                    outExpand = Expand(Points, 1, 1)
                    outExpand.save(working_dir + "/ScratchDir/RasterPointsExpand" + rpu + ".tif")
                if not arcpy.Exists(working_dir + "/ScratchDir/ExpandCost" + rpu + ".tif"):
                    # Mosaic expanded points raster and cost path raster set to 1
                    input1 = Raster(working_dir + "/ScratchDir/RasterPointsExpand" + rpu + ".tif")
                    input1 = Con(IsNull(input1),0,input1)
                    input2 = Raster(paths_dir + "/CostPath" + rpu + ".tif")
                    input2 = Con(IsNull(input2), 0, 1)
                    cost = Raster(paths_dir + '/CostPath' + rpu + '.tif')
                    arcpy.env.mask = cost
                    arcpy.env.snapRaster = cost
                    output = input1 + input2
                    output2 = Con(output>=1,1)
                    output2.save(working_dir + "/ScratchDir/ExpandCost" + rpu + ".tif")
                if not arcpy.Exists(paths_dir + "/StreamLink" + rpu + ".tif"):
                    # Run stream link on the cost path to 'uniqueify' the sections
                    # Execute StreamLink
                    arcpy.gp.StreamLink_sa(working_dir + "/ScratchDir/ExpandCost", fdr, paths_dir + "/StreamLink" + rpu + ".tif")                 
```

### Find duplicated PathIDs in StreamLink rasters from previous step
```{r, eval=F}
library(raster)
library(rgdal)
library(stringr)
library(foreign)
require(dplyr)

year = '2001'
path_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/CostPaths')
points_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPoints')
accum_path = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/Accumulation/')

files = list.files(accum_path, pattern = 'NLCD'); rpus = c()
for(i in 1:length(files)){
  #print(files[i])
  rpus[i] = substr(files[i], 18, 20)
}

path_list = list.files(path_dir, pattern = "StreamLink")
path_list = path_list[grep('\\.tif$',path_list)]

for (i in 1:length(path_list)){
  print(path_list[i])
  streamlink_ras = raster(paste0(path_dir,'/',path_list[i]))
  wetpoint = readOGR(points_dir, paste0('WetlandPoints', rpus[i]))
  results = extract(streamlink_ras, wetpoint)
  wetpoint$duplicated =  results  
  tmp = wetpoint@data
  head(tmp)
  tmp = subset(tmp, select = c(duplicated))
  tmp = tmp[duplicated(tmp$duplicated),]
  tmp = data.frame(duplicated = tmp)
  write.csv(tmp, file = paste0(path_dir, '/duplicated_', rpus[i],'.csv'), row.names=F)
}
```

### Fix duplicated PathIDs in StreamLink rasters
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import os
import arcpy
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env
import pandas as pd
import numpy as np
import gdal
import osr
import time

def array2raster(newRasterfn,rasterfn,array):
    geotransform = rasterfn.GetGeoTransform()
    originX = geotransform[0]
    originY = geotransform[3]
    pixelWidth = geotransform[1]
    pixelHeight = geotransform[5]
    cols = array.shape[1]
    rows = array.shape[0]

    driver = gdal.GetDriverByName('GTiff')
    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Int32)
    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))
    outband = outRaster.GetRasterBand(1)
    outband.SetNoDataValue(-2147483647.0)
    outband.WriteArray(array)
    outRasterSRS = osr.SpatialReference()
    outRasterSRS.ImportFromWkt(rasterfn.GetProjectionRef())
    outRaster.SetProjection(outRasterSRS.ExportToWkt())
    outband.FlushCache()
    
arcpy.env.compression = 'LZW'

year = '2011'
wetpt_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD'+year+'/WetlandPoints/'
cost_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandPath/CostPaths/'
files = filter(lambda x: x.endswith(('.tif')) and x.count(('StreamLink')), os.listdir(cost_dir))

#---------------------------------------------------------------------------------------------------------------------------------------------------------
    #Temporary paths used in development of approach
#cost_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/tmp_qa_fesri/' 
#dup_dir = cost_dir
#---------------------------------------------------------------------------------------------------------------------------------------------------------

#Set inputs - will want to make loopable
for in_strlink in files: 
    t1 = time.time()
    #Set names and paths for files    
    inRaster = cost_dir + in_strlink
    outRas = cost_dir + 'StreamLink_fv_' + in_strlink[10:]  
    in_dup = cost_dir + 'duplicated_' + in_strlink[10:13] + '.csv'
    column = 'duplicated'
    #Read in files 
    dup = pd.read_csv(in_dup)
    dup = np.array(dup[column])
    dup = dup[~np.isnan(dup)]
    dup = np.unique(dup)
    if not arcpy.Exists(outRas):
        print '---Processing: '+in_strlink+'---'
        inRas = gdal.Open(inRaster)
        rst = np.array(inRas.GetRasterBand(1).ReadAsArray())
        shp = rst.shape #Get initial shape of rst
        rst = rst.flatten() #flatten rst
        query1 = np.in1d(rst, dup) #Find duped cells in rst (boolean vector)
        #Define start and end of sequence that will replace these values
        start = np.max(rst) + 1
        end = start + np.sum(query1)
        sequence = np.arange(start,end, 1)
     
        #Replace rst values with sequence values where boolean == True
        #Much faster than the loop if it will run
#        np.place(rst, query1, sequence) #This code kept crashing python
        
        #Break array into 10 parts   - don't need if np.place works 
        splits = np.array_split(rst, 10)  
        x = 0
        for i, split in enumerate(splits):
            query_i = np.in1d(splits[i], dup)#Find boolean of need replace 
            splitseq = sequence[x:x + np.sum(query_i)]#Split seq vector
            np.place(splits[i], query_i, splitseq)#Replace values with seq   
            if i == 0:
                rst = splits[i]
            else:
                rst = np.append(rst, splits[i])
            x = x + np.sum(query_i)
            
        #Reshape and write out raster
        rst.shape = shp

    
        newraster = array2raster(outRas, inRas, rst)
        # don't need this step
    #    arcpy.CopyRaster_management(cost_dir + 'test_expand.tif', outRas, "", "", "", "", "", "32_BIT_UNSIGNED")
        print '---Minutes to process: '+str((time.time() - t1)/60)+'---' 
    
'''
#-------------------------------------------------------------------
#Code used to develop process
a = np.array([1,1,1,5,5,5,3,4,6,5,5,5])
b = np.array([1,5])
print a
query1 = np.in1d(a, b)

start = np.max(a) + 1
end = start + np.sum(query1)

np.place(a, np.in1d(a, b), np.arange(start,end))

print a


#Dev code to loop through sub-arrays
x = np.arange(8.0)
y = np.array_split(x, 3)
for i, z in enumerate(y):
    print i
    if i == 0:
        out_arr = z
    else:
        out_arr = np.append(out_arr, z)
'''

```

### Create flow path connections (from-to tables)
1. Shift the catchment in each of the 8 neighboring directions
2. Check each neighboring cell following conditions:
    * Does the cell have a different catchment ID as neighbor?
    * Does it flow into the neighboring cell?
3. If 'yes' to both questions, then connect in topology table
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}

# Import arcpy module
import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")
from datetime import datetime
import struct, decimal, itertools

arcpy.env.overwriteOutput = True
nhddir = 'H:/NHDPlusV21'
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
# NLCD 2011
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/IsolatedWetlands'
paths_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/CostPaths'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/FlowTables'
# NLCD 2001
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/IsolatedWetlands'
paths_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandPath/CostPaths'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandPath/FlowTables'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
# inputs = {'GL':['04']}          
for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]
                # Check to see if wetland paths from to exist already
                outDbf = frmto_dir + "/WetlandFrmTo" + rpu + ".dbf"
                outtif = frmto_dir + "/WetlandFrmTo" + rpu + ".tif"
                if not os.path.exists(outDbf):
                        #-- Create garbage cans --
                    garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
                    if not os.path.exists(garbage):
                        os.makedirs(garbage)
                    arcpy.env.workspace = garbage
                        #-- Delete garbage after run --
                    startTime = time.time()
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                    arcpy.env.snapRaster = fdr
                    description = arcpy.Describe(fdr)  
                    cellsize = description.children[0].meanCellHeight 
                    arcpy.env.cellSize = cellsize
                    arcpy.env.mask = fdr
                    arcpy.env.extent = fdr
                    print "Shifting region: " + rpu
                    Paths = Raster(paths_dir + '/StreamLink' + rpu + '.tif')     
                    shift1 = arcpy.Shift_management(Paths, "shift1.tif", "-%s"%(cellsize), "0", Paths)
                    shift2 = arcpy.Shift_management(Paths, "shift2.tif", "-%s"%(cellsize), "%s"%(cellsize), Paths)
                    shift4 = arcpy.Shift_management(Paths, "shift4.tif", "0", "%s"%(cellsize), Paths)
                    shift8 = arcpy.Shift_management(Paths, "shift8.tif", "%s"%(cellsize), "%s"%(cellsize), Paths)
                    shift16 = arcpy.Shift_management(Paths, "shift16.tif", "%s"%(cellsize), "0", Paths)
                    shift32 = arcpy.Shift_management(Paths, "shift32.tif", "%s"%(cellsize), "-%s"%(cellsize), Paths)
                    shift64 = arcpy.Shift_management(Paths, "shift64.tif", "0", "-%s"%(cellsize), Paths)
                    shift128 = arcpy.Shift_management(Paths, "shift128.tif", "-%s"%(cellsize), "-%s"%(cellsize), Paths)  
                    print "Minutes to shift this region: " + str((time.time()-startTime) / 60.0) 
                    
                    # Process: Raster Calculator                    
                    print 'Creating from-to connections'
                    startTime = time.time() 
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                    flowto1 = ((shift1 != Paths) * (fdr == 1)) * shift1
                    flowto1.save("FlowTo1.tif")
                    flowto1 = Raster("FlowTo1.tif")
                    flowto1 = Con(IsNull(flowto1),0,flowto1)
                    
                    flowto2 = ((shift2 != Paths) * (fdr == 2)) * shift2
                    flowto2.save("FlowTo2.tif")
                    flowto2 = Raster("FlowTo2.tif")
                    flowto2 = Con(IsNull(flowto2),0,flowto2)
                    
                    flowto4 = ((shift4 != Paths) * (fdr == 4)) * shift4
                    flowto4.save("FlowTo4.tif")
                    flowto4 = Raster("FlowTo4.tif")
                    flowto4 = Con(IsNull(flowto4),0,flowto4)
                    
                    flowto8 = ((shift8 != Paths) * (fdr == 8)) * shift8
                    flowto8.save("FlowTo8.tif")
                    flowto8 = Raster("FlowTo8.tif")
                    flowto8 = Con(IsNull(flowto8),0,flowto8)
                    
                    flowto16 = ((shift16 != Paths) * (fdr == 16)) * shift16
                    flowto16.save("FlowTo16.tif")
                    flowto16 = Raster("FlowTo16.tif")
                    flowto16 = Con(IsNull(flowto16),0,flowto16)
                    
                    flowto32 = ((shift32 != Paths) * (fdr == 32)) * shift32
                    flowto32.save("FlowTo32.tif")
                    flowto32 = Raster("FlowTo32.tif")
                    flowto32 = Con(IsNull(flowto32),0,flowto32)
                    
                    flowto64 = ((shift64 != Paths) * (fdr == 64)) * shift64
                    flowto64.save("FlowTo64.tif")
                    flowto64 = Raster("FlowTo64.tif")
                    flowto64 = Con(IsNull(flowto64),0,flowto64)
                    
                    flowto128 = ((shift128 != Paths) * (fdr == 128)) * shift128
                    flowto128.save("FlowTo128.tif")
                    flowto128 = Raster("FlowTo128.tif")
                    flowto128 = Con(IsNull(flowto128),0,flowto128)
                    
                    FlowToSum = flowto1 + flowto2 + flowto4 + flowto8 + flowto16 + flowto32 + flowto64 + flowto128
                    FlowToSum.save("FlowToSum.tif")
                    FlowToSum = Raster("FlowToSum.tif")
                    FlowToFinal = Con(FlowToSum != 0, FlowToSum)
                    FlowToFinal.save("FlowToFinal.tif")
                    
                    outCombine = Combine([FlowToFinal, Paths])
                    outCombine.save(outtif)

                    if not arcpy.Exists(outDbf):
                        arcpy.CopyRows_management(outCombine, outDbf, "")
                    print "Minutes to connect flowpaths in this region: " + str((time.time()-startTime) / 60.0) 
                    
                    try:
                        arcpy.Delete_management("FlowTo1.tif")
                        arcpy.Delete_management("FlowTo2.tif")
                        arcpy.Delete_management("FlowTo4.tif")
                        arcpy.Delete_management("FlowTo8.tif")
                        arcpy.Delete_management("FlowTo16.tif")
                        arcpy.Delete_management("FlowTo32.tif")
                        arcpy.Delete_management("FlowTo64.tif")
                        arcpy.Delete_management("FlowTo128.tif")
                        arcpy.Delete_management("shift1.tif")
                        arcpy.Delete_management("shift2.tif")
                        arcpy.Delete_management("shift4.tif")
                        arcpy.Delete_management("shift8.tif")
                        arcpy.Delete_management("shift16.tif")
                        arcpy.Delete_management("shift32.tif")
                        arcpy.Delete_management("shift64.tif")
                        arcpy.Delete_management("shift128.tif")
                        arcpy.Delete_management("FlowToSum.tif")
                        arcpy.Delete_management("FlowToFinal.tif")
                    except:
                        pass
```

### Create numpy files for accumulating wetland path results
1. Loops through from-to tables
2. Makes dictionary of next downstream path for each non-terminal wetland path
3. Runs bastards function to make full list of downstream flowpaths
4. Generates information such as length of each connection and saves results as 3 numpy vectors
    * comids<regionID>.npy - Vector of unique IDs for each wetland in region
    * lengths<regionID>.npy - Vector of the number of upstream catchments above each wetland. Children includes focal catchment, bastards excludes focal catchment
    * downPaths<regionID>.npy - Vector of the unique IDs of each downstream path for each focal path listed in order. 

```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import arcpy
import os, sys
import pysal as ps
import numpy as np
from collections import deque, defaultdict, OrderedDict

# NLCD 2011
# numpy_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/WetPaths_npy/'
# frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/FlowTables/'
# Paths_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/CostPaths/'

# NLCD 2001
numpy_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandPath/WetPaths_npy/'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandPath/FlowTables/'
Paths_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandPath/CostPaths/'

#Need to set to where WetCat_function.py is stored
wetcatfunc = 'J:/GitProjects/Wetland Connectivity/WetlandScripts'
sys.path.append(wetcatfunc)  
from WetCat_functions import dbf2DF, children, bastards

files = filter(lambda x: x.endswith(('.dbf')) and not x.count('.tif'), os.listdir(frmto_dir))

for file in files:
    rpu = file[-7:-4]
    print rpu

    #Read in wetland paths to get list of path IDs    
    wetpath = Paths_dir + 'StreamLink' + rpu + '.tif'
    if not os.path.exists(wetpath + '.vat.dbf'):
        arcpy.BuildRasterAttributeTable_management(wetpath, "Overwrite")
    tbl = dbf2DF(wetpath + '.vat.dbf')
    PathIDs = tbl.VALUE.values      
    
    #Read in from-to table
    flow = dbf2DF(frmto_dir + file)[['FLOWTOFINA','STREAMLINK']] 
    #print flow.head()
    print "Processing region: " + rpu + " with total records = " + str(len(flow))
    flow.columns = ['TOCOMID','FROMCOMID'] #Rename columns
    fromID = np.array(flow.FROMCOMID) #Make numpy arrays of from and to columns
    toID = np.array(flow.TOCOMID)
    
    #Make dictionary of next up catchment ID
    DownIDs = defaultdict(list)
    for i in range(0, len(flow), 1):
        FROMID = fromID[i]
        TOID = toID[i]
        DownIDs[FROMID].append(TOID)                              
        
    #Make and save bastards
    a = map(lambda x: bastards(x, DownIDs), PathIDs) #Make bastards vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'bastards'):
        os.makedirs(numpy_dir + 'bastards')
    np.save(numpy_dir + 'bastards/downPaths' + rpu + '.npy', a)
    np.save(numpy_dir + 'bastards/PathIDs' + rpu + '.npy', PathIDs)
    np.save(numpy_dir + 'bastards/lengths' + rpu + '.npy', lengths)
    
    #Make and save children
    a = map(lambda x: children(x, DownIDs), PathIDs) #Make children vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'children'):
        os.makedirs(numpy_dir + 'children')
    np.save(numpy_dir + 'children/downPaths' + rpu + '.npy', a)
    np.save(numpy_dir + 'children/PathIDs' + rpu + '.npy', PathIDs)
    np.save(numpy_dir + 'children/lengths' + rpu + '.npy', lengths)    
```

### Create the flow length rasters based on wetland paths
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import arcpy
from arcpy import env
from arcpy.sa import *
arcpy.CheckOutExtension("spatial")

import os
import time

stream_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask/'
# NLCD 2011
out_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/FlowLengths/'
path_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/CostPaths/'
# NLCD 2001
#out_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandPath/FlowLengths/'
#path_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/CostPaths/'

files = filter(lambda x: x.endswith(('.tif')) and x.count(('FDRNull')), os.listdir(stream_dir))

for fdrnull in files:
    outRas = out_dir+'fl_'+fdrnull[18:]
    if not arcpy.Exists(outRas):
        start_time = time.time() 
        print 'Processing: ' + fdrnull 
        arcpy.env.snapRaster = fdrnull
        maskraster = path_dir+'StreamLink'+fdrnull[18:]
        arcpy.env.mask = maskraster
        outFlowLength = FlowLength(stream_dir+fdrnull, 'DOWNSTREAM','')
        outFlowLength.save(outRas)
        print("Duration: --- %s seconds ---" % (time.time() - start_time))  
```

### Process rasters with wetland paths to produce continuous or categorical summaries
1. Open control table and access information to process each raster
2. Loop through RPUs
3. Based on raster type, use ArcGIS functions to create catchment summaries
    * Categorical - TabulateArea
    * Continuous - ZonalStatisticsAsTable
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import os
import arcpy
from arcpy.sa import TabulateArea, ZonalStatisticsAsTable
arcpy.CheckOutExtension("spatial")
import pandas as pd

ctl_path = 'J:/GitProjects/Wetland Connectivity/WetlandScripts/'
ctl = pd.read_csv(ctl_path + 'ControlTable_Wetlands_NLCD2011.csv')

#-----------------------------------------------------------------------------
# Populate variables from control table
NHD_dir = ctl.DirectoryLocations.values[0]
path_dir = ctl.DirectoryLocations.values[1]
out_dir_paths = ctl.DirectoryLocations.values[3]
numpy_dir = ctl.DirectoryLocations.values[8]
lookup_dir = ctl.DirectoryLocations.values[6]
#-----------------------------------------------------------------------------

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

for line in range(len(ctl.values)):
    if ctl.run[line] == 1:   
        print '---- Running: ' + str(ctl.LandscapeLayer[line]) + ' ----'
        accum_type = ctl.accum_type[line] 
        ingrid_dir = ctl.ingrid_dir[line]
            # Loop through RPUs
        for region in inputs.keys():
            for hydro in inputs[region]:
                print 'Region ' + region + ' and hydro number ' + hydro
                for dirs in os.listdir(NHD_dir + '/NHDPlus' + region + '/NHDPlus' + hydro):
                    if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                        rpu =  dirs[-3:] 
                            # Define inputs from control table
                        inZoneData = path_dir + '/StreamLink' + rpu + '.tif'
                        if ctl.LandscapeLayer[line] == 'elev_cm':
                            ingrid_dir = NHD_dir
                            LandscapeLayer = ingrid_dir + '/' + '/NHDPlus' + region + '/NHDPlus' + hydro + '/NEDSnapshot/Ned' + rpu + '/elev_cm'
                        if ctl.LandscapeLayer[line] == 'fldown':
                            LandscapeLayer = ingrid_dir + '/' + ctl.LandscapeLayer[line] + '_' + rpu + '.tif' 
                        if ctl.LandscapeLayer[line] != 'elev_cm' and ctl.LandscapeLayer[line] != 'fldown':
                            LandscapeLayer = ingrid_dir + '/' +   ctl.LandscapeLayer[line]                         
                        outTable = out_dir_paths + '/' + ctl.Final_Table_Name[line] + '_' + rpu + '.dbf'
                        arcpy.env.cellSize = "30"
                        arcpy.env.snapRaster = inZoneData
                        if accum_type == 'Categorical':
                            if not arcpy.Exists(outTable):
                                TabulateArea(inZoneData, 'VALUE', LandscapeLayer, "Value", outTable, "30")
                        if accum_type == 'Continuous':
                            if not arcpy.Exists(outTable):
                                ZonalStatisticsAsTable(inZoneData, 'VALUE', LandscapeLayer, outTable, "DATA", "ALL")  
```


### Associate wetlands with flow paths
Also make adjustment to get wetland points associated with paths correctly
```{r, eval=F}
library(raster)
library(rgdal)
library(stringr)
library(foreign)
require(dplyr)

year = '2011'
path_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/CostPaths')
points_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPoints')
wetlands_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/AllWetlands_rpu')
fromto_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/FlowTables')
cat_path = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandCat/Accumulation/')
cat_dir = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD', year, '/WetlandCat/Accumulation/')
accum_path = paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/Accumulation/')

files = list.files(accum_path, pattern = 'NLCD'); rpus = c()
for(i in 1:length(files)){
  #print(files[i])
  rpus[i] = substr(files[i], 18, 20)
}

path_list = list.files(path_dir, pattern = "StreamLink")
path_list = path_list[grep('\\.tif$',path_list)]

point_list = list.files(points_dir, pattern = "WetlandPoints")
point_list = point_list[grep('\\.shp$',point_list)]

wetland_list = list.files(wetlands_dir, pattern = "Wetlands")
wetland_list = wetland_list[grep('\\.dbf$',wetland_list)]

fromto_list = list.files(fromto_dir, pattern = "FrmTo")
fromto_list  = fromto_list[grep('\\.tif$',fromto_list)]

fromtotable_list = list.files(fromto_dir, pattern = 'FrmTo')
fromtotable_list  = fromtotable_list[grep('\\.dbf$',fromtotable_list)]
drop_list  = fromtotable_list[grep('.vat.dbf',fromtotable_list)]
fromtotable_list = setdiff(fromtotable_list, drop_list)

count_all=0
count_paths=0
count_nopaths=0
for (i in 1:59){
  streamlink_ras = raster(paste0(path_dir,'/',path_list[i]))
  wetpoint = readOGR(points_dir, strsplit(point_list[i],'\\.')[[1]][1])
  wetland = read.dbf(paste0(wetlands_dir,'/',wetland_list[i]))
  wetland = wetland[c(1)]
  names(wetland)[1] = 'WET_ID'
  results = extract(streamlink_ras, wetpoint)
  wetpoint$STRMLNK_ID =  results
  wetpoint = wetpoint[c(1,6)]
  
  #Adjust for correct wetland - path association
  fromto_ras = raster(paste0(fromto_dir,'/',fromto_list[i]))
  fromto_table <- read.dbf(paste0(fromto_dir,'/',fromtotable_list[i]))
  results = extract(fromto_ras, wetpoint)
  wetpoint$REPLACE_ID =  results
  wetpoint$REPLACE_WET_ID = fromto_table$FLOWTOFINA[match(wetpoint$REPLACE_ID, fromto_table$VALUE)]
  wetpoint$STRMLNK_ID = ifelse(!is.na(wetpoint$REPLACE_WET_ID), wetpoint$REPLACE_WET_ID, wetpoint$STRMLNK_ID)
  
  # Identify wetlands with paths and with no paths (riparian / non-riparian)
  # We have to pull out riparian wetlands where path intersects the riparian wetland point.
  # We do this by finding any situations where two wetland IDs share the same path ID
  # We then identify the wetland with the larger basin area - this will always be
  # the downstream, riparian wetland
  
  wetpoint = wetpoint@data[,1:2]
  names(wetpoint)[1] = 'WET_ID'
  AllWetlands = wetpoint
  
  # Get area from wetland catchments
  precip = read.csv(paste0(cat_dir, 'US2yr24ha_mm_10x_MEAN_', rpus[i], '.csv'))
  precip$AreaSqKm = (precip$COUNT * 900) / 1e6
  dups <- AllWetlands[duplicated(AllWetlands$STRMLNK_ID) & !is.na(AllWetlands$STRMLNK_ID),]
  dups <- AllWetlands[AllWetlands$STRMLNK_ID %in% dups$STRMLNK_ID,]
  dups$AreaSqKm <- precip$AreaSqKm[match(dups$WET_ID, precip$BasinID)]
  Non_Riparian <- dups %>% group_by(STRMLNK_ID) %>% filter(AreaSqKm==min(AreaSqKm))
  Downstream <- dups %>% group_by(STRMLNK_ID) %>% filter(AreaSqKm==max(AreaSqKm))
  Riparian <- Downstream[nrow(fromto_table[fromto_table$STREAMLIN==15419,])==0]
  
  Riparian <- AllWetlands[!AllWetlands$STRMLNK_ID %in% fromto_table$STREAMLINK,]
  
  WetlandsNoPath = subset(AllWetlands, is.na(STRMLNK_ID) | WET_ID %in% Riparian$WET_ID)
  WetlandsWithPath = subset(wetpoint, !is.na(STRMLNK_ID) & !WET_ID %in% Riparian$WET_ID)
  
  count_all<=count_all + nrow(AllWetlands)
  count_paths<=count_paths + nrow(WetlandsWithPath)
  count_nopaths<=count_nopaths + nrow(WetlandsNoPath)
  
  WetlandsNoPath$Riparian = 1
  WetlandsWithPath$Riparian = 0
  AllWetlands = rbind(WetlandsNoPath,WetlandsWithPath)
  
  write.csv(AllWetlands, paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/LookupTables/AllWetlands_StreamLink_Lookup_',str_sub(strsplit(wetland_list[i],'\\.')[[1]][1],-3),'.csv'), row.names=FALSE)
  write.csv(WetlandsWithPath, paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/LookupTables/WetlandsWithPath_StreamLink_Lookup_',str_sub(strsplit(wetland_list[i],'\\.')[[1]][1],-3),'.csv'), row.names=FALSE)
  write.csv(WetlandsNoPath, paste0('L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/LookupTables/WetlandsNoPath_StreamLink_Lookup_',str_sub(strsplit(wetland_list[i],'\\.')[[1]][1],-3),'.csv'), row.names=FALSE)
}
```

## Wetland catchment processes

### Delineate wetland catchments
1. Check to see if catchments already exist
2. If no, run ArcGIS 'watershed' tool on all wetlands
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
# Import arcpy module
import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")

from datetime import datetime
import struct, decimal, itertools

arcpy.env.overwriteOutput = True

nhddir = 'L:/Priv/CORFiles/Geospatial_Library/Data/RESOURCE/PHYSICAL/HYDROLOGY/NHDPlusV21'
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
fullstreams_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'

# NLCD 2011
wetland_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands_rpu'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/WetCats'

# NLCD 2001
#wetland_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/IsolatedWetlands'
#watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandCat/WetCats'
inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
          
for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]
                Fullstreamsnull = fullstreams_dir + "/FullStreamsFDRNull" + rpu + ".tif"
                #Check to see if wetland catchments exist already
                if not os.path.exists(watershed_dir + '/WetlandCat_' + rpu + '.tif'):                     
                    print rpu  
                    startTime = time.time() 
                        #-- Create garbage cans --
                    garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
                    if not os.path.exists(garbage):
                        os.makedirs(garbage)
                    arcpy.env.workspace = garbage
                    arcpy.env.mask = Fullstreamsnull
                        #-- Delete garbage after run --
                    startTime = time.time()                      
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                        # Generate wetland watersheds                      
                    outWtshd = Watershed(fdr, wetland_dir + '/Wetlands_' + rpu + '.tif', "VALUE")
                        # Save watershed
                    outWtshd.save(watershed_dir + '/WetlandCat_' + rpu + '.tif')                    
                    print "Minutes for this region: " + str((time.time()-startTime) / 60.0) 
```

### Create catchment connections (from-to tables)
1. Shift the catchment in each of the 8 neighboring directions
2. Check each neighboring cell following conditions:
    * Does the cell have a different catchment ID as neighbor?
    * Does it flow into the neighboring cell?
3. If 'yes' to both questions, then connect in topology table
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}

# Import arcpy module
import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")
from datetime import datetime
import struct, decimal, itertools

arcpy.env.overwriteOutput = True

nhddir = 'H:/NHDPlusV21'
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
# NLCD 2011
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/IsolatedWetlands'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/WetCats'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/FlowTables'

# NLCD 2001
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/IsolatedWetlands'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandCat/WetCats'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandCat/FlowTables'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
          
for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]
                    # Check to see if wetland catchments exist already
                outDbf = frmto_dir + "/WetlandFrmTo" + rpu + ".dbf"
                if not os.path.exists(outDbf):
                        #-- Create garbage cans --
                    garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
                    if not os.path.exists(garbage):
                        os.makedirs(garbage)
                    arcpy.env.workspace = garbage
                        #-- Delete garbage after run --
                    startTime = time.time()   
                    print "Shifting region: " + rpu
                    Wtshds = Raster(watershed_dir + '/WetlandCat_' + rpu + '.tif')     
                    shift1 = arcpy.Shift_management(Wtshds, "shift1.tif", "-30", "0", Wtshds)
                    shift2 = arcpy.Shift_management(Wtshds, "shift2.tif", "-30", "30", Wtshds)
                    shift4 = arcpy.Shift_management(Wtshds, "shift4.tif", "0", "30", Wtshds)
                    shift8 = arcpy.Shift_management(Wtshds, "shift8.tif", "30", "30", Wtshds)
                    shift16 = arcpy.Shift_management(Wtshds, "shift16.tif", "30", "0", Wtshds)
                    shift32 = arcpy.Shift_management(Wtshds, "shift32.tif", "30", "-30", Wtshds)
                    shift64 = arcpy.Shift_management(Wtshds, "shift64.tif", "0", "-30", Wtshds)
                    shift128 = arcpy.Shift_management(Wtshds, "shift128.tif", "-30", "-30", Wtshds)                   
                    print "Minutes to shift this region: " + str((time.time()-startTime) / 60.0) 
                    
                        # Process: Raster Calculator                    
                    print 'Creating from-to connections'
                    startTime = time.time() 
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                    flowto1 = ((shift1 != Wtshds) * (fdr == 1)) * shift1
                    flowto1.save("FlowTo1.tif")
                    flowto1 = Raster("FlowTo1.tif")
                    flowto1 = Con(IsNull(flowto1),0,flowto1)
                    
                    flowto2 = ((shift2 != Wtshds) * (fdr == 2)) * shift2
                    flowto2.save("FlowTo2.tif")
                    flowto2 = Raster("FlowTo2.tif")
                    flowto2 = Con(IsNull(flowto2),0,flowto2)
                    
                    flowto4 = ((shift4 != Wtshds) * (fdr == 4)) * shift4
                    flowto4.save("FlowTo4.tif")
                    flowto4 = Raster("FlowTo4.tif")
                    flowto4 = Con(IsNull(flowto4),0,flowto4)
                    
                    flowto8 = ((shift8 != Wtshds) * (fdr == 8)) * shift8
                    flowto8.save("FlowTo8.tif")
                    flowto8 = Raster("FlowTo8.tif")
                    flowto8 = Con(IsNull(flowto8),0,flowto8)
                    
                    flowto16 = ((shift16 != Wtshds) * (fdr == 16)) * shift16
                    flowto16.save("FlowTo16.tif")
                    flowto16 = Raster("FlowTo16.tif")
                    flowto16 = Con(IsNull(flowto16),0,flowto16)
                    
                    flowto32 = ((shift32 != Wtshds) * (fdr == 32)) * shift32
                    flowto32.save("FlowTo32.tif")
                    flowto32 = Raster("FlowTo32.tif")
                    flowto32 = Con(IsNull(flowto32),0,flowto32)
                    
                    flowto64 = ((shift64 != Wtshds) * (fdr == 64)) * shift64
                    flowto64.save("FlowTo64.tif")
                    flowto64 = Raster("FlowTo64.tif")
                    flowto64 = Con(IsNull(flowto64),0,flowto64)
                    
                    flowto128 = ((shift128 != Wtshds) * (fdr == 128)) * shift128
                    flowto128.save("FlowTo128.tif")
                    flowto128 = Raster("FlowTo128.tif")
                    flowto128 = Con(IsNull(flowto128),0,flowto128)
                    
                    FlowToSum = flowto1 + flowto2 + flowto4 + flowto8 + flowto16 + flowto32 + flowto64 + flowto128
                    FlowToSum.save("FlowToSum.tif")
                    FlowToSum = Raster("FlowToSum.tif")
                    FlowToFinal = Con(FlowToSum != 0, FlowToSum)
                    FlowToFinal.save("FlowToFinal.tif")
                    
                    outCombine = Combine([FlowToFinal, Wtshds])
                    outCombine.save(working_dir + "/ScratchDir/WetlandFrmTo" + rpu + ".tif")

                    if not arcpy.Exists(outDbf):
                        arcpy.CopyRows_management(outCombine, outDbf, "")
                    print "Minutes to connect catchments in this region: " + str((time.time()-startTime) / 60.0) 
                    
                    try:
                        arcpy.Delete_management("FlowTo1.tif")
                        arcpy.Delete_management("FlowTo2.tif")
                        arcpy.Delete_management("FlowTo4.tif")
                        arcpy.Delete_management("FlowTo8.tif")
                        arcpy.Delete_management("FlowTo16.tif")
                        arcpy.Delete_management("FlowTo32.tif")
                        arcpy.Delete_management("FlowTo64.tif")
                        arcpy.Delete_management("FlowTo128.tif")
                        arcpy.Delete_management("shift1.tif")
                        arcpy.Delete_management("shift2.tif")
                        arcpy.Delete_management("shift4.tif")
                        arcpy.Delete_management("shift8.tif")
                        arcpy.Delete_management("shift16.tif")
                        arcpy.Delete_management("shift32.tif")
                        arcpy.Delete_management("shift64.tif")
                        arcpy.Delete_management("shift128.tif")
                        arcpy.Delete_management("FlowToSum.tif")
                        arcpy.Delete_management("FlowToFinal.tif")
                    except:
                        pass
```

### Create numpy files for accumulating wetland catchment results
1. Loops through from-to tables
2. Makes dictionary of next upstream catchment for each non-headwater catchment
3. Runs children and bastards functions to make full list of upstream catchments
4. Generates information such as length of each connection and saves results as 3 numpy vectors
    * comids<regionID>.npy - Vector of unique IDs for each wetland in region
    * lengths<regionID>.npy - Vector of the number of upstream catchments above each wetland. Children includes focal catchment, bastards excludes focal catchment
    * upCats<regionID>.npy - Vector of the unique IDs of each upstream catchment for each focal catchment listed in order. Focal catchment included for children, excluded for bastards
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import arcpy
import os, sys
import pysal as ps
import numpy as np
from collections import deque, defaultdict, OrderedDict

# NLCD 2011
numpy_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/WetCats_npy/'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/FlowTables/'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandCat/WetCats/'

# NLCD 2001
numpy_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandCat/WetCats_npy/'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandCat/FlowTables/'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandCat/WetCats/' 

#Need to set to where WetCat_function.py is stored

sys.path.append(wetcatfunc)  
from WetCat_functions import dbf2DF, children, bastards

files = filter(lambda x: x.endswith(('.dbf')) and not x.count('.tif'), os.listdir(frmto_dir))

for file in files:
    rpu = file[-7:-4]
    print rpu

        #Read in wetland catchments to get list of COMIDs    
    wetcat = watershed_dir + 'WetlandCat_' + rpu + '.tif'
    if not os.path.exists(wetcat + '.vat.dbf'):
        arcpy.BuildRasterAttributeTable_management(wetcat, "Overwrite")
    tbl = dbf2DF(wetcat + '.vat.dbf')
    COMIDs = tbl.VALUE.values      
    
        #Read in from-to table
    flow = dbf2DF(frmto_dir + file)[[1,3]] #Only need columns 1 and 3
    #print flow.head()
    print "Processing region: " + rpu + " with total records = " + str(len(flow))
    flow.columns = ['TOCOMID','FROMCOMID'] #Rename columns
    flow  = flow[flow.FROMCOMID != 0] #Remove paths with FROMCOMID == 0
    fromID = np.array(flow.FROMCOMID) #Make numpy arrays of from and to columns
    toID = np.array(flow.TOCOMID)
    
        #Make dictionary of next up catchment ID
    UpCOMs = defaultdict(list)
    for i in range(0, len(flow), 1):
        FROMID = fromID[i]
        TOID = toID[i]
        UpCOMs[TOID].append(FROMID)                              
        
        #Make and save bastards
    a = map(lambda x: bastards(x, UpCOMs), COMIDs) #Make bastards vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'bastards'):
        os.makedirs(numpy_dir + 'bastards')
    np.save(numpy_dir + 'bastards/upCats' + rpu + '.npy', a)
    np.save(numpy_dir + 'bastards/comids' + rpu + '.npy', COMIDs)
    np.save(numpy_dir + 'bastards/lengths' + rpu + '.npy', lengths)
    
         #Make and save children
    a = map(lambda x: children(x, UpCOMs), COMIDs) #Make children vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'children'):
        os.makedirs(numpy_dir + 'children')
    np.save(numpy_dir + 'children/upCats' + rpu + '.npy', a)
    np.save(numpy_dir + 'children/comids' + rpu + '.npy', COMIDs)
    np.save(numpy_dir + 'children/lengths' + rpu + '.npy', lengths)   
```


### Process rasters with wetland catchments to produce continuous or categorical summaries
1. Open control table and access information to process each raster
2. Loop through RPUs
3. Based on raster type, use ArcGIS functions to create catchment summaries
    * Categorical - TabulateArea
    * Continuous - ZonalStatisticsAsTable
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import os
import arcpy
from arcpy.sa import TabulateArea, ZonalStatisticsAsTable
arcpy.CheckOutExtension("spatial")
import pandas as pd

ctl_path = 'J:/GitProjects/Wetland Connectivity/WetlandScripts/'
ctl = pd.read_csv(ctl_path + 'ControlTable_Wetlands_NLCD2001.csv')

#-----------------------------------------------------------------------------
# Populate variables from control table
NHD_dir = ctl.DirectoryLocations.values[0]
basin_dir = ctl.DirectoryLocations.values[2]
out_dir_basins = ctl.DirectoryLocations.values[4]
numpy_dir = ctl.DirectoryLocations.values[7]
lookup_dir = ctl.DirectoryLocations.values[6]
#-----------------------------------------------------------------------------

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

for line in range(len(ctl.values)):
    if ctl.run[line] == 1:   
        print '---- Running: ' + str(ctl.LandscapeLayer[line]) + ' ----'
        accum_type = ctl.accum_type[line] 
        ingrid_dir = ctl.ingrid_dir[line]
            # Loop through RPUs
        for region in inputs.keys():
            for hydro in inputs[region]:
                print 'Region ' + region + ' and hydro number ' + hydro
                for dirs in os.listdir(NHD_dir + '/NHDPlus' + region + '/NHDPlus' + hydro):
                    if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                        rpu =  dirs[-3:] 
                            # Define inputs from control table
                        inZoneData = basin_dir + '/WetlandCat_' + rpu + '.tif'
                        LandscapeLayer = ingrid_dir + '/' + ctl.LandscapeLayer[line]
                        outTable = out_dir_basins + '/' + ctl.Final_Table_Name[line] + '_' + rpu + '.dbf'
                        arcpy.env.cellSize = "30"
                        arcpy.env.snapRaster = inZoneData
                        if accum_type == 'Categorical':
                            if not arcpy.Exists(outTable):
                                TabulateArea(inZoneData, 'VALUE', LandscapeLayer, "Value", outTable, "30")
                        if accum_type == 'Continuous':
                            if not arcpy.Exists(outTable):
                                ZonalStatisticsAsTable(inZoneData, 'VALUE', LandscapeLayer, outTable, "DATA", "ALL")  
```

## Accumulate path and catchment data

### Universal code to accumulate path or catchment metrics
* Uses control tables to determine whether path or basin metrics should be calculated
* Places results in appropriate directory (i.e., path or basin)
```{r, engine='python', engine.path='C:/Python27/ArcGIS10.3/python.exe', eval=F}
import pandas as pd
import numpy as np
import os, sys

wetcatfunc = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/WetlandConnectivity/ScriptsArchive/'
sys.path.append(wetcatfunc)  
from WetCat_functions import dbf2DF, Accumulation

ctl_path = 'D:/WorkFolder/WetConnect_Aug2016/'
ctl = pd.read_csv(ctl_path + 'ControlTable_Wetlands.csv')

    #Use any of the numpy files to get list of regions
numpy_dir = ctl.DirectoryLocations.values[8] + '/'
files = filter(lambda x: x.endswith(('.npy')) and x.count('lengths'), os.listdir(numpy_dir+'children'))

for line in range(len(ctl.values)):
    if ctl.run[line] == 1:   
        
        zonal_type = str.upper(ctl.MetricType[line]) #Type of zonal and accumulation metric to process
        var = ctl.Final_Table_Name[line] #Name of variable to be processed
        tbl_type = ctl.path_basin[line] #Name of type of table (basin or path)
        ID_column = str.capitalize(tbl_type) + 'ID'
        accum_type = ctl.accum_type[line]
            # Populate variables from control table
        if tbl_type == 'path':
            zonal_dir = ctl.DirectoryLocations.values[3] + '/'
            numpy_dir = ctl.DirectoryLocations.values[8] + '/'
            path_dir = ctl.DirectoryLocations.values[1] + '/'
            out_accum = ctl.DirectoryLocations.values[9] + '/'
            npIDvect = 'PathIDs'
            npNetwork = 'downPaths'
        else:
            zonal_dir = ctl.DirectoryLocations.values[4] + '/'    
            numpy_dir = ctl.DirectoryLocations.values[7] + '/'    
            path_dir = ctl.DirectoryLocations.values[2] + '/'
            out_accum = ctl.DirectoryLocations.values[10] + '/'     
            npIDvect = 'comids'
            npNetwork = 'upCats'
            
        print '---- Running: ' + var + ' ' + zonal_type + ' ----'
        for file in files:
            region = file[7:10]
            print region  
            startTime = time.time() 
            outFile = out_accum + var + '_' + zonal_type + '_' + region + '.csv'
            zonal_file =  zonal_dir + var + '_' + region + '.dbf'
                #Read in zonal table
            arr = dbf2DF(zonal_file)  
                #Which columns to keep or drop for accumulation
            if zonal_type == 'MEAN':    
                arr = arr[['VALUE', 'SUM', 'COUNT']]
            elif zonal_type != 'MEAN' and zonal_type != 'PERCENT':
                arr = arr[['VALUE', zonal_type]]                
                #Read in numpy vectors                        
            IDs = np.load(numpy_dir + 'children/' + npIDvect + region + '.npy')
            lengths = np.load(numpy_dir + 'children/lengths' + region + '.npy')
            network = np.load(numpy_dir + 'children/' + npNetwork + region + '.npy')
                #Make sure all path or ws IDs are accounted for
            if len(arr) != len(IDs):
                if tbl_type == 'path':
                    allIDs = dbf2DF(path_dir + 'StreamLink' + region + '.tif.vat.dbf')[['VALUE']]
                else:
                    allIDs = dbf2DF(path_dir + 'WetlandCat_' + region + '.tif.vat.dbf')[['VALUE']]
                arr = pd.merge(arr, allIDs, on = 'VALUE', how = 'right')

            df = Accumulation(arr, IDs, lengths, network, tbl_type=tbl_type, ID_column=ID_column, zonal_type=zonal_type)
            df.to_csv(out_accum + var + '_' + zonal_type + '_' + region + '.csv', index=False)
            print "Minutes for this region: " + str((time.time()-startTime) / 60.0)
```













