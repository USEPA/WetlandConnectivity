---
title: "Wetland Connectivity Processing Steps"
author: "Marc Weber & Ryan Hill"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    theme: yeti
    highlighted: default 
    toc: yes
    toc_float: true
---

The following steps lay out the approach to generate wetland flow paths and calculate wetland hydrological connectivity at a national level

## Wetland extraction and preparation

### Derive NLCD 2001 or 2011 based wetlands
Using both the 2001 and 2011 NLCD, we:

1. Extract wetland cells from NLCD 2011 raster
2. Use Arc region group tool to define contiguous wetland cells and assign a unique ID. The region 


```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import arcpy
import os
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env

# Set variables
nhddir = "L:/Priv/CORFiles/Geospatial_Library_Resource/PHYSICAL/HYDROLOGY/NHDPlusV21"
year = '2011'
wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD'+year+'/AllWetlands/'
out_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD'+year+'b/AllWetlands_rpu/'
#old_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD'+year+'/AllWetlands_rpu/'
Wetlands = Raster(wetlands_dir + "Wetlands.tif")

# for 2011
nlcd = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/nlcd2011.tif'
# for 2001
#nlcd = 'L:/Priv/CORFiles/Geospatial_Library_Resource/PHYSICAL/LAND_COVER/NLCD/nlcd_2001_landcover_2011_edition_2014_10_10/nlcd_2001_landcover_2011_edition_2014_10_10.img'

# Derive NLCD based wetlands
#NLCD = Raster(nlcd)
#wetlands = Con((NLCD == 90) | (NLCD == 95), 1,)
#if not arcpy.Exists(wetlands_dir + "/Wetlands" + ".tif"):
#    wetlands.save(wetlands_dir + "/Wetlands.tif")

# Now create unique wetland groups of contiguous wetland cells
inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
         'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']} 

i = 1
for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]
                #print i
                fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                cats = Raster(nhddir + "/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusCatchment/cat")
                arcpy.env.snapRaster = fdr
                arcpy.env.cellSize = "30"
                arcpy.env.mask = fdr
                arcpy.env.extent = fdr
                arcpy.env.compression = 'LZW'
                arcpy.env.parallelProcessingFactor = "100%"
                WetlandRegions = RegionGroup(Wetlands, "EIGHT", "WITHIN", "NO_LINK", "")
                #WetlandRegions = Raster(old_dir + 'WetlandsRgnGrp_'+rpu+'.tif')
                WetlandCats = arcpy.gp.Combine_sa([WetlandRegions, cats])
                WetlandCats = Raster(WetlandCats)
                if i ==1:                    
                    WetlandCats.save(out_dir + 'WetlandsRgnGrp_'+rpu+'.tif')
                else:
                    WetlandCats = WetlandCats + maxval
                    WetlandCats.save(out_dir + 'WetlandsRgnGrp_'+rpu+'.tif')
                maxval = arcpy.GetRasterProperties_management(WetlandCats, "MAXIMUM").getOutput(0)
                maxval = int(maxval)
                i = i + 1  
```

### Generate wetland points for each wetland group

1. Generate points for each raster cell in wetland groups  by RPU using Arc Raster to Point conversion tool
2. Uses gdal to read and write rasters (see read_raster and write_raster functions). The script flattens the rasters into 1-d vectors and then finds the point of maximum flow accumulation (fac raster) within each wetland (wet raster) with the ndimage.maximum_position function. These locations are then mapped into a new raster where these points in the new raster also have the wetland ID. 
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import arcpy
import os
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env
import geopandas as gp
import pandas as pd
import numpy as np
import numpy.ma as ma
from scipy import ndimage
try:
    import gdal
except:
    from osgeo import gdal
    
def read_raster(path):
    ds1 = gdal.Open(path)
    band1 = ds1.GetRasterBand(1)
    xsize = band1.XSize
    ysize = band1.YSize
    geotransform = ds1.GetGeoTransform()
    proj = ds1.GetProjection()
    return [xsize, ysize, geotransform, proj, 
            band1.ReadAsArray()]

def write_raster(raster, path, xsize, ysize, nodata, geotransform, proj):
    format = "GTiff"
    driver = gdal.GetDriverByName( format )
    dst_ds = driver.Create(path, xsize, ysize, 1, gdal.GDT_Int32, options = [ 'COMPRESS=LZW' ])
    dst_ds.SetGeoTransform(geotransform)
    dst_ds.SetProjection(proj)
    dst_ds.GetRasterBand(1).SetNoDataValue(nodata)
    dst_ds.GetRasterBand(1).WriteArray(raster)
    dst_ds = None

nhddir = "D:/GISData/NHDPlusV21"
#working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
working_dir = 'D:/WorkFolder/WetlandConnectivity/WetConnect_Apr2019'
year = '2011'
wetrpu_dir = working_dir + '/Wetlands_NLCD' + year + 'b/AllWetlands_rpu'
wetpoints_dir = working_dir + '/Wetlands_NLCD' + year + 'b/WetlandPoints'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

for region in inputs.keys():
    for hydro in inputs[region]:
        print 'on region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                print dirs
                rpu = dirs[-3:]
                
                if not arcpy.Exists(wetpoints_dir + "/WetlandPoints" + rpu + ".tif"):
                    #Convert rasters to numpy arrays
                    fac = read_raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fac")
                    xsize = fac[0]; ysize = fac[1]; geotransform = fac[2]; proj = fac[3]
                    fac = fac[4]
                    wet = read_raster(wetrpu_dir + "/WetlandsRgnGrp_" + rpu + ".tif")[4]
                    #Get raster attributes for later
                    shp = wet.shape
                    mn = np.min(wet)
                    #Flatten arrays 
                    wet = wet.flatten()
                    fac = fac.flatten()
                    #Create masked array that excludes nodata values from analysis
                    wet = ma.masked_values(wet, value=mn)
                    #Get unique values
                    unq = np.unique(wet)
                    #Find locations of max fac value within each wetland
                    locs = ndimage.maximum_position(fac, labels=wet, index=unq)
                    del(wet); del(fac)
                    #Create empty numpy array that has the same
                    empty = np.full(shp, mn, dtype='int32')
                    #Put wetland IDs into empty raster at max fac locations
                    empty.flat[locs] = unq
                    #write out raster
                    write_raster(empty, wetpoints_dir + "/WetlandPoints" + rpu + ".tif", xsize, ysize, mn, geotransform, proj)
                    del(empty); del(unq)
```  

## Create full stream rasters
### Create NLCD year specific full stream rasters (i.e. full streams for NLCD 2001 and NLCD 2011) using following steps:

1. Extract water cells (Value==11) from NLCD rasters to create NLCD water mask
2. By NHDPlusV2 'raster processing units (RPUS):

      a. Rasterize NHDPlusV2 flowlines of type 'ArtificialPath', 'Connector', and 'StreamRiver' using geopandas and rasterio
      b. Use the ArcGIS RegionGroup tool to group NLCD water mask raster cells into contiguously identified chunks
      c. Use ArcGIS times tool to muliply water mask region group raster and rasterized NHDPlus flowlines
      d. Use gdal and numpy to convert raster to a numpy array, and flatten 2d to 1d array and use numpy where clause to extract NLCD region group water mask pixels that abut rasterized NHDPlus flowlines in order to create 'full streams' rasters for each RPU (Ryan, elaborate or add on here if needed)
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
# Import arcpy module
import arcpy
import os
from arcpy.sa import *
# Check out any necessary licenses
arcpy.CheckOutExtension("spatial")
import numpy as np
import numpy.ma as ma
from osgeo import gdal
import osr
import geopandas as gpd
import fiona
import rasterio
from rasterio import features
arcpy.env.overwriteOutput = True

# Local variables:
working_dir = 'D:/WorkFolder/WetlandConnectivity/WetConnect_Apr2019'
scratch_dir = 'D:/WorkFolder/WetlandConnectivity/WetConnect_Apr2019/ScratchDir'
NHDDir = "D:/GISData/NHDPlusV21"
Year = '2011'
FullStreamsDir = working_dir + '/Wetlands_NLCD' + year + 'b/FullStreams'
raster_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/StreamCat/LandscapeRasters/QAComplete'
Mosaics_dir = raster_dir + '/WaterMask/Mosaics'
def array2raster(newRasterfn,rasterfn,array):
    geotransform = rasterfn.GetGeoTransform()
    originX = geotransform[0]
    originY = geotransform[3]
    pixelWidth = geotransform[1]
    pixelHeight = geotransform[5]
    cols = array.shape[1]
    rows = array.shape[0]

    driver = gdal.GetDriverByName('GTiff')
    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Byte)
    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))
    outband = outRaster.GetRasterBand(1)
    outband.WriteArray(array)
    outRasterSRS = osr.SpatialReference()
    outRasterSRS.ImportFromWkt(rasterfn.GetProjectionRef())
    outRaster.SetProjection(outRasterSRS.ExportToWkt())
    outband.FlushCache()

def records(filename, usecols, **kwargs):
    with fiona.open(filename, **kwargs) as source:
        for feature in source:
            f = {k: feature[k] for k in ['id', 'geometry']}
            f['properties'] = {k: feature['properties'][k] for k in usecols}
            yield f

def getRows(fn, idxList):
    reader = fiona.open(fn)
    return gpd.GeoDataFrame.from_features([reader[x] for x in idxList])
            

# Pull out NLCD Water to use in creating mask
if not arcpy.Exists(FullStreamsDir + '/NLCD_Water.tif'):
    if Year=='2001':
        nlcd = Raster('L:/Priv/CORFiles/Geospatial_Library_Resource/PHYSICAL/LAND_COVER/NLCD/nlcd_2001_landcover_2011_edition_2014_10_10/nlcd_2001_landcover_2011_edition_2014_10_10.img')
    if Year=='2011':    
        nlcd = Raster(raster_dir + '/nlcd2011.tif')
    NLCDWat = Con(nlcd ==11 ,1)
    NLCDWat.save(FullStreamsDir + '/NLCD_Water.tif')
    

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
for regions in inputs.keys():
    for hydro in inputs[regions]:
        print 'on region ' + regions + ' and hydro number ' + hydro
        hydrodir = "%s/NHDPlus%s/NHDPlus%s"%(NHDDir,regions, hydro)
        for subdirs in os.listdir(hydrodir):
            if subdirs.count("FdrNull") and not subdirs.count('.txt') and not subdirs.count('.7z'):
                print 'working on ' + subdirs
                
                # Read in the fdr null raster for hydroregion
                fdrnull = "%s/%s/fdrnull"%(hydrodir, subdirs)
                dsc=arcpy.Describe(fdrnull)
                arcpy.env.extent=dsc.Extent
                ext=dsc.Extent
                ll = arcpy.Point(ext.XMin, ext.YMin)
                arcpy.env.outputCoordinateSystem=dsc.SpatialReference
                arcpy.env.cellSize=dsc.meanCellWidth
                fdr = "%s/%s/fdr"%(hydrodir, subdirs.replace('Null','Fac'))
                arcpy.env.mask = fdr 
                
                
                #Convert NHD flowlines to raster
                flowline = NHDDir + "/NHDPlus" + regions + "/NHDPlus" + hydro + "/NHDSnapshot/Hydrography/NHDFlowline.shp"
                flowgrid = scratch_dir + '/flowgrid' + hydro
                if not arcpy.Exists(flowgrid):
                    flowline_sp = gpd.read_file(flowline)
                    flowline_sp = flowline_sp.loc[(flowline_sp['FTYPE'].isin([ 'ArtificialPath', 'Connector', 'StreamRiver'])) | (flowline_sp['FLOWDIR'] == 'With Digitized')]
                    flowline_sp['Junk'] = 1
                    rst = rasterio.open(fdr)
                    if flowline_sp.crs != rst.crs:
                        flowline_sp = flowline_sp.to_crs(rst.crs)
                    meta = rst.meta.copy()
                    meta.update(compress='lzw')
                    with rasterio.open(flowgrid, 'w', **meta) as out:
                        out_arr = out.read(1)
                        # this is where we create a generator of geom, value pairs to use in rasterizing
                        shapes = ((geom,value) for geom, value in zip(flowline_sp.geometry, flowline_sp.Junk))
                        
                        burned = features.rasterize(shapes=shapes, fill=0, out=out_arr, transform=out.transform)
                        out.write_band(1, burned)
                    
                StrmRas = Raster(scratch_dir + '/flowgrid' + hydro )
                # Process: Region Group - this gives each group of contiguous pixels a unique region ID
                NLCDWat = Raster(FullStreamsDir + '/NLCD_Water.tif')
                RegGrp = scratch_dir + '/RegionGroup_' + subdirs.split('Null',2)[1] + '.tif'
                if not arcpy.Exists(RegionGroup):
                    outRegGrp = RegionGroup(NLCDWat, "EIGHT", "WITHIN", "NO_LINK", "")
                    # Save the output 
                    outRegGrp.save(RegGrp)
                                                
                # Now multiply the region group raster by the stream raster
                RgnGrp = Raster(RegGrp)
                OutTimes = Times(StrmRas,RgnGrp)
                if not arcpy.Exists(scratch_dir + '/OutTimes_' + subdirs.split('Null',2)[1] + '.tif'):
                    OutTimes.save(scratch_dir + '/OutTimes_' + subdirs.split('Null',2)[1] + '.tif')
                if not arcpy.Exists(FullStreamsDir + '/WaterMask_' + subdirs.split('Null',2)[1] + '.tif'):
                    # Convert Rasters to numpy arrays
                    OutTimes = gdal.Open(scratch_dir + '/OutTimes_' + subdirs.split('Null',2)[1] + '.tif')
                    OutTimes_arr = np.array(OutTimes.GetRasterBand(1).ReadAsArray())
                    shp = OutTimes_arr.shape
                    unq = np.unique(OutTimes_arr) #Get unique values for query
                    del(OutTimes_arr)
                    unq = unq[1:] #The first member of the vector will be -32768. Let's us set new grid == 1 
                    #This is what the vector looked like before removing the first element:
                    #unq
                    #Out[46]: array([-32768,      3,      7, ...,   2462,   2464,   2466], dtype=int16)
                    RgnGrp = gdal.Open(scratch_dir + '/RegionGroup_' + subdirs.split('Null',2)[1] + '.tif')
                    RgnGrp_arr = np.array(RgnGrp.GetRasterBand(1).ReadAsArray())                    
                    RgnGrp_arr = RgnGrp_arr.flatten() #Flatten 2d array to 1d
                    z = np.where(np.in1d(RgnGrp_arr, unq), 1, np.NaN)
                    del(RgnGrp_arr)
                    #z = np.where(np.in1d(RgnGrp_arr, unq), RgnGrp_arr, np.NaN) #Make NaN where no match
                    #z[z==-32768] = np.NaN #Brings in big neg number when read into Python. Turn to NaN
                    z.shape = shp #Reshape back to 2d
                    
                    #newRaster = arcpy.NumPyArrayToRaster(z, ll, dsc.meanCellWidth, dsc.meanCellHeight) #Make ESRI raster
                    newraster= array2raster(scratch_dir + '/OutTimesV2_' + subdirs.split('Null',2)[1] + '.tif', OutTimes, z)
                    del(z)
                    newRaster = Raster(scratch_dir + '/OutTimesV2_' + subdirs.split('Null',2)[1] + '.tif')
                    WaterMask = Con(newRaster == 1, 1) #run it through a process to get it to be integer and in native ESRI format (exclude odd NUMPY stuff)                
                    WaterMask.save(FullStreamsDir + '/WaterMask_' + subdirs.split('Null',2)[1] + '.tif')
                if not arcpy.Exists(FullStreamsDir + '/FullStreams_' + subdirs.split('Null',2)[1] + '.tif'):
                    WaterMask = Raster(FullStreamsDir + '/WaterMask_' + subdirs.split('Null',2)[1] + '.tif')
                    StrmRas = Con(IsNull(StrmRas),0,1)
                    WaterMask = Con(IsNull(WaterMask),0,1)
                    FullStreams = StrmRas + WaterMask
                    FullStreams = Con(FullStreams >= 1, 1,)
                    FullStreams.save(FullStreamsDir + '/FullStreams_' + subdirs.split('Null',2)[1] + '.tif')
                if not arcpy.Exists(FullStreamsDir + '/FullStreamsFDRNull' + subdirs.split('Null',2)[1] + '.tif'):
                    FullStreams = Raster(FullStreamsDir + '/FullStreams_' + subdirs.split('Null',2)[1] + '.tif')
                    FDR_Ras = Raster("%s/%s/fdr"%(hydrodir, subdirs.replace('Null','Fac')))
                    FullStreams = Con(IsNull(FullStreams),0)
                    FDRNull = FullStreams + FDR_Ras
                    FDRNull.save(FullStreamsDir + '/FullStreamsFDRNull' + subdirs.split('Null',2)[1] + '.tif')
```

## Wetland path processes
### Generate Cost Paths from each wetland outlet point to NHDPlus stream lines for each NLCD year
* Create cost paths
  1. Recode flow direction grid to backlink grid (seems to prefer it this way) 
  2. Use NHDPlus hydrodem as cost distance input grid, but add the abs(min) value to remove negative values
  3. Use wetland outlets as sources & full streams grid as destination (coded as 0 in backlink grid)
  4. We need each wetland outlet point to have a unique ID. The StreamLink process creates a unique ID for each contiguous set of pixels without additional "stream" pixels joining the path. This is good, except where a wetland point is along a contiguous path. We buffer the points by 1 pixel to trick the algorithm into giving a unique ID for the wetland points. These buffered pixels will be removed from the results later.
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import os
import arcpy
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env
from datetime import datetime
import geopandas as gpd
from collections import OrderedDict 
import pandas as pd
# Use half of the cores on the machine.
arcpy.env.parallelProcessingFactor = "100%"
arcpy.env.compression = "LZW"

nhddir = 'D:/GISData/NHDPlusV21'
#working_dir = 'F:/WetlandConnectivity/SpatialData'
working_dir = 'D:/WorkFolder/WetlandConnectivity/WetConnect_Apr2019'
year = '2011'

fullstreams_dir = working_dir + '/Wetlands_NLCD' + year + 'b/FullStreams'
paths_dir = working_dir + '/Wetlands_NLCD' + year + 'b/WetlandPath/CostPaths'
wetpoints_dir = working_dir + '/Wetlands_NLCD' + year + 'b/WetlandPoints'

hydroregions = pd.read_csv(working_dir + '/hydro-regions.csv')

nope = list()

for i in range(len(hydroregions)):
    region = hydroregions.ix[i][0]
    hydro = hydroregions.ix[i][2]
    rpu = hydroregions.ix[i][1]
    print 'on region ' + region + ' and hydro number ' + hydro + ' and rpu ' + rpu    
    
    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
    arcpy.env.snapRaster = fdr
    arcpy.env.cellSize = "30"
    arcpy.env.mask = fdr
    arcpy.env.extent = fdr
            
    if not arcpy.Exists(paths_dir + '/CostPath' + rpu +'.tif'):

        WetPoints = wetpoints_dir + "/WetlandPoints" + rpu + ".tif" 
        FullStreams = Raster(fullstreams_dir + '/FullStreams_' + rpu + '.tif')
        Fullstreamsnull = fullstreams_dir + "/FullStreamsFDRNull" + rpu + ".tif"
        backlink = paths_dir + '/backlink/Backlink_' + rpu + '.tif'

        #Recode flow direction grid to backlink grid (seems to prefer it this way) 
        if not arcpy.Exists(backlink):
            arcpy.gp.Reclassify_sa(Fullstreamsnull, "Value",
                                   "0 NODATA;1 1;2 2;4 3;8 4;16 5;32 6;64 7;128 8;NODATA 0",
                                   backlink, "DATA")

        if not arcpy.Exists(working_dir + '/scratch2/hydrodem'+ rpu + '.tif'):
            #Read in hydrodem 
            hydrodem = Raster(nhddir + "/NHDPlus" + region + "/NHDPlus" + hydro + "/NHDPlusHydrodem" + rpu + "/hydrodem")
            #Add the absolute value of the min to so that no values < 0
            hydrodem = (hydrodem + abs(hydrodem.minimum)) / 100
            #Read backlink in as raster
            backlink = Raster(backlink)
            #Set stream cells in backlink to 0s in elevation raster (gives algorithm stopping point and runs much faster)
            hydrodem = hydrodem * Con(backlink == 0, 0, 1)
            hydrodem.save(working_dir + '/scratch2/hydrodem'+ rpu +'.tif')   
            
        if not arcpy.Exists(paths_dir + '/CostPath' + rpu +'.tif'):
            try:
                print 'yehaa!'
                arcpy.gp.CostPath_sa(WetPoints, 
                                     working_dir + '/scratch2/hydrodem'+ rpu +'.tif', 
                                     paths_dir + '/backlink/Backlink_' + rpu + '.tif', 
                                     paths_dir + '/CostPath' + rpu +'.tif', 'EACH_CELL')
            except:
                nope.append(rpu)
                print 'nope'
                pass

        if not arcpy.Exists(working_dir + "/ScratchDir/RasterPointsExpand" + rpu + ".tif"):
            # Expand the rasterized wetlands points to force each point gets unique value during StreamLink
            Points = Raster(wetpoints_dir + "/WetlandPoints" + rpu + ".tif")
            Points = Con(Points >= 1, 1,)
            outExpand = Expand(Points, 1, 1)
            outExpand.save(working_dir + "/ScratchDir/RasterPointsExpand" + rpu + ".tif")
            
        if not arcpy.Exists(working_dir + "/ScratchDir/ExpandCost" + rpu + ".tif"):
            # Mosaic expanded points raster and cost path raster set to 1
            input1 = Raster(working_dir + "/ScratchDir/RasterPointsExpand" + rpu + ".tif")
            input1 = Con(IsNull(input1),0,input1)
            input2 = Raster(paths_dir + "/CostPath" + rpu + ".tif")
            input2 = Con(IsNull(input2), 0, 1)
            #cost = Raster(paths_dir + '/CostPath' + rpu + '.tif')
#                    arcpy.env.mask = cost
#                    arcpy.env.snapRaster = cost
            output = input1 + input2
            output2 = Con(output>=1,1)
            output2.save(working_dir + "/ScratchDir/ExpandCost" + rpu + ".tif")
        if not arcpy.Exists(paths_dir + "/StreamLinkExp" + rpu + ".tif"):
            # Run stream link on the cost path to 'uniqueify' the sections
            # Execute StreamLink
            arcpy.gp.StreamLink_sa(working_dir + "/ScratchDir/ExpandCost" + rpu + ".tif", fdr, paths_dir + "/StreamLinkExp" + rpu + ".tif")  


```

### Fix duplicated PathIDs in StreamLink rasters
StreamLink should create unique IDs for each wetland flow segment and, hence, each wetland outlet. In the previous step, we buffered each wetland outlet in an attempt to enforce unique IDs. However, this approach fails if all adjoining pixels in the expanded outlet location are flowing in the same direction and now flowing into the outlet point. In these cases, we need to find duplicated IDs and replace them with a new unique ID.

1. Find duplicated values in StreamLink raster at wetland points by multiplying wetland points (converted to 1s/NAs) by StreamLink
2. Create numpy arrays from both, flatten 2d array to 1d array, find duplicated values and replace 
3. Replace duplicated values with values that start at the max value in the IDs raster and go to the total number of duplicated values. The process fails (crashes python without error), so we split the raster into 10 pieces and process individually
4. Resize raster and set original cost path raster as mask to remove expanded pixels from previous step

```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import arcpy
from arcpy.sa import *
arcpy.CheckOutExtension("Spatial")
from arcpy import env
from datetime import datetime
import geopandas as gpd
from collections import OrderedDict 
import pandas as pd
import numpy as np
import time
import gdal
import numpy.ma as ma

arcpy.env.parallelProcessingFactor = "100%"
arcpy.env.compression = "LZW"

def read_raster(path):
    ds1 = gdal.Open(path)
    band1 = ds1.GetRasterBand(1)
    xsize = band1.XSize
    ysize = band1.YSize
    geotransform = ds1.GetGeoTransform()
    proj = ds1.GetProjection()
    return [xsize, ysize, geotransform, proj, 
            band1.ReadAsArray()]

def write_raster(raster, path, xsize, ysize, nodata, geotransform, proj):
    format = "GTiff"
    driver = gdal.GetDriverByName( format )
    dst_ds = driver.Create(path, xsize, ysize, 1, gdal.GDT_Int32, options = [ 'COMPRESS=LZW' ])
    dst_ds.SetGeoTransform(geotransform)
    dst_ds.SetProjection(proj)
    dst_ds.GetRasterBand(1).SetNoDataValue(nodata)
    dst_ds.GetRasterBand(1).WriteArray(raster)
    dst_ds = None

nhddir = 'D:/GISData/NHDPlusV21'
#working_dir = 'F:/WetlandConnectivity/SpatialData'
working_dir = 'D:/WorkFolder/WetlandConnectivity/WetConnect_Apr2019'
year = '2011'

paths_dir = working_dir + '/Wetlands_NLCD' + year + 'b/WetlandPath/CostPaths'
wetpoints_dir = working_dir + '/Wetlands_NLCD' + year + 'b/WetlandPoints'

hydroregions = pd.read_csv(working_dir + '/hydro-regions.csv')

for i in range(len(hydroregions)):
    t1 = time.time() #get start time
    region = hydroregions.ix[i][0]
    hydro = hydroregions.ix[i][2]
    rpu = hydroregions.ix[i][1]
    print 'on region ' + region + ' and hydro number ' + hydro + ' and rpu ' + rpu  
    outRas = paths_dir + '/StreamLink_' + rpu + '.tif'
    if not arcpy.Exists(outRas):
    #Check to see if values need to be replaced in the raster
        
        #Set extent, cell size, mask, snapraster
        fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
        arcpy.env.snapRaster = fdr
        arcpy.env.cellSize = "30"
        arcpy.env.mask = fdr
        arcpy.env.extent = fdr
        #Make wetland points == 1, multiply by stream link raster to find duplicates
        points = Raster(wetpoints_dir + '/WetlandPoints' + rpu + '.tif')
        points = Con(points > -9999, 1)
        streamlink = Raster(paths_dir + '/StreamLinkExp' + rpu + '.tif')
        points = points * streamlink 
        #Save temp raster because ESRI raster to numpy conversion bonks randomly
        if not arcpy.Exists(working_dir + '/ScratchDir/points' + rpu + '.tif'):
            points.save(working_dir + '/ScratchDir/points' + rpu + '.tif')  
        points = read_raster(working_dir + '/ScratchDir/points' + rpu + '.tif')[4]
        #Flatten raster, remove NAs, find duplicated IDs among unique IDs
        points = points.flatten()
        rm_na = np.in1d(points, np.min(points), invert=True)
        points = points[rm_na]    
        points, c = np.unique(points, return_counts=True)
        dup = points[c > 1]

        if len(dup) > 0: 
            #Read in raster and get raster info
            rst = read_raster(paths_dir + '/StreamLinkExp' + rpu + '.tif')
            xsize = rst[0]; ysize = rst[1]; geotransform = rst[2]; proj = rst[3]
            rst = rst[4]            
            shp = rst.shape #Get initial shape of rst
            rst = rst.flatten() #flatten rst
            #Get max val (NA value) because unsigned int
            mx = np.max(rst)
            rst = ma.masked_values(rst, value=mx) #Make masked raster to ignore NAs
            query1 = np.in1d(rst, dup) #Find duped cells in rst (boolean vector)
            #Define start and end of sequence that will replace these values
            start = np.max(rst) + 1
            end = start + np.sum(query1)
            sequence = np.arange(start,end, 1)
            #Replace rst values with sequence values where boolean == True
            #Much faster than the loop if it will run
            #np.place not throwing error, simply crashing python. Can't use try/except as control
            #try:
            #    np.place(rst, query1, sequence) #This code kept crashing python
            #except:
            #Break array into 10 parts   - don't need if np.place works 
            splits = np.array_split(rst, 10)  
            x = 0
            for k, split in enumerate(splits):
                query_i = np.in1d(splits[k], dup)#Find boolean of need replace 
                if np.sum(query_i) > 0:
                    splitseq = sequence[x:x + np.sum(query_i)]#Split seq vector
                    np.place(splits[k], query_i, splitseq)#Replace values with seq   
                if k == 0:
                    rst = splits[k]
                else:
                    rst = np.append(rst, splits[k])
                x = x + np.sum(query_i)
            #Reshape and write out raster
            rst.shape = shp
        else:
            #Still need to read raster in to mask even if no values replaced
            rst = read_raster(paths_dir + '/StreamLinkExp' + rpu + '.tif')
            xsize = rst[0]; ysize = rst[1]; geotransform = rst[2]; proj = rst[3]
            rst = rst[4]         
        #Save temp rater because ESRI bonks on converting
        tempraster = working_dir + '/ScratchDir/streamlinkfixed' + rpu + '.tif'            
        write_raster(rst, tempraster, xsize, ysize, mx, geotransform, proj)
        #Set cost paths as mask and snap
        cost = Raster(paths_dir + '/CostPath' + rpu + '.tif')
        arcpy.env.mask = cost
        arcpy.env.snapRaster = cost
        #Filter to match cost raster data areas (removes expanded pixels from prev. process)        
        tmp_link = Raster(tempraster)
        tmp_link = Con(tmp_link > -9999, tmp_link)
        tmp_link.save(outRas)
        #arcpy.CopyRaster_management(tempraster, outRas, "", "", "", "", "", "32_BIT_SIGNED")
        print '---Minutes to process: '+str((time.time() - t1)/60)+'---' 
```

### Create the flow path connections (from-to tables)

1. Shift the paths in each of the 8 neighboring directions
2. Check each neighboring cell following conditions:
    * Does the cell have a different path ID as neighbor?
    * Does it flow into the neighboring cell?
3. If 'yes' to both questions, then connect in topology table and write out (along with flow connection raster)
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}

# Import arcpy module
import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")
import time
import pandas as pd

arcpy.env.overwriteOutput = True
arcpy.env.parallelProcessingFactor = "100%"
arcpy.env.compression = "LZW"

nhddir = 'D:/GISData/NHDPlusV21'
#working_dir = 'F:/WetlandConnectivity/SpatialData'
working_dir = 'D:/WorkFolder/WetlandConnectivity/WetConnect_Apr2019'
year = '2011'

paths_dir = working_dir + '/Wetlands_NLCD' + year + 'b/WetlandPath/CostPaths'
frmto_dir = working_dir + '/Wetlands_NLCD' + year + 'b/WetlandPath/FlowTables'
     
hydroregions = pd.read_csv(working_dir + '/hydro-regions.csv')

for i in range(len(hydroregions)):
    region = hydroregions.ix[i][0]
    hydro = hydroregions.ix[i][2]
    rpu = hydroregions.ix[i][1]
    print 'on region ' + region + ' and hydro number ' + hydro + ' and rpu ' + rpu  
    # Check to see if wetland paths from to exist already
    outcsv = frmto_dir + "/WetlandFrmTo" + rpu + ".csv"
    if not os.path.exists(working_dir + '/ESRI_garbage/garbage_' + rpu):
            #-- Create garbage cans --
        garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
        if not os.path.exists(garbage):
            os.makedirs(garbage)
        arcpy.env.workspace = garbage
            #-- Delete garbage after run --
        startTime = time.time()
        fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
        arcpy.env.snapRaster = fdr
        description = arcpy.Describe(fdr)  
        cellsize = description.children[0].meanCellHeight 
        arcpy.env.cellSize = cellsize
        arcpy.env.mask = fdr
        arcpy.env.extent = fdr
        print "Shifting region: " + rpu
        Paths = Raster(paths_dir + '/StreamLink_' + rpu + '.tif')     
        shift1 = arcpy.Shift_management(Paths, "shift1.tif", "-%s"%(cellsize), "0", Paths)
        shift2 = arcpy.Shift_management(Paths, "shift2.tif", "-%s"%(cellsize), "%s"%(cellsize), Paths)
        shift4 = arcpy.Shift_management(Paths, "shift4.tif", "0", "%s"%(cellsize), Paths)
        shift8 = arcpy.Shift_management(Paths, "shift8.tif", "%s"%(cellsize), "%s"%(cellsize), Paths)
        shift16 = arcpy.Shift_management(Paths, "shift16.tif", "%s"%(cellsize), "0", Paths)
        shift32 = arcpy.Shift_management(Paths, "shift32.tif", "%s"%(cellsize), "-%s"%(cellsize), Paths)
        shift64 = arcpy.Shift_management(Paths, "shift64.tif", "0", "-%s"%(cellsize), Paths)
        shift128 = arcpy.Shift_management(Paths, "shift128.tif", "-%s"%(cellsize), "-%s"%(cellsize), Paths)  
        print "Minutes to shift this region: " + str((time.time()-startTime) / 60.0) 
        
        # Process: Raster Calculator                    
        print 'Creating from-to connections'
        startTime = time.time() 
        fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
        flowto1 = ((shift1 != Paths) * (fdr == 1)) * shift1
        flowto1.save("FlowTo1.tif")
        flowto1 = Raster("FlowTo1.tif")
        flowto1 = Con(IsNull(flowto1),0,flowto1)
        
        flowto2 = ((shift2 != Paths) * (fdr == 2)) * shift2
        flowto2.save("FlowTo2.tif")
        flowto2 = Raster("FlowTo2.tif")
        flowto2 = Con(IsNull(flowto2),0,flowto2)
        
        flowto4 = ((shift4 != Paths) * (fdr == 4)) * shift4
        flowto4.save("FlowTo4.tif")
        flowto4 = Raster("FlowTo4.tif")
        flowto4 = Con(IsNull(flowto4),0,flowto4)
        
        flowto8 = ((shift8 != Paths) * (fdr == 8)) * shift8
        flowto8.save("FlowTo8.tif")
        flowto8 = Raster("FlowTo8.tif")
        flowto8 = Con(IsNull(flowto8),0,flowto8)
        
        flowto16 = ((shift16 != Paths) * (fdr == 16)) * shift16
        flowto16.save("FlowTo16.tif")
        flowto16 = Raster("FlowTo16.tif")
        flowto16 = Con(IsNull(flowto16),0,flowto16)
        
        flowto32 = ((shift32 != Paths) * (fdr == 32)) * shift32
        flowto32.save("FlowTo32.tif")
        flowto32 = Raster("FlowTo32.tif")
        flowto32 = Con(IsNull(flowto32),0,flowto32)
        
        flowto64 = ((shift64 != Paths) * (fdr == 64)) * shift64
        flowto64.save("FlowTo64.tif")
        flowto64 = Raster("FlowTo64.tif")
        flowto64 = Con(IsNull(flowto64),0,flowto64)
        
        flowto128 = ((shift128 != Paths) * (fdr == 128)) * shift128
        flowto128.save("FlowTo128.tif")
        flowto128 = Raster("FlowTo128.tif")
        flowto128 = Con(IsNull(flowto128),0,flowto128)
        
        FlowToSum = flowto1 + flowto2 + flowto4 + flowto8 + flowto16 + flowto32 + flowto64 + flowto128
        FlowToSum.save("FlowToSum.tif")
        FlowToSum = Raster("FlowToSum.tif")
        FlowToFinal = Con(FlowToSum != 0, FlowToSum)
        FlowToFinal.save("FlowToFinal.tif")
        
        ft = read_raster(working_dir + '/ESRI_garbage/garbage_' + rpu + '/FlowToFinal.tif')[4]
        sl = read_raster(paths_dir + '/StreamLink_' + rpu + '.tif')[4]
        ft = ft.flatten(); sl = sl.flatten()
        mask = ft > np.min(ft)
        ft = ft[mask]
        sl = sl[mask]
        fromto = pd.DataFrame({'From':sl, 'To':ft})
        fromto.to_csv(outcsv, index=False)          

        print "Minutes to connect flowpaths in this region: " + str((time.time()-startTime) / 60.0) 
        
        try:
            arcpy.Delete_management("FlowTo1.tif")
            arcpy.Delete_management("FlowTo2.tif")
            arcpy.Delete_management("FlowTo4.tif")
            arcpy.Delete_management("FlowTo8.tif")
            arcpy.Delete_management("FlowTo16.tif")
            arcpy.Delete_management("FlowTo32.tif")
            arcpy.Delete_management("FlowTo64.tif")
            arcpy.Delete_management("FlowTo128.tif")
            arcpy.Delete_management("shift1.tif")
            arcpy.Delete_management("shift2.tif")
            arcpy.Delete_management("shift4.tif")
            arcpy.Delete_management("shift8.tif")
            arcpy.Delete_management("shift16.tif")
            arcpy.Delete_management("shift32.tif")
            arcpy.Delete_management("shift64.tif")
            arcpy.Delete_management("shift128.tif")
            arcpy.Delete_management("FlowToSum.tif")
            arcpy.Delete_management("FlowToFinal.tif")
        except:
            pass
```

### Create numpy files for accumulating wetland path results

1. Loops through from-to tables
2. Makes dictionary of next downstream path for each non-terminal wetland path
3. Runs bastards function to make full list of downstream flowpaths
4. Generates information such as length of each connection and saves results as 3 numpy vectors
    * comids<regionID>.npy - Vector of unique IDs for each wetland in region
    * lengths<regionID>.npy - Vector of the number of upstream catchments above each wetland. Children includes focal catchment, bastards excludes focal catchment
    * downPaths<regionID>.npy - Vector of the unique IDs of each downstream path for each focal path listed in order. 

```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import arcpy
import os, sys
import pysal as ps
import numpy as np
import pandas as pd
from collections import deque, defaultdict, OrderedDict
#Need to set to where WetCat_function.py is stored
wetcatfunc = 'D:/WorkFolder/WetlandConnectivity/WetConnect_Apr2019/scripts'
sys.path.append(wetcatfunc)  
from WetCat_functions import children, bastards

#year = '2001'
year = '2011'
working_dir = 'D:/WorkFolder/WetlandConnectivity/WetConnect_Apr2019'
numpy_dir = working_dir + '/Wetlands_NLCD' + year + 'b/WetlandPath/WetPaths_npy/'
frmto_dir = working_dir + '/Wetlands_NLCD' + year + 'b/WetlandPath/FlowTables/'
Paths_dir = working_dir + '/Wetlands_NLCD' + year + 'b/WetlandPath/CostPaths/'


files = filter(lambda x: x.endswith(('.csv')) , os.listdir(frmto_dir))

for file in files:
    rpu = file[-7:-4]
    print rpu

    #Read in wetland paths to get list of path IDs    
    wetpath = Paths_dir + 'StreamLink_' + rpu + '.tif'
    if not os.path.exists(wetpath + '.vat.dbf'):
        arcpy.BuildRasterAttributeTable_management(wetpath, "Overwrite")
    tbl = dbf2DF(wetpath + '.vat.dbf')
    PathIDs = tbl.VALUE.values      
    
    #Read in from-to table
    #flow = dbf2DF(frmto_dir + file)[['FLOWTOFINA','STREAMLINK']] 
    flow = pd.read_csv(frmto_dir + file)
    #print flow.head()
    print "Processing region: " + rpu + " with total records = " + str(len(flow))
    #flow.columns = ['TOCOMID','FROMCOMID'] #Rename columns
    fromID = np.array(flow.From) #Make numpy arrays of from and to columns
    toID = np.array(flow.To)
    
    #Make dictionary of next up catchment ID
    DownIDs = defaultdict(list)
    for i in range(0, len(flow), 1):
        FROMID = fromID[i]
        TOID = toID[i]
        DownIDs[FROMID].append(TOID)                              
        
    #Make and save bastards
    a = map(lambda x: bastards(x, DownIDs), PathIDs) #Make bastards vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'bastards'):
        os.makedirs(numpy_dir + 'bastards')
    np.save(numpy_dir + 'bastards/downPaths' + rpu + '.npy', a)
    np.save(numpy_dir + 'bastards/PathIDs' + rpu + '.npy', PathIDs)
    np.save(numpy_dir + 'bastards/lengths' + rpu + '.npy', lengths)
    
    #Make and save children
    a = map(lambda x: children(x, DownIDs), PathIDs) #Make children vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'children'):
        os.makedirs(numpy_dir + 'children')
    np.save(numpy_dir + 'children/downPaths' + rpu + '.npy', a)
    np.save(numpy_dir + 'children/PathIDs' + rpu + '.npy', PathIDs)
    np.save(numpy_dir + 'children/lengths' + rpu + '.npy', lengths)        
```

### Create the flow length rasters for calculating flow distances
Flow distances are based on DEMs

```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import arcpy
from arcpy import env
from arcpy.sa import *
arcpy.CheckOutExtension("spatial")

import os
import time

#year = '2001'
year = '2011'
working_dir = 'D:/WorkFolder/WetlandConnectivity/WetConnect_Apr2019'
streams_dir =  working_dir + '/Wetlands_NLCD' + year + 'b/FullStreams/'
out_dir =  working_dir + '/Wetlands_NLCD' + year + 'b/FlowLengthsDown/'

files = filter(lambda x: x.endswith(('.tif')) and x.count(('FDRNull')), os.listdir(streams_dir))

for fdrnull in files:
    start_time = time.time() 
    print 'Processing: ' + fdrnull 
    outRas = out_dir + 'fldown_' + fdrnull[18:]
    
    outFlowLength = FlowLength(streams_dir + fdrnull, 'DOWNSTREAM','')
    outFlowLength.save(outRas)
    print("Duration: --- %s seconds ---" % (time.time() - start_time))
```

### Create expanded stream rasters for determining riparian wetlands (wetland pour points adjacent to streams)

```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import arcpy
import os
from arcpy.sa import *
# Check out any necessary licenses
arcpy.CheckOutExtension("spatial")
import numpy as np
import numpy.ma as ma
from osgeo import gdal
import osr

year = '2011'
arcpy.env.overwriteOutput = True

# Local variables:
NHDDir = "H:/NHDPlusV21"
StreamDir = "L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD" + year + "/FullStreams/"
inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
for regions in inputs.keys():
    for hydro in inputs[regions]:
        hydrodir = "%s/NHDPlus%s/NHDPlus%s"%(NHDDir,regions, hydro)
        for subdirs in os.listdir(hydrodir):
            if subdirs.count("FdrNull") and not subdirs.count('.txt') and not subdirs.count('.7z'):
                print 'working on ' + subdirs[-3:]
                
                # Read in the fdr null raster for hydroregion
                fdrnull = "%s/%s/fdrnull"%(hydrodir, subdirs)
                dsc=arcpy.Describe(fdrnull)
                arcpy.env.extent=dsc.Extent
                ext=dsc.Extent
                ll = arcpy.Point(ext.XMin, ext.YMin)
                arcpy.env.outputCoordinateSystem=dsc.SpatialReference
                arcpy.env.cellSize=dsc.meanCellWidth
                fdr = "%s/%s/fdr"%(hydrodir, subdirs.replace('Null','Fac'))
                arcpy.env.mask = fdr 
                
                Streams = StreamDir + 'FullStreams_' + subdirs[-3:] + '.tif'
                # Execute Expand
                outExpand = Expand(Streams, 1, 1)
                # Save the output 
                outExpand.save(StreamDir + 'FullStreamsExpand_' + subdirs[-3:] + '.tif')
```

## Summarize landscape data over wetland paths
###Process rasters with wetland paths to produce continuous or categorical summaries

1. Open control table and access information to process each raster
2. Loop through RPUs
3. Based on raster type, use ArcGIS functions to create catchment summaries
    * Categorical - TabulateArea
    * Continuous - ZonalStatisticsAsTable
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import os
import arcpy
from arcpy.sa import TabulateArea, ZonalStatisticsAsTable
arcpy.CheckOutExtension("spatial")
import pandas as pd

#ctl_path = 'J:/GitProjects/Wetland Connectivity/WetlandScripts/'
ctl_path = 'D:/WorkFolder/WetConnect_Nov2016/Scripts/'
ctl = pd.read_csv(ctl_path + 'ControlTable_Wetlands_NLCD2011.csv')

#-----------------------------------------------------------------------------
# Populate variables from control table
NHD_dir = ctl.DirectoryLocations.values[0]
path_dir = ctl.DirectoryLocations.values[1]
out_dir_paths = ctl.DirectoryLocations.values[3]
#-----------------------------------------------------------------------------

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

for line in range(len(ctl.values)):
    if ctl.run[line] == 1:   
        #print '---- Running: ' + str(ctl.LandscapeLayer[line]) + ' ----'
        accum_type = ctl.accum_type[line] 
        ingrid_dir = ctl.ingrid_dir[line]
            # Loop through RPUs
        for region in inputs.keys():
            for hydro in inputs[region]:
                #print 'Region ' + region + ' and hydro number ' + hydro
                for dirs in os.listdir(NHD_dir + '/NHDPlus' + region + '/NHDPlus' + hydro):
                    if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                        rpu =  dirs[-3:] 
                        print rpu + " " + hydro + " " + region
                            # Define inputs from control table
                        inZoneData = path_dir + '/StreamLink_' + rpu + '.tif'
                        if ctl.LandscapeLayer[line] == 'elev_cm':
                            ingrid_dir = NHD_dir
                            LandscapeLayer = ingrid_dir + '/' + '/NHDPlus' + region + '/NHDPlus' + hydro + '/NEDSnapshot/Ned' + rpu + '/elev_cm'
                        if ctl.LandscapeLayer[line] == 'fac':
                            ingrid_dir = NHD_dir
                            LandscapeLayer = ingrid_dir + '/' + '/NHDPlus' + region + '/NHDPlus' + hydro + '/NHDPlusFdrFac' + rpu + '/fac'                        
                        if ctl.LandscapeLayer[line] == 'fldown':
                            LandscapeLayer = ingrid_dir + '/' + ctl.LandscapeLayer[line] + '_' + rpu + '.tif' 
                        if ctl.LandscapeLayer[line] != 'elev_cm' and ctl.LandscapeLayer[line] != 'fldown' and ctl.LandscapeLayer[line] != 'fac':
                            LandscapeLayer = ingrid_dir + '/' +   ctl.LandscapeLayer[line]                         
                        outTable = out_dir_paths + '/' + ctl.Final_Table_Name[line] + '_' + rpu + '.dbf'
                        arcpy.env.cellSize = "30"
                        arcpy.env.snapRaster = inZoneData
                        if accum_type == 'Categorical':
                            if not arcpy.Exists(outTable):
                                TabulateArea(inZoneData, 'VALUE', LandscapeLayer, "Value", outTable, "30")
                        if accum_type == 'Continuous':
                            if not arcpy.Exists(outTable):
                                ZonalStatisticsAsTable(inZoneData, 'VALUE', LandscapeLayer, outTable, "DATA", "ALL") 
```


## Associate wetlands with flow paths
### Also make adjustment to get wetland points associated with paths correctly
```{r, eval=F}
library(raster)
library(rgdal)
library(stringr)
library(foreign)
require(dplyr)

year = '2001'
path_dir = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/CostPaths')
points_dir = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPoints')
wetlands_dir = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/AllWetlands_rpu')
streams_dir = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/FullStreams')
fromto_dir = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/FlowTables')
# cat_path = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandCat/Accumulation/')
# cat_dir = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD', year, '/WetlandCat/Accumulation/')
# zonal_path = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/Zonal/')
nhddir = 'L:/Priv/CORFiles/Geospatial_Library_Resource/PHYSICAL/HYDROLOGY/NHDPlusV21/'

nhd_units = read.csv('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/nhd_process_units.csv')

files = list.files(fromto_dir, pattern = '.dbf'); rpus = c()
files = files[!grepl('\\.xml$',files) & ! grepl('\\.vat.dbf$',files)]
for(i in 1:length(files)){
  #print(files[i])
  rpus[i] = substr(files[i], 13,15)
}

path_list = list.files(path_dir, pattern = "StreamLink_")
path_list = path_list[grep('\\.tif$',path_list)]

point_list = list.files(points_dir, pattern = "WetlandPoints")
point_list = point_list[grep('\\.shp$',point_list)]

wetland_list = list.files(wetlands_dir, pattern = "Wetlands")
wetland_list = wetland_list[grep('\\.dbf$',wetland_list)]

stream_list = list.files(streams_dir, pattern = "Expand")
stream_list  = stream_list[grep('\\.tif$',stream_list)]

# fromtotable_list = list.files(fromto_dir, pattern = 'FrmTo')
# fromtotable_list  = fromtotable_list[grep('\\.dbf$',fromtotable_list)]
# drop_list  = fromtotable_list[grep('.vat.dbf',fromtotable_list)]
# fromtotable_list = setdiff(fromtotable_list, drop_list)

for (i in 1:59){ 
  print((rpus[i]))
  #print(nhd_units[i,])
  region = nhd_units[i,3]; hydro = nhd_units[i,2]; rpu = nhd_units[i,1] 
  # fac_ras = raster(paste0(nhddir,'NHDPlus',region,'/NHDPlus',hydro,'/NHDPlusFdrFac',rpu,'/fac'))
  streamlink_ras = raster(paste0(path_dir,'/',path_list[i]))
  wetpoint = readOGR(points_dir, strsplit(point_list[i],'\\.')[[1]][1])
  # wetland = read.dbf(paste0(wetlands_dir,'/',wetland_list[i]))
  # wetland = wetland[c(1)]
  # fromto = read.dbf(paste0(fromto_dir, '/', fromtotable_list[i]))[c('STREAMLINK','FLOWTOFINA')]
  # names(fromto) = c('from','to')
  # names(wetland)[1] = 'WET_ID'
  wetpoint$STRMLNK_ID =  extract(streamlink_ras, wetpoint)
  # wetpoint$fac = extract(fac_ras, wetpoint)
  # wetpoint = wetpoint[c(1,6,7)]
  # faczonal = read.dbf(paste0(zonal_path, 'Fac_', rpus[i], '.dbf'))[c('Value','COUNT','MIN','MAX')]
  # wetpoint = wetpoint@data
  # wetpoint = merge(wetpoint, faczonal, by.x = 'STRMLNK_ID', by.y = 'Value', all.x=T)
  # wetpoint = merge(wetpoint, fromto, by.x = 'STRMLNK_ID', by.y = 'from', all.x=T)
  
  stream_exp = raster(paste0(streams_dir,'/',stream_list[i]))
  wetpoint$adj = extract(stream_exp, wetpoint)
  
  wetpoint$Riparian = 0
  # wetpoint$Riparian[(wetpoint$fac == wetpoint$MAX & is.na(wetpoint$to))] = 1
  # wetpoint$Riparian[(is.na(wetpoint$STRMLNK_ID))] = 1
  wetpoint$Riparian[(wetpoint$adj == 1)] = 1
  wetpoint = wetpoint[c('STRMLNK_ID','GRID_CODE','Riparian')]
  names(wetpoint) = c('PATHID','WET_ID','Riparian')
  wetpoint = wetpoint[c('WET_ID', 'PATHID','Riparian')]
  # wetpoint$PATHID[(wetpoint$Riparian==1)] = NA
  
  #------------------------------------------------------------------------------------------------
#   #Development to find riparian versus GIW
#   #Case 1  Riparian
#   head(wetpoint[(wetpoint$fac == wetpoint$MAX & is.na(wetpoint$to)), ], n=50)
#   #Case 2 GIW
#   head(wetpoint[(wetpoint$fac == wetpoint$MAX & !is.na(wetpoint$to)), ], n=50)
#   #Case 3 GIW
#   head(wetpoint[(wetpoint$fac < wetpoint$MAX & is.na(wetpoint$to)), ], n=50)    
#   #Case 4 GIW
#   head(wetpoint[(wetpoint$fac < wetpoint$MAX & !is.na(wetpoint$to)), ], n=50) 
#   #Case 5 Doesn't exist
#   head(wetpoint[(wetpoint$fac > wetpoint$MAX & is.na(wetpoint$to)), ], n=50) 
#   #Case 6 Doesn't exist
#   head(wetpoint[(wetpoint$fac > wetpoint$MAX & !is.na(wetpoint$to)), ], n=50)
#   #Case 7 Riparian
#   head(wetpoint[(is.na(wetpoint$STRMLNK_ID)), ], n=50)
  #------------------------------------------------------------------------------------------------
  
  WetlandsNoPath = wetpoint[wetpoint$Riparian==1,]
  WetlandsWithPath = wetpoint[wetpoint$Riparian==0,]
  
  write.csv(wetpoint, paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/LookupTables/AllWetlands_StreamLink_Lookup_',str_sub(strsplit(wetland_list[i],'\\.')[[1]][1],-3),'.csv'), row.names=FALSE)
  write.csv(WetlandsWithPath, paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/LookupTables/WetlandsWithPath_StreamLink_Lookup_',str_sub(strsplit(wetland_list[i],'\\.')[[1]][1],-3),'.csv'), row.names=FALSE)
  write.csv(WetlandsNoPath, paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/LookupTables/WetlandsNoPath_StreamLink_Lookup_',str_sub(strsplit(wetland_list[i],'\\.')[[1]][1],-3),'.csv'), row.names=FALSE)
}
```

## Wetland catchment processes
### Delineate wetland catchments

1. Check to see if catchments already exist
2. If no, run ArcGIS 'watershed' tool on all wetlands
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
# Import arcpy module
import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")

from datetime import datetime
import struct, decimal, itertools

arcpy.env.overwriteOutput = True

nhddir = 'L:/Priv/CORFiles/Geospatial_Library_Resource/PHYSICAL/HYDROLOGY/NHDPlusV21'
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'

year = '2001'
wetland_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/AllWetlands_rpu'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandCat/WetCats'
fullstreams_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year +'/FullStreams'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
          
for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]
                Fullstreamsnull = fullstreams_dir + "/FullStreamsFDRNull" + rpu + ".tif"
                #Check to see if wetland catchments exist already
                if not os.path.exists(watershed_dir + '/WetlandCat_' + rpu + '.tif'):                     
                    print rpu  
                    startTime = time.time() 
                        #-- Create garbage cans --
                    garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
                    if not os.path.exists(garbage):
                        os.makedirs(garbage)
                    arcpy.env.workspace = garbage
                    arcpy.env.mask = Fullstreamsnull
                        #-- Delete garbage after run --
                    startTime = time.time()                      
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                        # Generate wetland watersheds                      
                    outWtshd = Watershed(fdr, wetland_dir + '/WetlandsRgnGrp_' + rpu + '.tif', "VALUE")
                        # Save watershed
                    outWtshd.save(watershed_dir + '/WetlandCat_' + rpu + '.tif')                    
                    print "Minutes for this region: " + str((time.time()-startTime) / 60.0) 
```

### Create catchment connections (from-to tables)

1. Shift the catchment in each of the 8 neighboring directions
2. Check each neighboring cell following conditions:
    * Does the cell have a different catchment ID as neighbor?
    * Does it flow into the neighboring cell?
3. If 'yes' to both questions, then connect in topology table
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}

# Import arcpy module
import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")
from datetime import datetime
import struct, decimal, itertools

arcpy.env.overwriteOutput = True

nhddir = "L:/Priv/CORFiles/Geospatial_Library_Resource/PHYSICAL/HYDROLOGY/NHDPlusV21"
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
year = '2001'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandCat/WetCats'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandCat/FlowTables'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
          
for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]
                    # Check to see if wetland catchments exist already
                outDbf = frmto_dir + "/WetlandFrmTo" + rpu + ".dbf"
                if not os.path.exists(outDbf):
                        #-- Create garbage cans --
                    garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
                    if not os.path.exists(garbage):
                        os.makedirs(garbage)
                    arcpy.env.workspace = garbage
                        #-- Delete garbage after run --
                    startTime = time.time()   
                    print "Shifting region: " + rpu
                    Wtshds = Raster(watershed_dir + '/WetlandCat_' + rpu + '.tif')     
                    shift1 = arcpy.Shift_management(Wtshds, "shift1.tif", "-30", "0", Wtshds)
                    shift2 = arcpy.Shift_management(Wtshds, "shift2.tif", "-30", "30", Wtshds)
                    shift4 = arcpy.Shift_management(Wtshds, "shift4.tif", "0", "30", Wtshds)
                    shift8 = arcpy.Shift_management(Wtshds, "shift8.tif", "30", "30", Wtshds)
                    shift16 = arcpy.Shift_management(Wtshds, "shift16.tif", "30", "0", Wtshds)
                    shift32 = arcpy.Shift_management(Wtshds, "shift32.tif", "30", "-30", Wtshds)
                    shift64 = arcpy.Shift_management(Wtshds, "shift64.tif", "0", "-30", Wtshds)
                    shift128 = arcpy.Shift_management(Wtshds, "shift128.tif", "-30", "-30", Wtshds)                   
                    print "Minutes to shift this region: " + str((time.time()-startTime) / 60.0) 
                    
                        # Process: Raster Calculator                    
                    print 'Creating from-to connections'
                    startTime = time.time() 
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                    flowto1 = ((shift1 != Wtshds) * (fdr == 1)) * shift1
                    flowto1.save("FlowTo1.tif")
                    flowto1 = Raster("FlowTo1.tif")
                    flowto1 = Con(IsNull(flowto1),0,flowto1)
                    
                    flowto2 = ((shift2 != Wtshds) * (fdr == 2)) * shift2
                    flowto2.save("FlowTo2.tif")
                    flowto2 = Raster("FlowTo2.tif")
                    flowto2 = Con(IsNull(flowto2),0,flowto2)
                    
                    flowto4 = ((shift4 != Wtshds) * (fdr == 4)) * shift4
                    flowto4.save("FlowTo4.tif")
                    flowto4 = Raster("FlowTo4.tif")
                    flowto4 = Con(IsNull(flowto4),0,flowto4)
                    
                    flowto8 = ((shift8 != Wtshds) * (fdr == 8)) * shift8
                    flowto8.save("FlowTo8.tif")
                    flowto8 = Raster("FlowTo8.tif")
                    flowto8 = Con(IsNull(flowto8),0,flowto8)
                    
                    flowto16 = ((shift16 != Wtshds) * (fdr == 16)) * shift16
                    flowto16.save("FlowTo16.tif")
                    flowto16 = Raster("FlowTo16.tif")
                    flowto16 = Con(IsNull(flowto16),0,flowto16)
                    
                    flowto32 = ((shift32 != Wtshds) * (fdr == 32)) * shift32
                    flowto32.save("FlowTo32.tif")
                    flowto32 = Raster("FlowTo32.tif")
                    flowto32 = Con(IsNull(flowto32),0,flowto32)
                    
                    flowto64 = ((shift64 != Wtshds) * (fdr == 64)) * shift64
                    flowto64.save("FlowTo64.tif")
                    flowto64 = Raster("FlowTo64.tif")
                    flowto64 = Con(IsNull(flowto64),0,flowto64)
                    
                    flowto128 = ((shift128 != Wtshds) * (fdr == 128)) * shift128
                    flowto128.save("FlowTo128.tif")
                    flowto128 = Raster("FlowTo128.tif")
                    flowto128 = Con(IsNull(flowto128),0,flowto128)
                    
                    FlowToSum = flowto1 + flowto2 + flowto4 + flowto8 + flowto16 + flowto32 + flowto64 + flowto128
                    FlowToSum.save("FlowToSum.tif")
                    FlowToSum = Raster("FlowToSum.tif")
                    FlowToFinal = Con(FlowToSum != 0, FlowToSum)
                    FlowToFinal.save("FlowToFinal.tif")
                    
                    outCombine = Combine([FlowToFinal, Wtshds])
                    outCombine.save(working_dir + "/ScratchDir/WetlandFrmTo" + rpu + ".tif")

                    if not arcpy.Exists(outDbf):
                        arcpy.CopyRows_management(outCombine, outDbf, "")
                    print "Minutes to connect catchments in this region: " + str((time.time()-startTime) / 60.0) 
                    
                    try:
                        arcpy.Delete_management("FlowTo1.tif")
                        arcpy.Delete_management("FlowTo2.tif")
                        arcpy.Delete_management("FlowTo4.tif")
                        arcpy.Delete_management("FlowTo8.tif")
                        arcpy.Delete_management("FlowTo16.tif")
                        arcpy.Delete_management("FlowTo32.tif")
                        arcpy.Delete_management("FlowTo64.tif")
                        arcpy.Delete_management("FlowTo128.tif")
                        arcpy.Delete_management("shift1.tif")
                        arcpy.Delete_management("shift2.tif")
                        arcpy.Delete_management("shift4.tif")
                        arcpy.Delete_management("shift8.tif")
                        arcpy.Delete_management("shift16.tif")
                        arcpy.Delete_management("shift32.tif")
                        arcpy.Delete_management("shift64.tif")
                        arcpy.Delete_management("shift128.tif")
                        arcpy.Delete_management("FlowToSum.tif")
                        arcpy.Delete_management("FlowToFinal.tif")
                    except:
                        pass
```

### Create numpy files for accumulating wetland catchment results
1. Loops through from-to tables
2. Makes dictionary of next upstream catchment for each non-headwater catchment
3. Runs children and bastards functions to make full list of upstream catchments
4. Generates information such as length of each connection and saves results as 3 numpy vectors
    * comids<regionID>.npy - Vector of unique IDs for each wetland in region
    * lengths<regionID>.npy - Vector of the number of upstream catchments above each wetland. Children includes focal catchment, bastards excludes focal catchment
    * upCats<regionID>.npy - Vector of the unique IDs of each upstream catchment for each focal catchment listed in order. Focal catchment included for children, excluded for bastards
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import arcpy
import os, sys
import pysal as ps
import numpy as np
from collections import deque, defaultdict, OrderedDict

year = '2011'
numpy_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandCat/WetCats_npy/'
frmto_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandCat/FlowTables/'
watershed_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD' + year + '/WetlandCat/WetCats/'


#Need to set to where WetCat_function.py is stored
wetcatfunc = 'J:/GitProjects/Wetland Connectivity/WetlandScripts'
sys.path.append(wetcatfunc)  
from WetCat_functions import dbf2DF, children, bastards

files = filter(lambda x: x.endswith(('.dbf')) and not x.count('.tif'), os.listdir(frmto_dir))

for file in files:
    rpu = file[-7:-4]
    print rpu

        #Read in wetland catchments to get list of COMIDs    
    wetcat = watershed_dir + 'WetlandCat_' + rpu + '.tif'
    if not os.path.exists(wetcat + '.vat.dbf'):
        arcpy.BuildRasterAttributeTable_management(wetcat, "Overwrite")
    tbl = dbf2DF(wetcat + '.vat.dbf')
    COMIDs = tbl.VALUE.values      
    
        #Read in from-to table
    flow = dbf2DF(frmto_dir + file)[[1,3]] #Only need columns 1 and 3
    #print flow.head()
    print "Processing region: " + rpu + " with total records = " + str(len(flow))
    flow.columns = ['TOCOMID','FROMCOMID'] #Rename columns
    flow  = flow[flow.FROMCOMID != 0] #Remove paths with FROMCOMID == 0
    fromID = np.array(flow.FROMCOMID) #Make numpy arrays of from and to columns
    toID = np.array(flow.TOCOMID)
    
        #Make dictionary of next up catchment ID
    UpCOMs = defaultdict(list)
    for i in range(0, len(flow), 1):
        FROMID = fromID[i]
        TOID = toID[i]
        UpCOMs[TOID].append(FROMID)                              
        
        #Make and save bastards
    a = map(lambda x: bastards(x, UpCOMs), COMIDs) #Make bastards vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'bastards'):
        os.makedirs(numpy_dir + 'bastards')
    np.save(numpy_dir + 'bastards/upCats' + rpu + '.npy', a)
    np.save(numpy_dir + 'bastards/comids' + rpu + '.npy', COMIDs)
    np.save(numpy_dir + 'bastards/lengths' + rpu + '.npy', lengths)
    
         #Make and save children
    a = map(lambda x: children(x, UpCOMs), COMIDs) #Make children vector
    lengths = np.array([len(v) for v in a]) #Make lengths vector
    a = np.int32(np.hstack(np.array(a)))    #Convert to 1d vector
    if not os.path.exists(numpy_dir + 'children'):
        os.makedirs(numpy_dir + 'children')
    np.save(numpy_dir + 'children/upCats' + rpu + '.npy', a)
    np.save(numpy_dir + 'children/comids' + rpu + '.npy', COMIDs)
    np.save(numpy_dir + 'children/lengths' + rpu + '.npy', lengths)   
```


### Process rasters with wetland catchments to produce continuous or categorical summaries
1. Open control table and access information to process each raster
2. Loop through RPUs
3. Based on raster type, use ArcGIS functions to create catchment summaries
    * Categorical - TabulateArea
    * Continuous - ZonalStatisticsAsTable
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import os
import arcpy
from arcpy.sa import TabulateArea, ZonalStatisticsAsTable
arcpy.CheckOutExtension("spatial")
import pandas as pd

ctl_path = 'J:/GitProjects/Wetland Connectivity/WetlandScripts/'
ctl = pd.read_csv(ctl_path + 'ControlTable_Wetlands_NLCD2001.csv')

#-----------------------------------------------------------------------------
# Populate variables from control table
NHD_dir = ctl.DirectoryLocations.values[0]
basin_dir = ctl.DirectoryLocations.values[2]
out_dir_basins = ctl.DirectoryLocations.values[4]
#-----------------------------------------------------------------------------

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

for line in range(len(ctl.values)):
    if ctl.run[line] == 1:   
        print '---- Running: ' + str(ctl.LandscapeLayer[line]) + ' ----'
        accum_type = ctl.accum_type[line] 
        ingrid_dir = ctl.ingrid_dir[line]
            # Loop through RPUs
        for region in inputs.keys():
            for hydro in inputs[region]:
                print 'Region ' + region + ' and hydro number ' + hydro
                for dirs in os.listdir(NHD_dir + '/NHDPlus' + region + '/NHDPlus' + hydro):
                    if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                        rpu =  dirs[-3:] 
                            # Define inputs from control table
                        inZoneData = basin_dir + '/WetlandCat_' + rpu + '.tif'
                        LandscapeLayer = ingrid_dir + '/' + ctl.LandscapeLayer[line]
                        outTable = out_dir_basins + '/' + ctl.Final_Table_Name[line] + '_' + rpu + '.dbf'
                        arcpy.env.cellSize = "30"
                        arcpy.env.snapRaster = inZoneData
                        if accum_type == 'Categorical':
                            if not arcpy.Exists(outTable):
                                TabulateArea(inZoneData, 'VALUE', LandscapeLayer, "Value", outTable, "30")
                        if accum_type == 'Continuous':
                            if not arcpy.Exists(outTable):
                                ZonalStatisticsAsTable(inZoneData, 'VALUE', LandscapeLayer, outTable, "DATA", "ALL")  
```

## Accumulate path and catchment data

### Universal code to accumulate path or catchment metrics
* Uses control tables to determine whether path or basin metrics should be calculated
* Places results in appropriate directory (i.e., path or basin)
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import pandas as pd
import numpy as np
import os, sys

wetcatfunc = 'D:/WorkFolder/WetConnect_Nov2016/Scripts/'
# wetcatfunc = 'J:/GitProjects/Wetland Connectivity/WetlandScripts/'

sys.path.append(wetcatfunc)
from WetCat_functions import dbf2DF, Accumulation

ctl_path = 'D:/WorkFolder/WetConnect_Nov2016/Scripts/'
# ctl_path = 'J:/GitProjects/Wetland Connectivity/WetlandScripts/'

ctl = pd.read_csv(ctl_path + 'ControlTable_Wetlands_NLCD2011.csv')

#Use any of the numpy files to get list of regions
numpy_dir = ctl.DirectoryLocations.values[8] + '/'
files = filter(lambda x: x.endswith(('.npy')) and x.count('lengths'), os.listdir(numpy_dir+'children'))

for line in range(len(ctl.values)):
    
    if ctl.run[line] == 1:   
        zonal_type = str.upper(ctl.MetricType[line]) #Type of zonal and accumulation metric to process
        var = ctl.Final_Table_Name[line] #Name of variable to be processed
        tbl_type = ctl.path_basin[line] #Name of type of table (basin or path)
        ID_column = str.capitalize(tbl_type) + 'ID'
        accum_type = ctl.accum_type[line]
            # Populate variables from control table
        if tbl_type == 'path':
            zonal_dir = ctl.DirectoryLocations.values[3] + '/'
            numpy_dir = ctl.DirectoryLocations.values[8] + '/'
            path_dir = ctl.DirectoryLocations.values[1] + '/'
            out_accum = ctl.DirectoryLocations.values[9] + '/'
            npIDvect = 'PathIDs'
            npNetwork = 'downPaths'
        else:
            zonal_dir = ctl.DirectoryLocations.values[4] + '/'    
            numpy_dir = ctl.DirectoryLocations.values[7] + '/'    
            path_dir = ctl.DirectoryLocations.values[2] + '/'
            out_accum = ctl.DirectoryLocations.values[10] + '/'     
            npIDvect = 'comids'
            npNetwork = 'upCats'
            
        print '---- Running: ' + var + ' ' + zonal_type + ' ----'
        for file in files:
            region = file[7:10]
            print region  
            startTime = time.time() 
            outFile = out_accum + var + '_' + zonal_type + '_' + region + '.csv'
            zonal_file =  zonal_dir + var + '_' + region + '.dbf'
                #Read in zonal table
            arr = dbf2DF(zonal_file)  
                #Which columns to keep or drop for accumulation
            if zonal_type == 'MEAN':    
                arr = arr[['VALUE', 'SUM', 'COUNT']]
            elif zonal_type != 'MEAN' and zonal_type != 'PERCENT':
                arr = arr[['VALUE', zonal_type]]                
                #Read in numpy vectors                        
            IDs = np.load(numpy_dir + 'children/' + npIDvect + region + '.npy')
            lengths = np.load(numpy_dir + 'children/lengths' + region + '.npy')
            network = np.load(numpy_dir + 'children/' + npNetwork + region + '.npy')
                #Make sure all path or ws IDs are accounted for
            if len(arr) != len(IDs):
                if tbl_type == 'path':
                    allIDs = dbf2DF(path_dir + 'StreamLink_' + region + '.tif.vat.dbf')[['VALUE']]
                else:
                    allIDs = dbf2DF(path_dir + 'WetlandCat_' + region + '.tif.vat.dbf')[['VALUE']]
                arr = pd.merge(arr, allIDs, on = 'VALUE', how = 'right')

            df = Accumulation(arr, IDs, lengths, network, tbl_type=tbl_type, ID_column=ID_column, zonal_type=zonal_type)
            df.to_csv(out_accum + var + '_' + zonal_type + '_' + region + '.csv', index=False)
            print "Minutes for this region: " + str((time.time()-startTime) / 60.0)
```

## Get summaries of raster data for just the wetland - not the basin or the path, just the wetland
### Process rasters with wetlands to produce continuous or categorical summaries
1. Open control table and access information to process each raster
2. Loop through RPUs
3. Based on raster type, use ArcGIS functions to create catchment summaries
    * Categorical - TabulateArea
    * Continuous - ZonalStatisticsAsTable
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import os
import arcpy
from arcpy.sa import TabulateArea, ZonalStatisticsAsTable
arcpy.CheckOutExtension("spatial")
import pandas as pd

ctl_path = 'J:/GitProjects/Wetland Connectivity/WetlandScripts/'
ctl = pd.read_csv(ctl_path + 'ControlTable_Wetlands_NLCD2011.csv')

#-----------------------------------------------------------------------------
# Populate variables from control table
NHD_dir = ctl.DirectoryLocations.values[0]
wetlands_dir = ctl.DirectoryLocations.values[11]
out_dir_wetlands = ctl.DirectoryLocations.values[12]
#-----------------------------------------------------------------------------

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

for line in range(len(ctl.values)):
    if ctl.run[line] == 1:   
        print '---- Running: ' + str(ctl.LandscapeLayer[line]) + ' ----'
        accum_type = ctl.accum_type[line] 
        ingrid_dir = ctl.ingrid_dir[line]
            # Loop through RPUs
        for region in inputs.keys():
            for hydro in inputs[region]:
                print 'Region ' + region + ' and hydro number ' + hydro
                for dirs in os.listdir(NHD_dir + '/NHDPlus' + region + '/NHDPlus' + hydro):
                    if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                        rpu =  dirs[-3:] 
                            # Define inputs from control table
                        inZoneData = wetlands_dir + '/WetlandsRgnGrp_' + rpu + '.tif'
                        LandscapeLayer = ingrid_dir + '/' + ctl.LandscapeLayer[line]
                        outTable = out_dir_wetlands + '/' + ctl.Final_Table_Name[line] + '_' + rpu + '.dbf'
                        arcpy.env.cellSize = "30"
                        arcpy.env.snapRaster = inZoneData
                        if accum_type == 'Categorical':
                            if not arcpy.Exists(outTable):
                                TabulateArea(inZoneData, 'VALUE', LandscapeLayer, "Value", outTable, "30")
                        if accum_type == 'Continuous':
                            if not arcpy.Exists(outTable):
                                ZonalStatisticsAsTable(inZoneData, 'VALUE', LandscapeLayer, outTable, "DATA", "ALL")  
```

## QA check on wetland points and wetland rasters
```{r, eval=F}
library(rgdal)
library(raster)

year = '2011'
final_path = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/FinalTables/WetlandTables/')
# data_path = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/WetlandPath/Data'
# wetland_tables = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/FinalTables/WetlandTables/'
accum_path = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/Accumulation/')
accum_cat = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandCat/Accumulation/')
# precip_path = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/WetlandCat/Accumulation/'
lookup_tables = paste0('L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD',year,'/WetlandPath/LookupTables/')
# cat_path = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/FinalTables/NHDPlusCatchmentTables/'

#table_combo = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/CombiningTables/'

files = list.files(accum_path, pattern = 'NLCD'); rpus = c()
for(i in 1:length(files)){
  #print(files[i])
  rpus[i] = substr(files[i], 18, 20)
}
wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands_rpu'
wetland_points_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/WetlandPoints'


for (i in 1:length(rpus)){
  print(paste0('running ',rpus[i]))
  points = readOGR(wetland_points_dir,paste0('WetlandPoints',rpus[i]))
  wetlands = raster(paste0(wetlands_dir,'/WetlandsRgnGrp_',rpus[i],'.tif'))
  # wetlands = velox(wetlands)
  # test <- wetlands$extract_points(points)
  wetID = extract(wetlands, points,df=TRUE)
  
  if (any(wetID[[paste0('WetlandsRgnGrp_',rpus[i])]] != points$GRID_CODE)) print(paste0('problem with ',rpus[i]))
}
```


### Make point files for wetland path end cells
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}
import os
import arcpy
from arcpy.sa import Raster, Con
arcpy.CheckOutExtension("spatial")
import pandas as pd

NHD_dir = 'H:/NHDPlusV21'
path_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/WetlandPath/CostPaths'
path_lenght_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/FlowLengthsDown'
inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
          'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}

for region in inputs.keys():
    for hydro in inputs[region]:
        #print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(NHD_dir + '/NHDPlus' + region + '/NHDPlus' + hydro):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:] 
                print rpu + " " + hydro + " " + region
                LengthLayer = Raster(path_lenght_dir + '/fldown_' + rpu + '.tif') 
                PathLayer = Raster(path_dir + '/StreamLink_' + rpu + '.tif')                      
                outRas = 'H:/WorkingData/wetlandjunk/pathoutlet_' + rpu + '.tif'
                arcpy.env.cellSize = "30"
                arcpy.env.snapRaster = PathLayer
                if not arcpy.Exists(outRas):
                    TermPath = Con((LengthLayer == 0) & (PathLayer > 0), PathLayer,)
                    TermPath.save(outRas)

                outPoint = path_dir + '/StreamLinkEndPoint_' + rpu + '.tif'
                field = "VALUE"               
                # Execute RasterToPoint
                arcpy.RasterToPoint_conversion(outRas, outPoint, field)
```


### WE'RE NOT USING THIS NEXT CHUNK IN CURRENT PROCESS!!! ###
### Use Full Streams to test if wetlands are isolated from stream network 
1. Build VAT for wetland raster
2. Set non-null values in fdrnull raster = 1
3. Multiply rasters and build VAT of output of (2)
4. Compare counts of regions in VATS 
5. Save isolated wetlands
```{r, engine='python', engine.path='C:/Python27/ArcGISx6410.4/python.exe', eval=F}

import arcpy
import os
from arcpy.sa import *
from arcpy import env
arcpy.CheckOutExtension("spatial")
from collections import deque, defaultdict
import pysal as ps
import pandas as pd
import numpy as np
import numpy.ma as ma
from osgeo import gdal
import osr

arcpy.env.overwriteOutput = True

def array2raster(newRasterfn,rasterfn,array):
    geotransform = rasterfn.GetGeoTransform()
    originX = geotransform[0]
    originY = geotransform[3]
    pixelWidth = geotransform[1]
    pixelHeight = geotransform[5]
    cols = array.shape[1]
    rows = array.shape[0]

    driver = gdal.GetDriverByName('GTiff')
    outRaster = driver.Create(newRasterfn, cols, rows, 1, gdal.GDT_Byte)
    outRaster.SetGeoTransform((originX, pixelWidth, 0, originY, 0, pixelHeight))
    outband = outRaster.GetRasterBand(1)
    outband.WriteArray(array)
    outRasterSRS = osr.SpatialReference()
    outRasterSRS.ImportFromWkt(rasterfn.GetProjectionRef())
    outRaster.SetProjection(outRasterSRS.ExportToWkt())
    outband.FlushCache()

def dbf2DF(dbfile, upper=True):
    db = ps.open(dbfile)
    cols = {col: db.by_col(col) for col in db.header}
    db.close()  #Close dbf 
    pandasDF = pd.DataFrame(cols)
    if upper == True:
        pandasDF.columns = pandasDF.columns.str.upper()              
    return pandasDF


# nhddir = 'L:/Priv/CORFiles/Geospatial_Library_Resource/PHYSICAL/HYDROLOGY/NHDPlusV
working_dir = 'J:/GitProjects/Wetland Connectivity/SpatialData'
# working_dir = 'D:/WorkFolder/WetConnect_Aug2016'
# NLCD 2011
# wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands'
# wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/AllWetlands_rpu'
# watermask_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'
# isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2011/IsolatedWetlands'
# NLCD 2001
wetlands_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands'
wetrpu_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/AllWetlands_rpu'
watermask_dir = 'L:/Priv/CORFiles/Geospatial_Library/Data/Project/StreamCat/LandscapeRasters/QAComplete/WaterMask'
isolated_dir = 'L:/Priv/CORFiles/Geospatial_Library_Projects/WetlandConnectivity/SpatialDataInputs/Wetlands_NLCD2001/IsolatedWetlands'
arcpy.env.workspace = working_dir + '/garbage3'

inputs = {'CA':['18'],'CO':['14','15'],'GB':['16'],'GL':['04'],'MA':['02'],'MS':['05','06','07','08','10L','10U','11'],
         'NE':['01'],'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}
# inputs = {'PN':['17'],'RG':['13'],'SA':['03N','03S','03W'],'SR':['09'],'TX':['12']}           

for region in inputs.keys():
    for hydro in inputs[region]:
        print 'Region ' + region + ' and hydro number ' + hydro
        for dirs in os.listdir(nhddir + "/NHDPlus%s/NHDPlus%s"%(region, hydro)):
            if dirs.count("FdrFac") and not dirs.count('.txt') and not dirs.count('.7z'):
                rpu =  dirs[-3:]

                if not os.path.exists(isolated_dir + '/isoWetlands_' + rpu + '.tif'):                     
                    print rpu
                        #-- thanks ESRI --
                    garbage = working_dir + '/ESRI_garbage/garbage_' + rpu
                    if not os.path.exists(garbage):
                        os.makedirs(garbage)
                    arcpy.env.workspace = garbage
                        #-- thanks ESRI --
                    startTime = time.time()  
                    fdr = Raster(nhddir +"/NHDPlus" +region + "/NHDPlus" + hydro + "/NHDPlusFdrFac"  + rpu + "/fdr")
                        # Set env                
                    arcpy.env.snapRaster = fdr
                    arcpy.env.cellSize = "30"
                    arcpy.env.mask = fdr
                    arcpy.env.extent = fdr
                    # Get full streams              
                    fullstreams = Raster(watermask_dir +"/FullStreams"  + rpu + ".tif")
                    stream_expand = Expand(fullstreams, 1, 1) #Expand by 1 pixel to find wetlands that are disconnect by at least 1 pixel                
                    streamcon = Con(IsNull(stream_expand), 1, 0) #Set null pixels to zero, else stay the same                             
                    wetland_all = Raster(wetlands_dir + '/WetlandsRgnGrp.tif')
                    outWet_rpu = wetrpu_dir + '/Wetlands_' + rpu + '.tif'
                    # Make wetland for each RPU 
                    if not arcpy.Exists(outWet_rpu):
                        wetland_rpu = ExtractByMask(wetland_all, fdr)
                        wetland_rpu.save(outWet_rpu) 
                    #arcpy.gp.ExtractByMask_sa(wetland_all, fdr, outWet_rpu)
                    arcpy.BuildRasterAttributeTable_management(outWet_rpu, "Overwrite")
                    wetland = Raster(outWet_rpu)
                    wetcon = Con(IsNull(wetland),0, wetland)
                    # Multiply to create temporary query wetland
                    tmpWet = streamcon * wetcon
                    if not arcpy.Exists(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif'):
                        tmpWet.save(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif')
                    arcpy.BuildRasterAttributeTable_management(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif', "Overwrite")
                        # Read in and merge VATs to compare 
                    lesswet = dbf2DF(working_dir + '/ScratchDir/queryWetland_' + rpu + '.tif.vat.dbf')
                    allwet = dbf2DF(outWet_rpu + '.vat.dbf')
                    new = pd.merge(allwet, lesswet, on = 'VALUE', how = 'left')                
                    isolated = new.loc[new['COUNT_x'] == new['COUNT_y']]
                    isolated = np.array(isolated.VALUE).astype(int)
                        # Read in wetland raster, convert to numpy array, flatten, and query against list of isolated wetlands
                    wetland_ras = gdal.Open(outWet_rpu)
                    wetland_arr = np.array(wetland_ras.GetRasterBand(1).ReadAsArray())                
                    wetshape = wetland_arr.shape                               
                    wetland_flat = wetland_arr.flatten() #Flatten 2d array to 1d
                    z = np.where(np.in1d(wetland_flat, isolated), 1, np.NaN)
                    z.shape = wetshape             
                        # Stuff to get it out to TIF ESRI can see
                    newraster = array2raster(working_dir + '/ScratchDir/isoWetTmp_' + rpu + '.tif', wetland_ras, z)
                    newRaster = Raster(working_dir + '/ScratchDir/isoWetTmp_' + rpu + '.tif')
                    newRaster2 = Times(wetland_rpu, newRaster) #run it through a process to get it to be integer and in native ESRI format (exclude odd NUMPY stuff)    
                    newRaster3 = Con(newRaster2 != 0, newRaster2)
                    newRaster3.save(isolated_dir + '/isoWetlands_' + rpu + '.tif')              
                    print "Minutes for this region: " + str((time.time()-startTime) / 60.0)                        

```


